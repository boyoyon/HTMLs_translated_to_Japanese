<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>From Kepler to Newton</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
            .margin-large
            {
                margin-left: 30px;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .two-columns {
            display: flex;
            flex-direction: row;
            gap: 20px; /* 列間のスペース */
        }
        .column {
            flex: 1; /* 各列が均等に幅を取る */
        }
    </style>
<style>
.three-columns {
  display: flex;
  gap: 10px; /* 列間の余白を設定 */
}
.column {
  flex: 1; /* 各列の幅を均等にする */
  padding: 10px; /* 内側の余白を設定 */
}
</style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -20px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 0px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
            ol
            {
                margin-left: 30px;
            }
            ul
            {
                margin-left: 30px;
            }
    </style>
    <style>
        .thin-line {
            margin: 0; 
            margin-left:2em;
            border: 0;
            height: 1px;
            background-color: gray;
        }

        .thick-line {
            margin: 0; 
            margin-left:2em;
            border: 0;
            height: 2px;
            background-color: black;
        }
    </style>
    <style>
        .highlight {
            color: red; /* 好きな色に変更してください */
        }
    </style>
    </head>
    <body>
        <h1><center>From Kepler to Newton: Explainable AI for Science </center></h1>
<center>ケプラーからニュートンへ：科学のための説明可能な AI </center>
<br>
<center>Zelong Li　Jianchao Ji　Yongfeng Zhang </center>
<!--
<h2><center>Abstract </center></h2>
-->
<h2><center>要旨</center></h2>
<p class="margin-abstract">
<!--
The Observation — Hypothesis — Prediction — 
Experimentation loop paradigm for scientific research
 has been practiced by researchers for years 
towards scientific discoveries. However, with data 
explosion in both mega-scale and milli-scale research,
 it has been sometimes very difficult to 
manually analyze the data and propose new hypotheses
 to drive the cycle for scientific discovery. 
-->
科学研究における観察—仮説—予測—実験ループのパラダイムは、長年にわたり研究者によって科学的発見に向けて実践されてきました。しかし、メガスケールとミリスケールの両方の研究におけるデータ爆発により、科学的発見のサイクルを推進するために、データを手作業で分析し、新しい仮説を提案することが非常に困難になることがありました。
</p><p>
<!--
In this paper, we discuss the role of Explainable 
AI in scientific discovery process by demonstrating
 an Explainable AI-based paradigm for science 
discovery. The key is to use Explainable AI to 
help derive data or model interpretations, hypotheses,
 as well as scientific discoveries or insights. 
We show how computational and data-intensive 
methodology—together with experimental and 
theoretical methodology—can be seamlessly integrated
 for scientific research. To demonstrate 
the AI-based science discovery process, and to 
pay our respect to some of the greatest minds in 
human history, we show how Kepler’s laws of 
planetary motion and Newton’s law of universal 
gravitation can be rediscovered by (Explainable) 
AI based on Tycho Brahe’s astronomical observation
 data, whose works were leading the scientific 
revolution in the 16-17th century. This work also 
highlights the important role of Explainable AI 
(as compared to Blackbox AI) in science discovery
 to help humans prevent or better prepare for 
the possible technological singularity that may 
happen in the future, since science is not only 
about the know how, but also the know why. 
-->
本稿では、科学的発見のための説明可能なAIに基づくパラダイムを示すことにより、科学的発見プロセスにおける説明可能なAIの役割について議論する。鍵となるのは、説明可能なAIを用いて、データやモデルの解釈、仮説、そして科学的発見や洞察を導き出すことを支援することである。計算集約型およびデータ集約型の方法論を、実験的および理論的方法論と組み合わせることで、科学研究にどのようにシームレスに統合できるかを示す。AIに基づく科学的発見プロセスを実証し、人類史上最も偉大な知性を持つ人々に敬意を表すため、16世紀から17世紀の科学革命を牽引したティコ・ブラーエの天文観測データに基づく（説明可能な）AIによって、ケプラーの惑星運動の法則とニュートンの万有引力の法則がどのように再発見されるかを示す。この研究はまた、科学的発見における説明可能なAI（ブラックボックスAIと比較して）の重要な役割を浮き彫りにしています。科学はノウハウだけでなく、なぜノウハウなのかという知識も重要であり、将来起こりうる技術的特異点を人間が回避したり、より良く備えたりするのに役立つからです。
</p>
<!--
<h2>1. Introduction</h2>
-->
<h2>1. はじめに</h2>
<p> 
<!--
A frequently used paradigm for scientific research is the 
Hypothetico-Deductive paradigm (Figure 1(a)), which has 
been practiced by researchers for years [1, 2, 3]. In this 
paradigm, researchers first make observations which is usually
 a data collection process, and then raise a question. To 
get answers to the question, researchers will then propose a 
hypothesis as a possible explanation to the observation, usually
 through an abductive reasoning process. The hypothesis 
may come in the form of a theory, a model, an equation, 
an algorithm, or any other form depending on the research 
problem and research area. The hypothesis is used to make 
verifiable predictions, and then experimental tests or data 
analyses are conducted to verify or falsify the hypothesis. 
The above process may repeat as a loop, i.e., if the hypothesis
 is falsified, we may need to make new observations, 
propose new hypotheses, and even ask a new question. 
-->
科学研究で頻繁に用いられるパラダイムは、仮説演繹パラダイム（図1(a)）であり、長年にわたり研究者によって実践されてきました[1, 2, 3]。このパラダイムでは、研究者はまず観察（通常はデータ収集プロセス）を行い、次に疑問を提起します。疑問への答えを得るために、研究者は通常、帰納的推論プロセスを通じて、観察に対する可能な説明として仮説を提示します。仮説は、研究課題や研究分野に応じて、理論、モデル、方程式、アルゴリズムなど、様々な形式をとることができます。仮説は検証可能な予測を行うために用いられ、その後、実験的検証やデータ分析によって仮説の検証または反証が行われます。上記のプロセスはループとして繰り返される可能性があります。つまり、仮説が偽であると判定された場合、新たな観察を行い、新たな仮説を提案し、さらには新たな質問をする必要が生じる可能性があります。

</p>
<center><img src="images/fig1.png"></center>
<p>
<!--
Figure 1. The Hypothetico-Deductive paradigm for science discovery
 and the Explainable AI-based (hypothesis-free) paradigm 
for science discovery. The new paradigm uses Explainable AI to 
generate verifiable hypothesis. 
-->
図1. 科学的発見のための仮説演繹的パラダイム
と、科学的発見のための説明可能なAIベース（仮説フリー）パラダイム
新しいパラダイムでは、説明可能なAIを用いて検証可能な仮説を生成します。
</p><p>
<!--
An excellent example of science discovery is the works of 
Tycho Brahe, Johannes Kepler and Isaac Newton (Figure 
2), who are some of the greatest minds in human history 
and their work were leading the scientific revolution in the 
16-17th century. Tycho Brahe was an astronomer known for 
his accurate and comprehensive astronomical observations. 
During his career in the 16th century, though as a naked-eye 
astronomer, his observations of the planets orbiting the Sun 
were so accurate that it became possible for later researchers 
to build insightful discoveries based on his observational 
data. One notable name, of course, is Johannes Kepler, who 
discovered what was later known as the Kepler’s laws of 
planetary motion. During the science discovery process, Kepler
 hypothesized that the orbit of a planet is an ellipse with 
the Sun at one of the two foci, and he was able to fit the orbital
 equation of Mars based on Tycho’s observational data. 
Finally, the equation turns out to be surprisingly accurate 
in predicting the future position of planets, which verifies 
his first law of planetary motion. Later, Kepler further discovered
 the second and third laws through his insightful 
analyses of the data. Isaac Newton, one of the most notable 
figures in the human history of science, was not only interested
 in how planets orbit the Sun, but also why they orbit 
in such a way, which means that his goal is to explain the 
underlying mechanism of planetary motions. In conquest 
of this goal, he made several innovate discoveries which are 
later known as the Newton’s law of universal gravitation 
and the Newton’s laws of motion. 
-->
科学的発見の好例として、ティコ・ブラーエ、ヨハネス・ケプラー、アイザック・ニュートン（図2）の業績が挙げられます。彼らは人類史上最も偉大な知性を持つ人物であり、16世紀から17世紀の科学革命を牽引しました。ティコ・ブラーエは、正確かつ包括的な天文観測で知られる天文学者でした。16世紀に活躍した彼は、肉眼天文学者でありながら、太陽を周回する惑星の観測が非常に正確だったため、後世の研究者が彼の観測データに基づいて洞察に満ちた発見を積み重ねることが可能になりました。注目すべき人物の一人は、もちろんヨハネス・ケプラーです。彼は後にケプラーの惑星運動の法則として知られる法則を発見しました。科学の発見の過程において、ケプラーは惑星の軌道は太陽を2つの焦点の1つとする楕円であると仮説を立て、ティコの観測データに基づいて火星の軌道方程式を導き出しました。最終的に、この方程式は惑星の将来の位置を予測する上で驚くほど正確であることが判明し、彼の惑星運動の第一法則を証明しました。その後、ケプラーは洞察力に富んだデータの分析を通じて、第二法則と第三法則をさらに発見しました。人類の科学史における最も著名な人物の一人であるアイザック・ニュートンは、惑星がどのように太陽の周りを回るかだけでなく、なぜそのように回るかにも興味を持っていました。つまり、彼の目標は惑星運動の根底にあるメカニズムを説明することでした。この目標を達成する中で、彼は後にニュートンの万有引力の法則とニュートンの運動の法則として知られるいくつかの革新的な発見を成し遂げました。

</p>
<center><img src="images/fig2.png"></center>
<p>
<!--
Figure 2. Tycho Brahe, Johannes Kepler, Isaac Newton and their 
roles in the science discovery process. 
-->
図2. ティコ・ブラーエ、ヨハネス・ケプラー、アイザック・ニュートンと、科学発見プロセスにおける彼らの役割。
</p><p>
<!--
It is very interesting to see that Tycho, Kepler and Newton— 
though their works span over a hundred years of history— 
actually play different but closely related roles in the science 
discovery process, which are observation, analyzation, and 
explanation. Tycho’s key contribution is on observation and 
his accurate data lays foundation for insightful analyses and 
innovative discoveries in the future. Kepler analyzed the 
data and discovered meaningful patterns hidden in the data. 
Finally, Newton examined the underlying mechanism of 
such patterns and provided insightful explanations to show 
why planets move in such patterns rather than other patterns. 
Using more computer science language, Tycho’s work is 
on data collection, Kepler’s work is on model learning, i.e., 
he manually (instead of using modern computers) fit the 
data and learned predictive models based on the data, and 
finally, Newton’s work is on model interpretation, i.e., he 
(also manually) provided conceptual and mathematical explanations
 for Kepler’s results and Kepler’s laws can be 
naturally derived from Newton’s laws. 
-->
ティコ、ケプラー、ニュートンの業績は100年以上の歴史を誇りますが、科学的発見のプロセスにおいて、観測、分析、そして説明という、それぞれ異なるながらも密接に関連した役割を果たしていることは非常に興味深いことです。ティコの主要な貢献は観測にあり、彼の正確なデータは、将来の洞察に満ちた分析と革新的な発見の基盤を築きました。ケプラーはデータを分析し、そこに隠された意味のあるパターンを発見しました。最後に、ニュートンはそのようなパターンの根底にあるメカニズムを解明し、惑星が他のパターンではなくそのようなパターンで動く理由を示す洞察に満ちた説明を提供しました。よりコンピュータサイエンス的な言葉で言えば、ティコの研究はデータ収集に関するものであり、ケプラーの研究はモデル学習に関するものです。つまり、彼は（現代のコンピュータを使用する代わりに）手動でデータをフィッティングし、そのデータに基づいて予測モデルを学習しました。そして最後に、ニュートンの研究はモデル解釈に関するものです。つまり、彼は（これも手動で）ケプラーの結果に対する概念的および数学的な説明を提供し、ケプラーの法則はニュートンの法則から自然に導き出せるとしました。
</p><p>

<!--
In modern scientific research, with the help of various mechanical,
 electrical and biological equipment, many components
 of the research pipeline have been automated. The 
most notable component is observation and data collection— 
modern equipment such as telescopes, sensors and colliders 
automatically and continuously collect data to support research
 and discoveries, and such observational data usually 
comes in massive scale. For example, the Hubble Space 
Telescope (HST) generates up to 150 GB of spatial data per 
week [4], and the Large Hadron Collider (LHC) experiments 
produce about 90 PB of data per year [5]. Such abundant 
and accurate observational data helps to push the frontier of 
scientific research, but it also brings great challenges to process
 the data and build insightful hypotheses from the data. 
However, building insightful hypotheses is vitally important 
to drive the research cycle for new scientific discoveries. 
-->
現代の科学研究では、様々な機械的、電気的、生物学的機器の助けを借りて、研究パイプラインの多くの要素が自動化されています。最も注目すべき要素は観測とデータ収集です。望遠鏡、センサー、衝突型加速器などの近代的な機器は、研究と発見を支援するためにデータを自動的かつ継続的に収集し、そのような観測データは通常、膨大な量になります。例えば、ハッブル宇宙望遠鏡（HST）は週に最大150GBの空間データを生成し[4]、大型ハドロン衝突型加速器（LHC）実験は年間約90PBのデータを生成します[5]。このように豊富で正確な観測データは、科学研究の最先端を押し広げるのに役立ちますが、同時に、データを処理して洞察に富んだ仮説を構築するという大きな課題ももたらします。しかし、洞察に富んだ仮説を構築することは、新たな科学的発見のための研究サイクルを推進するために極めて重要です。
</p><p>
<!--
To indicate how the above challenges can be alleviated with 
the help of modern AI and machine learning technologies, 
we show an Explainable AI-based hypothesis-free paradigm 
for science discovery (Figure 1(b)). The key is to replace 
manual hypothesis development with an AI-driven model 
learning and model interpretation process. More specifically, 
the model learning component adopts black-box AI tools 
such as deep learning for data analysis, data augmentation 
and building accurate prediction models, while the model 
interpretation component adopts Explainable AI tools such 
as symbolic regression to translate the black-box model into 
human-understandable forms for understanding the scientific
 meanings and deriving scientific insights. Working 
together, the two components turn manual hypothesis development
 into automatic hypothesis development, saving 
efforts of building insightful hypotheses from data. 
-->
上記の課題が最新のAIと機械学習技術の助けを借りてどのように軽減できるかを示すために、科学的発見のための説明可能なAIベースの仮説フリーパラダイムを示します（図1(b)）。鍵となるのは、手作業による仮説開発をAI主導のモデル学習およびモデル解釈プロセスに置き換えることです。より具体的には、モデル学習コンポーネントは、データ分析、データ拡張、正確な予測モデルの構築にディープラーニングなどのブラックボックスAIツールを採用し、モデル解釈コンポーネントは、ブラックボックスモデルを人間が理解できる形式に変換するためにシンボリック回帰などの説明可能なAIツールを採用し、科学的な意味を理解して科学的洞察を導き出します。この2つのコンポーネントが連携することで、手作業による仮説開発が自動的な仮説開発に変換され、データから洞察に富んだ仮説を構築する労力が節約されます。
</p><p>
<!--
As a demonstration to the Explainable AI-based paradigm, 
we show how the Kepler’s laws of planetary motion and the 
Newton’s law of universal gravitation can be rediscovered by 
explainable AI based on Tycho’s astronomical observation 
data. At Kepler’s time, there were three main hypotheses 
on planetary motion—the Tychonic system, the Ptolemaic 
system and the Copernican system. These three hypotheses 
can give good predictions in the short term, but diverge from 
the observational data in the long term. Kepler spent several 
years on calculations and finally rejected the three models. 
Meanwhile, he proposed his elliptical orbit hypothesis and 
verified that it had better predictions than previous models. 
This process follows the observation–hypothesis–prediction 
paradigm of science discovery. Our experiments imagine 
that AI and machine learning techniques existed in Kepler’s 
time and show how Kepler would have been able to derive 
his first and second laws using Explainable AI-based science 
discovery based on the observational data of Mars, without 
manually making hypotheses. Besides, Explainable AI not 
only helps to find the first and second laws of planetary 
motion, but also helps the discovery process of Kepler’s 
third law: the ratio between the square of a planet’s orbital 
period and the cube of the length of the semi-major axis of 
its orbit, is a constant for all planets. It seems impossible 
to find the third law since that needs the observational data 
of other planets, but our experiment will show that by only 
using Mars data, Explainable AI is able to find the numerical 
relationship between the angular speed and the distance 
from the Sun with very high accuracy, which provides a 
clear direction towards the discovery of the third law. 
-->
説明可能なAIに基づくパラダイムのデモンストレーションとして、ティコの天文観測データに基づく説明可能なAIによって、ケプラーの惑星運動の法則とニュートンの万有引力の法則がどのように再発見されるかを示します。ケプラーの時代には、惑星運動に関する3つの主要な仮説、すなわちティコの理論、プトレマイオスの理論、そしてコペルニクスの理論がありました。これらの3つの仮説は短期的には優れた予測を与えることができますが、長期的には観測データと乖離します。ケプラーは数年にわたる計算の末、最終的にこれら3つのモデルを却下しました。その一方で、彼は楕円軌道仮説を提唱し、それが以前のモデルよりも優れた予測値を持つことを検証しました。このプロセスは、科学的発見における観測-仮説-予測というパラダイムに従っています。私たちの実験は、ケプラーの時代にAIと機械学習技術が存在していたと仮定し、ケプラーが火星の観測データに基づく説明可能なAIベースの科学的発見を用いて、手作業で仮説を立てることなく、どのようにして第一法則と第二法則を導き出すことができたかを示しています。さらに、説明可能なAIは、惑星運動の第一法則と第二法則の発見に役立つだけでなく、ケプラーの第三法則の発見プロセスにも役立ちます。第三法則とは、惑星の公転周期の2乗と軌道長半径の3乗の比は、すべての惑星において一定であるというものです。第三法則を見つけるには他の惑星の観測データが必要なので不可能に思えますが、私たちの実験では、火星のデータのみを使用して、Explainable AIが角速度と太陽からの距離の数値的な関係を非常に高い精度で見つけることができることが示され、第三法則の発見に向けた明確な方向性が示されます。
</p><p>
<!--
Throughout Kepler’s research career in the first 30 years of 
the 17th century, especially after his three laws of planetary 
motion have been discovered, Kepler has been constantly 
seeking for a kinetic explanation for the laws. He tried 
to explain the laws based on magnetic force, which from 
modern perspective turned out to be incorrect [6]. However, 
it demonstrates humans’ eager for explanations so as to not 
only know how but also know why. This is also the reason 
why we emphasize the importance of Explainable AI in the 
science discovery process. 
-->
17世紀最初の30年間、特に惑星運動の3法則が発見されて以来、ケプラーは研究を通じてこれらの法則の運動論的説明を絶えず模索し続けました。彼は磁力に基づいてこれらの法則を説明しようとしましたが、現代の視点から見るとそれは誤りであることが判明しました[6]。しかし、これは人間が「どのように」だけでなく「なぜ」も知りたいという説明への強い欲求を示していると言えます。これが、私たちが科学的発見プロセスにおける説明可能なAIの重要性を強調する理由でもあります。
</p><p>
<!--
History assigned the duty of finding the explanation to Issac 
Newton. If we would like to dig out the secret behind 
the motion of planets, we need to leverage the concepts 
of force and acceleration. During Kepler’s time, scientists 
have established the concept of force, but they still do not 
know the exact function of force. They thought force was 
proportional to distance and thus speed. Newton’s greatness 
lies in that he creatively linked the relationship between 
force and acceleration (instead of speed) and proposed the 
inverse square law of force and thus acceleration. Based 
on these concepts, Kepler’s laws can be naturally derived 
from Newton’s laws based on mathematical deviations, thus 
providing an explanation for the underlying mechanism of 
Kepler’s laws of planetary motion [7]. 
-->
歴史はアイザック・ニュートンにその説明を求める使命を与えました。惑星の運動の秘密を解き明かすには、力と加速度の概念を活用する必要があります。ケプラーの時代には、科学者たちは力の概念を確立しましたが、力の正確な作用は未だにわかっていませんでした。彼らは、力は距離、つまり速度に比例すると考えていました。ニュートンの偉大さは、力と加速度（速度ではなく）の関係を創造的に結び付け、力と加速度の反二乗の法則を提唱したことにあります。これらの概念に基づくと、ケプラーの法則は、数学的な偏差に基づくニュートンの法則から自然に導き出され、ケプラーの惑星運動の法則の根底にあるメカニズムを説明することができます[7]。

</p><p>

<!--
On the other hand, as Newton stated in his groundbreaking 
work the Principia, he considered forces from a mathematical
 point of view, not a physical view, and thus taking an 
instrumentalist view of his methods [7]. As a result, it is 
the job of the readers to assign “meanings” to the many 
variables such as the force in his mathematical framework. 
Though contemporary scientists believe that Newton must 
have his own insightful understanding of the meanings of 
the variables, and his statement was just making room for 
flexibility to accommodate different views of his readers, 
his cautiousness inspires us to think about what is the exact 
role of (Explainable) AI in science discovery. In the context 
of Explainable AI-based science discovery, the AI machines 
could indeed be able to learn black-box neural models for 
prediction and learn symbolic equations to explain the predictions,
 however, machines do not possess “meaning” of 
the variables or the combination of variables in the equations.
 For machines, the variables are just symbols used for 
data exploration, data fitting and prediction, while it is the 
job of humans to assign meanings to the variables and to 
build understandings of the universe based on the discoveries
 made by AI machines<sup>1</sup>. The role of (Explainable) AI in 
the science discovery process is to produce valid hypotheses 
or to narrow down the search space of hypotheses so as to 
speed up the discovery, but the role of assigning “meanings” 
to the discoveries is the job of humans (especially domain 
experts) which cannot be replaced by AI. In the experiments, 
we will demonstrate the importance of human during science
 discovery by showing how the representation of force 
is discovered by AI when explaining the elliptical orbit and 
how human needs to intervene so as to assign an appropriate 
meaning to force. 
-->
一方、ニュートンは画期的な著作『プリンキピア』で述べたように、力を物理的な観点からではなく数学的な観点から考察し、したがって自身の方法を道具主義的に捉えていた[7]。その結果、彼の数学的枠組みにおける力などの多くの変数に「意味」を付与するのは読者の役割となる。現代の科学者は、ニュートンが変数の意味について独自の洞察力のある理解を持っていたに違いないと考えており、彼の発言は読者の様々な見解に対応するための柔軟性を持たせたものに過ぎないと考えているが、彼の慎重さは、科学的発見における（説明可能な）AIの正確な役割について私たちに考えさせる。説明可能なAIに基づく科学的発見の文脈において、AIマシンは確かに予測のためのブラックボックスニューラルモデルを学習し、予測を説明する記号方程式を学習することができるかもしれない。しかし、マシンは方程式内の変数や変数の組み合わせの「意味」を所有していない。マシンにとって、変数はデータ探索、データフィッティング、予測に使用される単なる記号であり、変数に意味を割り当て、AIマシンによる発見に基づいて宇宙についての理解を構築するのは人間の仕事である<sup>1</sup>。科学的発見プロセスにおける（説明可能な）AIの役割は、有効な仮説を生み出すこと、あるいは発見を加速するために仮説の探索空間を絞り込むことであるが、発見に「意味」を割り当てる役割は人間（特に分野の専門家）の仕事であり、AIでは代替できない。実験では、楕円軌道を説明する際にAIがどのように力の表現を発見するか、そして力に適切な意味を与えるために人間がどのように介入する必要があるかを示すことで、科学の発見における人間の重要性を実証します。
</p><p class="margin-large">

<sup>1</sup>
<!--
In this discuss we limit ourselves to the sense of “meaning” in 
terms of human’s perspective. It is possible that machines would 
build their own internal “meaning” of the variables and calculations 
that is not understandable to humans, but that is beyond the scope 
of discussion in this work. 
-->
本稿では、人間の視点から見た「意味」に限定して議論する。機械が変数や計算について、人間には理解できない独自の内部「意味」を構築する可能性もあるが、それは本稿の議論の範囲外である。
</p><p>
<!--
This work also highlights the importance of Explainable 
AI (as compared to black-box AI) in science discovery. In 
particular, Explainable AI helps human beings to prevent 
or better prepare for the possible technological singularity 
(or simply singularity) that may happen in the future. The 
possibility of technology advancements leading to a singularity
 has been discussed by public figures from many fields 
such as John von Neumann [8], Irving John Good [9] and 
Stephen Hawking [10]. For example, I. J. Good speculated 
in 1965 that the advancement of artificial intelligence may 
bring about an intelligence explosion, where intelligent machines
 can solve problems and even build new machines 
using incomprehensible ways for humans and thus the intelligence
 of human would be left far behind [11]. Under the 
context of science discovery, if we develop and allow black-
box AI to make discoveries and represent such discoveries 
using black-box models such as complex neural networks 
that are incomprehensible for humans (though these models 
may indeed provide accurate predictions), it may lead to the 
situation that machines will accumulate knowledge that are 
more and more incomprehensible for humans and eventually 
the human knowledge will be left far behind by machine’s 
knowledge, leading to the singularity and even making machines
 out of control for humans. As a result, we need to 
make sure that AI explains its model and discoveries to humans
 using human understandable methods, so that humans 
can always keep track of the new discoveries and knowledge 
created by machines during the science discovery process. 
-->
この研究はまた、科学的発見における説明可能なAI（ブラックボックスAIと比較して）の重要性を浮き彫りにしています。特に、説明可能なAIは、将来起こりうる技術的特異点（または単にシンギュラリティ）を人類が回避したり、より良く備えたりするのに役立ちます。技術の進歩がシンギュラリティにつながる可能性については、ジョン・フォン・ノイマン[8]、アーヴィング・ジョン・グッド[9]、スティーブン・ホーキング[10]など、多くの分野の著名人によって議論されてきました。例えば、I.J.グッドは1965年に、人工知能の進歩によって知能爆発が起こり、知能機械が人間には理解できない方法で問題を解決し、新しい機械を構築することさえできるようになり、人間の知能ははるかに遅れをとるだろうと推測しました[11]。科学的発見という文脈において、ブラックボックスAIを開発し、人間には理解できない複雑なニューラルネットワークなどのブラックボックスモデルを用いて発見や表現を行えるようにした場合（これらのモデルは確かに正確な予測を提供する可能性はあるものの）、機械が人間にはますます理解できない知識を蓄積し、最終的には人間の知識が機械の知識に大きく遅れをとるという状況につながる可能性があります。その結果、人間は科学的発見のプロセスにおいて機械によって生み出される新しい発見や知識を常に把握できるように、AIがそのモデルと発見を人間に理解可能な方法で説明できるようにする必要があります。
</p><p>
<!--
In the following part of this paper, we first introduce some 
related work in Section 2, and then we will use Kepler’s and 
Newton’s works as examples to demonstrate the Explainable 
AI-based science discovery process. More specifically, in 
Section 3, we will first introduce the data and Explainable AI 
models to be used in this work, and then we will rediscover 
Kepler’s and Newton’s laws under the Explainable AI-based 
paradigm in Section 4 and Section 5, respectively. We 
conclude the work together with discussions and future 
directions in Section 6. 
-->
本論文の以下の部分では、まず第2節で関連研究を紹介し、次にケプラーとニュートンの研究を例に挙げて、説明可能なAIに基づく科学的発見プロセスを説明します。具体的には、第3節では、本研究で使用するデータと説明可能なAIモデルを紹介し、第4節ではケプラーの法則、第5節ではニュートンの法則を説明可能なAIに基づくパラダイムの下で再発見します。第6節では、議論と今後の方向性を述べて本研究を締めくくります。
</p>
<!--
<h2>2. Related Work</h2> 
<h3>2.1. Explainable AI</h3>
-->
<h2>2. 関連研究</h2>
<h3>2.1. 説明可能なAI</h3>
<p> 
<!--
Explainability has been an important perspective to consider 
in many AI systems, leading to the research on Explainable 
AI (XAI). For example, recommender system needs to explain
 its recommendations or decisions to users so as to gain 
trust and help users make informed decisions, leading to 
the research on explainable recommendation [12, 13, 14]; 
many prediction or classification algorithms need to provide
 explanations for the model designers to help them 
understand how the model works for better debugging and 
detecting potential bias in models [15, 16, 17]. Explainable 
AI methods can be generally classified to model-intrinsic 
methods and model-agnostic methods [12]. For model-
intrinsic methods, the decision and explanation are both 
produced by the same model, which means that the working
 mechanism of the model itself is transparent so that 
any decision produced by the model are naturally accompanied
 with explanations. The decision and explanation are 
usually produced concurrently in model-intrinsic methods. 
Notable examples of model-intrinsic methods include linear 
regression [18], decision tree [19, 20] and attention mechanism
 [13, 21, 22, 23], whose explanations are regression 
coefficients, decision paths and attention weights, respectively.
 For model-agnostic methods, the decision model and 
explanation model are usually two separate models. The 
decision model is responsible for prediction and decision 
making, while the explanation model is responsible for explaining
 the results produced by the decision model. In 
model-agnostic methods, the explanations are usually produced
 in a post-hoc manner, i.e., the model decisions are 
produced first and then explanations are generated for the 
decisions. Notable examples for model-agnostic methods 
include counterfactual explanations [14], local approximations
 [16], and Shapley values [15, 17]. 
-->
説明可能性は多くのAIシステムにおいて考慮すべき重要な視点であり、説明可能なAI（XAI）の研究につながっています。例えば、レコメンデーションシステムは、信頼を獲得し、ユーザーが情報に基づいた意思決定を行えるようにするために、ユーザーに推奨や決定を説明する必要があり、説明可能な推奨に関する研究につながっています[12, 13, 14]。多くの予測アルゴリズムや分類アルゴリズムは、モデル設計者がモデルの動作を理解し、デバッグを改善し、モデルの潜在的なバイアスを検出するのに役立つ説明を提供する必要があります[15, 16, 17]。説明可能なAI手法は、一般的にモデル固有の手法とモデルに依存しない手法に分類できます[12]。モデル固有の手法では、決定と説明の両方が同じモデルによって生成されます。つまり、モデル自体の動作メカニズムは透明であり、モデルによって生成された決定には自然に説明が伴います。モデル固有手法では、決定と説明は通常同時に生成される。モデル固有手法の代表的な例としては、線形回帰 [18]、決定木 [19, 20]、アテンションメカニズム [13, 21, 22, 23] などが挙げられ、これらの説明はそれぞれ回帰係数、決定パス、アテンション重みである。モデル非依存手法では、決定モデルと説明モデルは通常、別々のモデルである。決定モデルは予測と意思決定を担い、説明モデルは決定モデルによって生成された結果を説明する役割を担う。モデル非依存手法では、説明は通常、事後的に生成される。つまり、まずモデルの決定が生成され、次にその決定に対する説明が生成される。モデルに依存しない手法の注目すべき例としては、反事実的説明[14]、局所近似[16]、シャプレー値[15, 17]などが挙げられます。
</p><p>
<!--
It is worth noting that there exist explanation methods that 
may not be simply classified as either model-agnostic or 
model-intrinsic but actually in between agnostic and intrinsic
 because they can be implemented in either way. One 
such example is symbolic regression [24, 25]. Symbolic 
regression is a type of regression analysis to find a function \(f(x_1,x_2, \cdots,x_n)= 
y\) consisting of designated base functions
 that best fits the given dataset [24]. The base functions 
could be basic number operations such as addition, subtraction,
 multiplication, division, exponentiation, logarithm, 
etc., or trigonometric functions such as sine, cosine, tangent, 
etc., or any other designated base functions. Symbolic regression
 can be done in an intrinsic way by directly learning 
the symbolic function that best regresses the data, or can be 
done in an agnostic/post-hoc way by first learning a black-
box model such as neural network to fit the data and then 
using symbolic function to regress the black-box model. 
Symbolic regression is an NP-hard optimization problem 
[25, 26], but some effective and efficient heuristic methods
 have been developed, including genetic programming 
[27, 28], Bayesian methods [29], and continuous optimization
 methods [30, 31]. Besides, due to the high demand 
of solving symbolic regression problems in industry and 
research, many packages and tool-kits have been developed, 
such as Eureqa [32] which is based on genetic programming 
and TuringBot [33] which is based on simulated annealing. 
-->
注目すべきは、説明手法の中には、モデル非依存型とモデル固有型のいずれかに単純に分類できるものではなく、どちらにも実装できるため、非依存型と固有型の中間に位置するものが存在することです。その一例がシンボリック回帰 [24, 25] です。シンボリック回帰は、指定された基底関数から構成される関数 \(f(x_1,x_2, \cdots,x_n)= y\) を見つけ、与えられたデータセットに最も適合する回帰分析の一種です [24]。基底関数には、加算、減算、乗算、除算、べき乗、対数などの基本的な数値演算、正弦、余弦、正接などの三角関数、またはその他の指定された基底関数が含まれます。シンボリック回帰は、データに最適な回帰関数を直接学習するという本質的な方法で行うことも、ニューラルネットワークなどのブラックボックスモデルを最初に学習してデータに適合させ、その後シンボリック関数を用いてブラックボックスモデルを回帰するという不可知論的/事後的な方法で行うこともできます。
シンボリック回帰はNP困難な最適化問題ですが、遺伝的プログラミング[25, 26]、ベイズ法[29]、連続最適化法[30, 31]など、効果的かつ効率的なヒューリスティック手法が開発されています。さらに、産業界や研究においてシンボリック回帰問題を解く需要が高いため、遺伝的プログラミングに基づくEureqa[32]やシミュレーテッドアニーリングに基づくTuringBot[33]など、多くのパッケージやツールキットが開発されています。
</p><p>
<!--
<h3>2.2. AI for Science Discovery</h3>
-->
<h3>2.2. 科学的発見のためのAI</h3>
<p> 
<!--
AI for science discovery has been an important direction 
and is especially trending in recent years. For example, 
many efforts have been devoted to explore machine learning 
for drug discovery [34, 35, 36], material design [37], and 
chemistry or physics problems [38, 39, 40], though many of 
the works are conducted on synthesized data such as particle 
interaction rather than real observational data. A notable 
recent advance on AI for molecular biology is AlphaFold 
[41], which develops deep learning models to predict the 
folding structure of proteins. Most existing research on AI 
for science discovery focus on the AI utility instead of the 
AI explainability, i.e., they focus on developing advanced 
AI models for more accurate prediction, classification or 
regression of scientific data, but less effort is put on explaining
 the AI models or the AI-based discoveries. However, 
we believe that enabling AI to provide insightful explanations
 for science discovery is critically important, since it 
helps researchers to better understand the underlying mechanism
 of the AI models and better understand the scientific 
insight implied by the AI models, which is important to 
enhance human-beings’ understanding of the AI-discovered 
knowledge and advance science progress in the community. 
-->
科学的発見のためのAIは重要な方向性であり、近年特に注目されています。例えば、創薬[34, 35, 36]、材料設計[37]、化学または物理学の問題[38, 39, 40]のための機械学習の研究には多くの努力が払われてきましたが、多くの研究は実際の観測データではなく、粒子相互作用などの合成データに対して行われています。分子生物学のためのAIに関する最近の注目すべき進歩は、タンパク質の折り畳み構造を予測するための深層学習モデルを開発するAlphaFold[41]です。科学的発見のためのAIに関する既存の研究のほとんどは、AIの説明可能性ではなく、AIの有用性に焦点を当てています。つまり、科学的データのより正確な予測、分類、または回帰のための高度なAIモデルの開発に焦点を当てており、AIモデルやAIに基づく発見の説明にはあまり力を入れていません。しかし、AIが科学的発見に対して洞察に満ちた説明を提供できるようにすることは、研究者がAIモデルの根底にあるメカニズムをより深く理解し、AIモデルが示唆する科学的洞察をより深く理解するのに役立つため、極めて重要であると私たちは考えています。これは、AIによって発見された知識に対する人間の理解を深め、コミュニティにおける科学の進歩を促進するために重要です。
</p>
<!--
<h2>3. Research Setting and Background</h2> 
<h3>3.1. Research Data </h3>
-->
<h2>3. 研究設定と背景</h2>
<h3>3.1. 研究データ</h3>
<p>
<!--
Modern research facilities such as advanced telescopes have 
been able to collect very accurate and abundant data for 
planets orbiting the Sun. However, to fully restore the research
 situation at Kepler’s and Newton’s time, and to show 
how Kepler’s and Newton’s laws can be rediscovered by 
Explainable AI based on the (limited) data and knowledge at 
their time, we do not use any of the modern data of planetary 
motion. Instead, throughout the research, we only use the 
data and knowledge that were available to and used by Kepler,
 which was mostly collected by Tycho Brahe and partly 
collected or refined by Kepler 400 years ago. In particular, 
we use the observation data of Mars orbiting the Sun by 
Tycho and Kepler as summarized in Table 1, which comes 
from Kepler’s epoch-making book Astronomia Nova [6]. 
-->
高度な望遠鏡などの現代の研究施設は、太陽を周回する惑星に関する非常に正確で豊富なデータを収集することができます。しかし、ケプラーとニュートンの時代の研究状況を完全に復元し、当時の（限られた）データと知識に基づいて説明可能なAIによってケプラーとニュートンの法則がどのように再発見できるかを示すために、私たちは惑星運動に関する現代のデータを一切使用しません。その代わりに、研究全体を通して、ケプラーが利用可能で使用したデータと知識のみを使用します。これらのデータと知識は、主にティコ・ブラーエによって収集され、部分的に400年前にケプラーによって収集または洗練されました。特に、表1にまとめられているように、ケプラーの画期的な著書「新天文学」[6]に掲載されている、ティコとケプラーによる太陽を周回する火星の観測データを使用します。
</p><p>
<!--
In Table 1, the date is written in old style used by Kepler<sup>2</sup>. 
To obtain Gregorian style dates, we just need to add 10 days 
on top of Kepler’s dates [6]. The “Mars’ Angular Position” 
from Sun is the Mars’ longitudes in heliocentric ecliptic 
coordinates computed by Kepler. The “Sun-Mars Distance” 
is in units of Astronomical Unit (AU). A note here is that 
at Kepler’s time, humans were still unable to measure the 
distance between planets in miles [44, 45]. Instead, they 
recorded distances in the ratio of Sun-Earth distance, and set 
the average of Sun-Earth distance as 100, 
000, similar to the 
definition of AU. Thus, we use AU as the unit<sup>3</sup>. “Difference” 
is the difference between the computed and the observed 
Mars’ positions in geocentric ecliptic longitudes. Since the 
average measurement error of Tycho’s observations is just 
several arc-minutes and the largest difference is less than 
six arc-minutes, thus, we take the data as the top-accurate 
data at Tycho’s and Kepler’s time. 
-->
表1(付録)では、日付はケプラー<sup>2</sup>が用いた古い形式で表記されています。グレゴリオ暦の日付を得るには、ケプラーの日付[6]に10日を加えるだけです。太陽からの「火星の角位置」は、ケプラーによって計算された太陽中心黄道座標における火星の経度です。「太陽-火星距離」は、天文単位（AU）を単位としています。ここで注目すべき点は、ケプラーの時代、人類はまだ惑星間の距離をマイルで測定できなかったことです[44, 45]。代わりに、人類は太陽-地球距離の比で距離を記録し、AUの定義と同様に、太陽-地球距離の平均を100,000としました。したがって、ここではAUを単位として使用します<sup>3</sup>。 「差」とは、地心黄経における火星の位置の計算値と観測値の差です。ティコの観測値の平均測定誤差はわずか数分角で、最大差は6分角未満であるため、このデータはティコとケプラーの観測時点における最高精度のデータとみなします。
</p><p class="margin-large">
<sup>2</sup> 
<!--
This old style is based on Julian calendar which was used by 
Kepler. To fix the calendar drift of spring equinox due to the excess 
leap days introduced by the Julian algorithm, a calendar reform 
was introduced in 1582 which slightly adjusted the number of days 
per year and advanced the date by 10 days: October 4, 1582 was 
followed by October 15, 1582 [42, 43], leading to what is now 
known as the Gregorian calendar. 
-->
この古い暦は、ケプラーが用いたユリウス暦に基づいています。ユリウス暦のアルゴリズムによって生じた閏日の増加による春分の日のずれを修正するため、1582年に暦改正が導入され、年間の日数がわずかに調整され、日付が10日早まりました。1582年10月4日は、1582年10月15日と変更されました[42, 43]。これが、現在グレゴリオ暦として知られる暦の始まりです。
<br><br>

<sup>3</sup>
<!--
 Actually, computing Mars’ position and distance relative to 
Sun is one of Kepler’s most genius innovations. He smartly used 
the fact that the Mars’ period is 687 days, and thus should appear 
at the same position in universe once every 687 days. This makes 
it possible to compute the Sun-Mars distance and direction relative 
to the Sun-Earth distance (which is 1 AU) based on trigonometric 
calculations [6]. 
-->
実際、太陽に対する火星の位置と距離を計算することは、ケプラーの最も天才的な発明の一つです。彼は、火星の周期が687日であり、したがって687日ごとに宇宙の同じ位置に現れるという事実を巧みに利用しました。これにより、三角法に基づいて、太陽と地球の距離（1AU）に対する太陽と火星の距離と方向を計算することが可能になりました[6]。
</p>
<!--
<h3>3.2. AI and Explainable AI Models </h3>
-->
<h3>3.2. AI と説明可能な AI モデル </h3>
<p>
<!--
In this research, we aim to show what AI is able and unable 
to do in science discovery. In particular, we will highlight 
that learning black-box models could indeed give us accurate
 predictions of the physical phenomena, but may not help 
in advancing human understandings of the nature and universe.
 To really transform data into knowledge rather than 
just prediction tools, we not only need black-box prediction 
models learned from data, but also need explanation models 
that can reveal the physical insights underlying the data and 
model in human understandable ways, so that human beings 
can keep up with the pace of AI’s discoveries. 
-->
本研究では、科学的発見においてAIが何ができ、何ができないかを明らかにすることを目指しています。特に、ブラックボックスモデルの学習は物理現象の正確な予測を可能にするものの、自然や宇宙に対する人間の理解を深める上では役立たない可能性があることを明らかにします。データを単なる予測ツールではなく、真に知識へと変換するには、データから学習したブラックボックス予測モデルだけでなく、データとモデルの根底にある物理的な洞察を人間が理解できる方法で明らかにできる説明モデルも必要です。そうすることで、人間はAIの発見のペースに追いつくことができるのです。
</p><p>
<!--
Our experiments involve two types of models. One is 
a black-box model implemented as neural network (NN) 
which is learned from observational data. The black-box 
model is responsible for making accurate predictions such 
as predicting the position of Mars at certain time, as well 
as data augmentation to turn limited observational data into 
large scale data for science discovery. The black-box model 
would have already been very helpful to human-beings, for 
example, it may help to develop calendars and to guide 
agricultural production by making accurate predictions of 
the future, but its black-box nature makes it difficult for humans
 to understand the underlying physical mechanism of 
such predictions. As a result, we involve the second type of 
model for explanation, which is implemented based on symbolic
 regression that transforms the black-box model into a 
symbolic function to express the interpretable physical rules. 
The symbolic regression process also discovers meaningful 
physical variables to inspire insightful understandings of the 
underlying physical mechanism behind the data. 
-->
私たちの実験では、2種類のモデルを用います。1つは、観測データから学習するニューラルネットワーク（NN）として実装されたブラックボックスモデルです。このブラックボックスモデルは、特定の時刻における火星の位置を予測するなどの正確な予測を行うだけでなく、限られた観測データを科学的発見のための大規模データに変換するデータ拡張も担います。ブラックボックスモデルは、例えば、未来を正確に予測することで暦を作成したり、農業生産を導いたりするなど、人類にとって既に非常に役立っていますが、ブラックボックスという性質上、人間がそのような予測の背後にある物理的メカニズムを理解することは困難です。そのため、私たちは説明のために、ブラックボックスモデルを解釈可能な物理法則を表現する記号関数に変換する記号回帰に基づいて実装された2つ目のモデルを用います。シンボリック回帰プロセスは、データの背後にある物理的なメカニズムに対する洞察に満ちた理解を促す、意味のある物理変数も発見します。
</p><p>
<!--
For the implementation details, we use three layers of multilayer
 perceptron (MLP) as the NN model with the hidden 
size as 100. As a black-box, we will not change the internal 
structure of NN throughout the experiments, i.e., we will not 
purposely design unique NN structures to fit different data, 
instead, we always use the same and simple three-layer MLP 
as the black-box and we only designate the input and output 
data for the black-box to learn different prediction models. 
We use TuringBot [33] for model explanation based on symbolic
 regression, which is a widely used symbolic regression 
algorithm based on simulated annealing and performed well 
on a variety of physics-inspired learning problems [46]. 
-->
実装の詳細については、NNモデルとして3層の多層パーセプトロン（MLP）を使用し、隠れ層のサイズは100としています。NNはブラックボックスであるため、実験を通してNNの内部構造を変更しません。つまり、異なるデータに適合するために意図的に独自のNN構造を設計することはありません。代わりに、ブラックボックスとしては常に同じシンプルな3層MLPを使用し、ブラックボックスが異なる予測モデルを学習するための入力データと出力データのみを指定します。モデルの説明には、シミュレーテッドアニーリングに基づく広く使用されているシンボリック回帰アルゴリズムであるTuringBot [33]を使用します。このアルゴリズムは、物理学に着想を得たさまざまな学習問題で優れたパフォーマンスを発揮しています[46]。
</p>
<!--
<h2>4. Rediscover Kepler’s Laws based on Explainable AI </h2>
-->
<h2>4. 説明可能なAIに基づくケプラーの法則の再発見</h2>
<p>
<!--
Let us first review the process of Kepler’s discovery of his 
first law. In Kepler’s time, there were three models of planetary
 motion: the Ptolemaic, Copernican and Tychonic systems.
 In his book Astronomia Nova [6], Kepler mentioned 
that these three systems all had high prediction accuracy in 
the near term, but diverged and failed to fit historical and 
future observations in the long term. The first step of his research
 was to check the accuracy of the observation data. If 
a theory is based on inaccurate observations, then the theory 
could be misleading. Therefore, Kepler went through the 
calculation with at least seventy rounds of verification, at a 
very great loss of time [47]. Nowadays, data collection and 
inspection are still important and necessary but are relatively 
mature, and most part of them can be done automatically 
with minimal manual intervention. 
-->
まず、ケプラーが第一法則を発見した過程を振り返ってみましょう。ケプラーの時代には、惑星の運動にはプトレマイオス理論、コペルニクス理論、ティコ理論の3つのモデルがありました。ケプラーは著書『新天文学』[6]の中で、これら3つのシステムはいずれも短期的には高い予測精度を示すものの、長期的には過去の観測結果や将来の観測結果と乖離し、適合しないと述べています。彼の研究の第一歩は、観測データの精度を確認することでした。理論が不正確な観測に基づいている場合、その理論は誤解を招く可能性があります。そのため、ケプラーは少なくとも70回の検証を経た計算を行い、多大な時間を浪費しました[47]。今日でも、データの収集と検証は依然として重要かつ必要ですが、比較的成熟しており、その大部分は最小限の手動介入で自動的に行うことができます。
</p><p>
<!--
After multiple rounds of recalculation, Kepler chose to believe
 the observation data from Tycho. However, he was not 
satisfied with the measurement error of the existing planetary
 motion models [48], which led him to propose a new 
hypothesis that the orbit of a planet is an ellipse with the 
Sun at one of the two foci, which is known as Kepler’s first 
law of planetary motion, and then he used the observation 
data to verify his hypothesis. This process practiced the 
traditional Hypothetico-Deductive paradigm of science discovery,
 where a hypothesis is first manually proposed and 
then experiments are conducted to verify or falsify the hypothesis.
 In the following, we will show the hypothesis-free 
science discovery process based on (Explainable) AI which 
directly starts from data to rediscover the Kepler’s laws. 
-->
ケプラーは複数回の再計算を経て、ティコの観測データを信じることを選択した。しかし、既存の惑星運動モデル[48]の測定誤差に満足せず、惑星の軌道は太陽を2つの焦点の1つとする楕円であるという新しい仮説を提唱した。これはケプラーの惑星運動の第一法則として知られ、彼は観測データを用いてこの仮説を検証した。このプロセスは、科学的発見における伝統的な仮説演繹的パラダイムを実践したもので、仮説は最初に手動で提案され、次に仮説を検証または反証するための実験が実行される。以下では、データから直接ケプラーの法則を再発見する、（説明可能な）AIに基づく仮説フリーの科学的発見プロセスを示す。
</p>
<!--
<h3>4.1. Black-box Model for Prediction and Data Augmentation </h3>
-->
<h3>4.1. 予測とデータ拡張のためのブラックボックスモデル</h3>
<p>
<!--
First, we use the neural network model as a black-box model 
for data fitting, prediction, and data augmentation. An advantage
 of deep neural network is its ability to smoothly fit 
the data so as to augment the small amount of observation 
data into large amount of data samples to facilitate AI-based 
science discovery. We plot the observation data points in 
Table 1 as Figure 3. Since the amount of original observa
tion data is small, we only use three samples for validation 
and use the remaining 25 samples for training. We set the 
number of training epochs as 200,000 for \(NN\)-based data 
fitting to learn a regression function \(r=NN(\theta)\), where \(NN\) 
is the learned neural network function, \(r\) 
is the Sun-Mars 
distance and \(θ\) 
is the Mars’ angular position relative to the 
Sun (column 2 and column 3 of Table 1). The final mean 
square loss (MSE) of the \(NN\) on the training data and validation
 data is \(4\times 10^{-11}\) and \(7\times 10^{-8}\), respectively, which 
means the neural network function is able to provide quite 
accurate predictions. For data augmentation, we uniformly 
sample 1,000 random numbers between 0 and 1 as input to 
the \(NN\), which is in the same input number range of the \(NN\) 
model. We then use the sampled inputs and the corresponding
 outputs of the NN model to generate augmented data 
samples and to approximate the function. The augmented 
data samples are shown as the Figure 4. 
-->
まず、ニューラルネットワークモデルをブラックボックスモデルとして用いて、データのフィッティング、予測、データ拡張を行います。ディープニューラルネットワークの利点は、少量の観測データを大量のデータサンプルに拡張し、AI による科学的発見を促進するために、データをスムーズにフィッティングできることです。表1の観測データポイントを図3にプロットします。元の観測データの量が少ないため、検証には3つのサンプルのみを使用し、残りの25のサンプルを学習に使用します。 \(NN\) ベースのデータフィッティングを用いて回帰関数 \(r=NN(θ)\) を学習するためのトレーニングエポック数を200,000に設定しました。ここで、NNは学習済みのニューラルネットワーク関数、rは太陽と火星間の距離、\(θ\) は太陽に対する火星の角度位置です（表1の2列目と3列目）。トレーニングデータと検証データにおけるNNの最終的な平均二乗損失（MSE）はそれぞれ \(4×10^{-11}\) と \(7×10^{-8}\) であり、ニューラルネットワーク関数が非常に正確な予測を提供できることを意味します。データ拡張のために、\(NN\)モデルの入力範囲と同じ範囲にある0から1までの乱数を 1,000 個均一にサンプリングし、\(NN\) モデルに入力する。次に、サンプリングした入力と対応する \(NN\) モデルの出力を用いて拡張データサンプルを生成し、関数を近似する。拡張データサンプルは図4に示している。
</p>
<!--
<h3>4.2. White-box Model for Explanation </h3>
-->
<h3>4.2. 説明のためのホワイトボックスモデル</h3>
<p>
<!--
Our next step is to interpret the neural network function 
\(r = NN(\theta)\) into a human understandable symbolic function 
based on symbolic regression so as to gain physical insights 
from the black-box model. From Figure 4, we can see 
that the NN model has a good ability of smooth function 
approximation and we can see the periodicity of data from 
the figure. However, even though our 3-layer MLP model is 
very simple from the AI perspective, it is still a very complex 
non-linear nested matrix multiplication formula, which is 
difficult to understand its physical insights. This is why we 
use symbolic regression as Explainable AI to transform the 
black-box model into simple and intuitive physical rules. 
In particular, we hope to turn the neural network function 
\(r=NN(\theta)\) into an explicit symbolic function \(r=f(\theta)\). We 
use the cosine function (cos) due to periodicity alongside 
with three other basic operations for symbolic regression: 
addition (+), multiplication (\(\cdot\)) and division (/) (subtraction 
can be expressed by adding a negative sign). The symbolic 
regression results are shown in Table 2. 
-->
次のステップは、シンボリック回帰に基づいてニューラルネットワーク関数\(r = NN(\theta)\)を人間が理解できるシンボリック関数に変換し、ブラックボックスモデルから物理的な洞察を得ることです。図4から、NNモデルは滑らかな関数近似の能力に優れており、データの周期性も確認できます。しかし、この3層MLPモデルはAIの観点からは非常にシンプルですが、依然として非常に複雑な非線形ネストされた行列乗算式であり、その物理的な洞察を理解するのは困難です。そのため、Explainable AIとしてシンボリック回帰を用いて、ブラックボックスモデルをシンプルで直感的な物理ルールに変換します。特に、ニューラルネットワーク関数\(r=NN(\theta)\)を明示的なシンボリック関数\(r=f(\theta)\)に変換したいと考えています。シンボリック回帰では、周期性を考慮し、余弦関数（cos）を、加算（+）、乗算（\(\cdot\)）、除算（/）（減算は負の符号を付加することで表すことができます）という3つの基本演算とともに使用します。シンボリック回帰の結果を表2に示します。
</p><p>
<!--
In Table 2, the error means the root mean square error
 (RMSE) between the output of the black-box model 
and the output of the white-box model, i.e., \(RMSE =\sqrt{\sum_\theta 
(NN(\theta)−f(\theta))^2}\). The size stands for the complexity 
of the generated function, which is calculated by adding up 
the size of each base function used by the generated function,
 and the size of each base function is shown in Table 
3. The symbolic regression process selects the simple and 
effective functions, i.e., if a simpler (smaller size) function 
is more accurate (smaller error) than a complex (larger size) 
function, then the complex function will be eliminated from 
the results. We plot the relation between the function size 
and the negative log error in Figure 5, which shows that 
the size 14 candidate function has the sharpest increase in 
accuracy (in terms of negative log error) while maintaining 
a smaller size, which indicates that this function has the best 
chance to achieve a good balance between accuracy and 
complexity to reveal the physical rule behind the data [30]. 
We write down and simplify this function as Eq.(1): 
-->
表2において、誤差はブラックボックスモデルの出力とホワイトボックスモデルの出力との間の二乗平均平方根誤差（RMSE）を意味し、\(RMSE =\sqrt{\sum_\theta
(NN(\theta)−f(\theta))^2}\)となります。サイズは生成された関数の複雑さを表し、生成された関数で使用される各基本関数のサイズを合計することで計算されます。各基本関数のサイズは表3に示されています。シンボリック回帰プロセスでは、単純で効果的な関数が選択されます。つまり、より単純な（サイズの小さい）関数が複雑な（サイズの大きい）関数よりも正確（誤差が小さい）である場合、複雑な関数は結果から除外されます。図5は関数のサイズと負の対数誤差の関係をプロットしたものです。サイズ14の候補関数は、サイズを小さく保ちながら、精度（負の対数誤差の観点から）が最も急激に向上していることがわかります。これは、この関数が、データの背後にある物理的法則を明らかにするために、精度と複雑さの間の良好なバランスを達成する可能性が最も高いことを示しています[30]。
この関数を式(1)のように書き直して簡略化します。

\[
\begin{align}
r=f(\theta) &= \frac{1.51977}{ 1.00625+0.0932972·\cos(θ+0.544536)} \\
\\ 
&=\frac{1.51033}{1+0.0927177·\cos(θ+0.544536)} 
\tag{1}
\end{align}
\] 

<!--
If we have basic knowledge of elliptic equations, we know 
Eq.(1) implies a standard elliptical orbit, which can be represented
 as the following function in polar coordinates: 
-->
楕円方程式の基礎知識があれば、式(1)は標準的な楕円軌道を意味し、それは極座標で次の関数として表されることがわかります。

\[
r=f(\theta)=\frac{l}{1+ε·\cos(\theta)}  \tag{2}
\] 

<!--
where \(r\) stands for the distance between the Sun and Mars, 
and \(θ\) is Mars’ longitude in heliocentric ecliptic coordinate. 
This clearly shows that the orbit of Mars is an ellipse with 
Sun at the focus, leading to Kepler’s first law. We will 
further interpret the meaning of the numbers in Eq.(1) in the 
following subsection. 
-->
ここで、\(r\)は太陽と火星の間の距離、\(θ\)は太陽中心の黄道座標における火星の経度です。
これは、火星の軌道が太陽を焦点とする楕円であることを明確に示しており、ケプラーの第一法則につながります。次の節では、式(1)の数値の意味をさらに解釈します。
</p>
<!--
<h3>4.3. Physical Interpretation of the Results</h3>
-->
<h3>4.3. 結果の物理的な解釈</h3>
<p>
<!--
Besides the elliptical orbit, we can obtain more insightful information
 from Eq.(1). In Kepler’s book Astronomia Nova 

[6] (Chapter 41, Page 321), he calculated the eccentricity 
of Mars as 0.09264 
based on complex and meticulously 
designed geometric calculations. By comparing the two 
equations, Eq.(1) and Eq.(2), we can directly learn that the 
Mars eccentricity \(ε=0.0927177\), which tends to be consistent
 with Kepler’s result with relative error less than 0:1%. If 
we compare our Explainable AI-based result with the Mars 
eccentricity from modern science observations (as shown in 
Table 4), we can see the relative error is about 0:7%, which 
is larger than that comparing with Kepler’s result, most 
likely due to the observational errors in Tycho and Kepler’s 
data that was collected 400 years ago, but the relative error 
is still small and the result is reasonable because we used 
the same data as Kepler did, and thus no surprisingly our 
result would be closer to Kepler’s. 
-->
楕円軌道に加えて、式(1)からより深い洞察が得られる。ケプラーの著書『新天文学』[6]（第41章、321ページ）では、複雑かつ綿密に設計された幾何学的計算に基づき、火星の離心率が0.09264と算出されている。式(1)と式(2)の2つの式を比較することで、火星の離心率が\(ε=0.0927177\)であることが直接わかる。これは、ケプラーの結果と相対誤差0.1%未満で一致する傾向がある。 Explainable AI ベースの結果を、現代科学観測による火星の離心率（表 4 参照）と比較すると、相対誤差は約 0.7% であり、ケプラーの結果と比較した場合よりも大きいことがわかります。これは、400 年前に収集されたティコとケプラーのデータの観測誤差によるものと考えられます。しかし、相対誤差は依然として小さく、ケプラーと同じデータを使用しているため、結果は妥当です。したがって、私たちの結果がケプラーの結果に近くなるのも当然です。
</p><p>
<!--
Another difference between Eq.(1) and the standard oval 
equation is the declination in the cosine function. For standard
 oval equation, \(r_{min}= f(θ=0)\), while in our equation, \(r_{min}
=f[θ=-0.544536(about −31.2^\circ)]\). This is consistent
 with and can be explained by the series of closest Mars 
Oppositions in history. Mars Oppositions are phenomena 
when Earth passes in between Sun and Mars. Table 5 (from 
[49]) shows all of the closest Mars Oppositions with distance
 between Mars and Earth less than 0:375 
AU from the 
1500s (Kepler’s time) to nowadays. We see that all of these 
closest Mars Oppositions happen around August, which is 
about one month before the fall equinox (around September 
23)—the time when Sun reaches the celestial longitude of \(180^\circ\), i.e., \(\theta_{Earth}=0\). Since the orbit of Earth is very close 
to a circle (scientists at Kepler’s time knew this according 
to their observations [6][p.271-272]), therefore, the distance 
between Mars and Earth on Mars Oppositions is mainly 
decided by the position of Mars, and Mars is most likely at 
perihelion around August according to the historical observations
 of closest Mars Oppositions (e.g., Table 5). This is 
consistent with the results shown by Explainable-AI model, 
since Eq.(1) also shows August as the Mars perihelion when \(\theta_{Earth}
=\theta_{Mars}=-0.544536\approx -31.2^\circ\), which is about 
\(\frac{31.2}{360}×365≈32\) days ahead of the fall equinox, i.e., in
August. In the following, we will also show how Kepler’s 
other laws can be discovered in the process of pursuing for 
Newton’s laws based on Explainable AI. 
-->
式(1)と標準的な楕円方程式とのもう一つの違いは、余弦関数の偏角です。標準的な楕円方程式では\(r_{min}= f(θ=0)\)ですが、私たちの式では\(r_{min}=f[θ=-0.544536(約-31.2^\circ)]\)です。これは、歴史上最も接近した火星の衝の系列と一致しており、それによって説明できます。火星の衝とは、地球が太陽と火星の間を通過する現象です。表5（[49]より）は、1500年代（ケプラーの時代）から現在に至るまで、火星と地球の距離が0.375 AU未満であったすべての最も近い火星の衝を示しています。これらの火星の最接近はすべて8月頃に発生しており、これは秋分（9月23日頃）の約1か月前、つまり太陽が天の黄経 \(180^\circ\)、つまり \(\theta_{Earth}=0\) に達する時です。地球の軌道は円に非常に近いため（ケプラーの時代の科学者たちは観測によってこれを知っていました [6][p.271-272]）、火星の接近時における火星と地球の距離は主に火星の位置によって決まり、火星の最接近に関する過去の観測結果（例えば表5）によれば、火星は8月頃に近日点にある可能性が最も高いと考えられます。これはExplainable-AIモデルによって示された結果と一致しています。なぜなら、式(1)は、\(\theta_{地球}=\theta_{火星}=-0.544536\approx -31.2^\circ\)のとき、8月が火星の近日点であるとも示しており、これは秋分点の約\(\frac{31.2}{360}×365≈32\)日前、つまり8月だからです。以下では、Explainable-AIに基づいてニュートンの法則を追求する過程で、ケプラーの他の法則がどのように発見されるかについても示します。
</p>
<!--
<h2>5. Rediscover Newton’s Laws based on Explainable AI</h2>
-->
<h2>5. 説明可能なAIに基づくニュートンの法則の再発見</h2>
<p>
<!--
We have shown how Kepler’s first law and certain attributes 
of Mars can be extracted by Explainable AI from data. But 
one may not be satisfied with this, because one may naturally
 want to know why Mars orbits in oval and what “power” 
drives this elliptical orbit. In history, with limited information
 and tools, Kepler thought that the variable distance 
between Sun and Mars was due to the magnetic attraction 
and repulsion of Mars by Sun [50], which was inspired from 
the proposal that Earth is a magnet by English physician 
and physicist William Gilbert in his groundbreaking book 
De Magnete published in early 1600s [51]. Though we now 
know that this explanation is not the true reason, we cannot 
help imaging whether Explainable AI can help to answer 
this question based on ancient data that Kepler used. 
-->
ケプラーの第一法則と火星の特定の特性を、Explainable AIによってデータから抽出できることを示しました。しかし、これでは満足できないかもしれません。なぜなら、火星がなぜ楕円軌道を描いて公転するのか、そしてこの楕円軌道を駆動する「力」は何なのかを知りたいと思うのは当然だからです。歴史的に、限られた情報とツールのもと、ケプラーは太陽と火星の距離が変動するのは、太陽による火星の磁気的な引力と反発によるものだと考えました[50]。これは、イギリスの医師で物理学者のウィリアム・ギルバートが1600年代初頭に出版した画期的な著書『磁石論』の中で、地球は磁石であるという提唱に触発されたものです[51]。現在ではこの説明が真の理由ではないことが分かっていますが、ケプラーが使用した古代のデータに基づいて、Explainable AIがこの疑問に答えるのに役立つかどうかは想像に難くありません。
</p>
<!--
<h3>5.1. Black-box Model for Time-Sensitive Prediction and Data Augmentation </h3>
-->
<h3>5.1. 時間依存予測とデータ拡張のためのブラックボックスモデル</h3>
<p>
<!--
Eq.(1) describes the position of Mars relative to Sun as 
\(r=f(\theta)\). An intuitive and interesting idea is to construct 
the relationship between the Mars position and time, since 
we have not used the time information in Table 1. More 
specifically, we naturally hope to have the \(\theta-as-t\) 
relationship 
\(θ= g(t)\), so that combined with the \(r=f(\theta)\) 
function, we 
will be able to predict the Mars position for any given time in 
the future, which was an important problem for astronomy 
and calendar development at Kepler and Newton’s time, 
and making accurate future predictions is also important to 
verify if a theory is correct. Kepler and his contemporary 
scientists knew that the orbital period of Mars is about 687 
days, and the time span of the data in Table 1 is much 
longer than that, so we shift all data points into one orbital 
period and normalize the time to the range of [0,1] for 
better visualization. We show the normalized time \(t\) 
and Mars’ longitude \(θ\) in Figure 6. We can see that the \(\theta-t\) 
relationship is close to linear but with certain non-linearity, 
which implies small changes of Mars’ speed when orbiting 
the Sun. 
-->
式(1)は、太陽に対する火星の位置を\(r=f(\theta)\)と表しています。表1では時間情報を使用していないため、火星の位置と時間の関係を構築することは直感的で興味深いアイデアです。より具体的には、\(\theta-as-t\)関係\(θ= g(t)\)が得られることを期待します。したがって、\(r=f(\theta)\)関数と組み合わせることで、将来の任意の時点における火星の位置を予測できるようになります。これは、ケプラーとニュートンの時代における天文学と暦の発展にとって重要な問題でした。また、正確な未来予測を行うことは、理論が正しいかどうかを検証するためにも重要です。ケプラーと同時代の科学者たちは、火星の公転周期が約687日であることを知っていました。表1のデータの期間はそれよりもはるかに長いため、すべてのデータ点を1つの公転周期にシフトし、時間を[0,1]の範囲に正規化して視覚化しやすくしました。正規化された時間\(t\)と火星の経度\(θ\)を図6に示します。\(\theta-t\)の関係は線形に近いものの、ある程度の非線形性があり、これは火星が太陽を周回する際に速度がわずかに変化することを示唆しています。
</p><p>
<!--
Similar to previous experiments, we first feed the data to 
a neural network model for black-box prediction and data 
augmentation. We use a simple three-layer multi-layer perceptron
 (MLP) network to train the predictor \(θ=NN(t)\), 
where the input is the normalized time \(t\) 
and the output is 
Mars’ longitude \(θ\) 
in radian. After 200,000 epochs of training,
 the mean square loss (MSE) on training and validation 
data is \(7\times 10^{-8}\) and \(1.5\times 10^{-5}\), respectively. After training, 
we uniformly sample \(2T\) points between 0 and 1 as input 
for data augmentation, where \(T=687\)  
is the orbital period 
of Mars, and we plot the augmented data points based on 
the trained neural predictor \(θ=NN(t)\) in Figure 7. 
-->
以前の実験と同様に、まずデータをニューラルネットワークモデルに入力し、ブラックボックス予測とデータ拡張を行います。予測器 \(θ=NN(t)\) を学習させるために、単純な3層の多層パーセプトロン (MLP) ネットワークを使用します。ここで、入力は正規化された時間 \(t\)、出力は火星の経度 \(θ\) (ラジアン) です。200,000 エポックの学習後、学習データと検証データの平均二乗損失 (MSE) はそれぞれ \(7\times 10^{-8}\) と \(1.5\times 10^{-5}\) です。トレーニング後、データ拡張の入力として0と1の間の\(2T\)点を均一にサンプリングします。ここで、\(T=687\)は火星の公転周期です。図7に、トレーニング済みのニューラル予測器\(θ=NN(t)\)に基づいて拡張されたデータポイントをプロットします。
</p><p>
<!--
Actually, the above simple experiment which adopts machine
 learning to learn a black-box neural predictor \(θ=NN(t)\)  
implies a significant role of machine learning (especially
 deep learning based on neural networks) in science 
discovery. Nowadays, based on advanced mathematical 
tools and deeper understandings of planetary motion, we 
are able to know that the relationship between \(t\) 
and \(θ\) 
can 
be expressed as the following Eq.(3) [52], 
-->
実際、ブラックボックスニューラル予測器 \(θ=NN(t)\) を学習するために機械学習を採用した上記の単純な実験は、科学的発見における機械学習（特にニューラルネットワークに基づく深層学習）の重要な役割を示唆しています。今日では、高度な数学的ツールと惑星運動のより深い理解に基づいて、\(t\) と \(θ\) の関係は次の式(3) で表せることが分かっています [52]。

\[
\frac{2\pi}{T}t=2\tan^{-1}\left(\sqrt{\frac{1-\epsilon}{1+\epsilon}}\tan\left(\frac{\theta}{2}\right)\right)-
\frac{\epsilon\sqrt{1-\epsilon^2}\sin(\theta)}{1+\epsilon\cos(\theta)}
\tag{3}
\]

<!--
where \(T\) and \(\epsilon\) are constant parameters of Mars. This means 
that we can express \(t\) 
as a function of \(\theta\), i.e., \(t=h(\theta)\), 
however, we can hardly find a function to express \(θ\) 
as \(t\), i.e., \(θ=g(t)\), since Eq.(3) is a transcendental equation. As a 
result, suppose we did not know Eq.(3), then we possibly 
will spend efforts trying to find the \(\theta-t\) 
relationship, however, 
any attempt to find a \(\theta-t\) function \(θ=g(t)\) 
would fail no 
matter based on manual efforts or automatic tools such as 
symbolic regression, which incurs a waste of time. Nevertheless,
 sometimes we do need a \(\theta-as-t\) 
function because 
we may want to analyze some important features of Mars 
motion such as the angular velocity and acceleration. Deep 
learning and neural network models provide a solution to 
this problem, because according to the universal approximation
 theorem [53, 54, 55], neural networks—when the 
structure and weights are properly designed and learned— 
are able to approximate a wide scope of functions based 
on training data. As a result, even though the functional 
form of \(θ=g(t)\)  
is difficult (if at all possible) to find, we 
can still learn a fairly good \(\theta-t\) function as a neural network 
\(θ=NN(t)\), and because \(NN\) is differentiable, we can conduct
 mathematical analysis for the \(\theta-t\) 
relationship, such as angular velocity \(ω=\frac{dNN(t)}{dt}\) and angular acceleration 
\(a=\frac{d^2NN(t)}{dt^2}\) . This will enable us to discover the possible 
physical relationship between many physical variables that 
are otherwise difficult to calculate. We will further illustrate 
on this point in the following subsections. 
-->
ここで、\(T\)と\(\epsilon\)は火星の定数パラメータです。これは、\(t\)を\(\theta\)の関数として、つまり\(t=h(\theta)\)と表すことができることを意味します。しかし、式(3)は超越方程式であるため、\(θ\)を\(t\)として、つまり\(θ=g(t)\)と表す関数を見つけることは困難です。その結果、式(3)を知らないと仮定すると、\(\theta-t\)関係を見つけるのに労力を費やすことになるでしょう。しかし、\(\theta-t\)関数\(θ=g(t)\)を見つけようとする試みは、手作業であれ、記号回帰などの自動ツールであれ失敗し、時間の無駄になります。しかしながら、火星の運動の重要な特徴、例えば角速度や加速度などを解析したい場合、\(\theta-as-t\)関数が必要になることもあります。ディープラーニングとニューラルネットワークモデルは、この問題の解決策を提供します。普遍近似定理[53, 54, 55]によれば、ニューラルネットワークは、構造と重みが適切に設計され学習された場合、学習データに基づいて広範囲の関数を近似できるためです。その結果、\(θ=g(t)\) の関数形を見つけるのは（そもそも可能だとしても）困難であるにもかかわらず、ニューラルネットワークとしてかなり良好な \(\theta-t\) 関数を学習することができ、\(θ=NN(t)\) は微分可能であるため、角速度 \(ω=\frac{dNN(t)}{dt}\) や角加速度 \(a=\frac{d^2NN(t)}{dt^2}\) などの \(\theta-t\) 関係について数学的解析を行うことができます。これにより、他の方法では計算が困難な多くの物理変数間の物理的な関係を発見することが可能になります。この点については、以下の節でさらに詳しく説明します。
</p>
<!--
<h3>5.2. White-box Model for Explanation </h3>
-->
<h3>5.2. 説明のためのホワイトボックスモデル</h3>
<p>
<!--
At Kepler’s time, calculus has not been invented yet, but 
scientists have already established the concept of velocity. 
As a result, we should not use differentials to derive the 
angular velocity, but we can calculate the angular velocity 
\(ω\) 
by calculating the change of angle \(θ\) 
within a certain time 
interval based on the black-box neural network prediction 
model \(θ=NN(t)\)  
that we have learned in the above subsection.
 To show the generalization ability of the neural 
network model, we randomly sample the same number (28) 
of data points from \(θ=NN(t)\)  
by using different values 
between 0.1 and 0.9 as the time in one orbital period of 
Mars, denoted as \(t_i (i=1, 2,\cdots, 28)\). For each \(t_i\), we use 
the neural model to obtain the angle of Mars \(\theta_i = NN(t_i)\). 
Then, we set the time interval \(\delta_t = \frac{1}{32}\) day (about 45 minutes), and for each time \(t_i\), we calculate the corresponding angular velocity \(\omega_i
=\frac{NN(t_i+\delta_t)-NN(t_i-\delta_t)}{2\delta_t}\). Besides, based 
on Eq.(1), we can also obtain the corresponding Sun-Mars 
distance at time \(t_i\) which is \(r_i=f(\theta_i)=f(NN(t_i))\). 
-->
ケプラーの時代には微積分はまだ発明されていませんでしたが、科学者たちはすでに速度の概念を確立していました。
そのため、角速度を導くために微分を用いるべきではありませんが、前の節で学んだブラックボックス型ニューラルネットワーク予測モデル\(θ=NN(t)\)に基づいて、ある時間間隔内の角度\(θ\)の変化を計算することで、角速度\(ω\)を計算できます。
ニューラルネットワークモデルの一般化能力を示すために、火星の1公転周期である0.1から0.9までの異なる値（\(t_i (i=1, 2, 3, 28)\)と表記）を用いて、\(θ=NN(t)\)から同じ数（28）のデータ点をランダムにサンプリングします。各 \(t_i\) について、ニューラルモデルを用いて火星の角度 \(\theta_i = NN(t_i)\) を取得します。
次に、時間間隔 \(\delta_t = \frac{1}{32}\) 日（約 45 分）を設定し、各時刻 \(t_i\) について、対応する角速度 \(\omega_i
=\frac{NN(t_i+\delta_t)-NN(t_i-\delta_t)}{2\delta_t}\) を計算します。さらに、式 (1) に基づいて、時刻 \(t_i\) における対応する太陽-火星距離 \(r_i=f(\theta_i)=f(NN(t_i))\) も取得できます。
</p><p>
<!--
Now, with the augmented data points \((t_i, \theta_i, r_i, \omega_i)\), we 
would like to find the interpretable symbolic physical relationship
 among some or all of these physical variables. 
Though nowadays even a high school student knows their 
relationship, we should assume that we have no knowledge 
about the underlying physical rule when using Explainable 
AI such as symbolic regression to find their relationship, because
 to demonstrate the role and ability of Explainable AI 
in this task, we should avoid from introducing prior knowledge
 into the discovery process. As a result, we augment 
as many variables as we can imagine from the existing variables
 and then totally rely on symbolic regression to find the 
potential relationship underlying some or all of the variables, 
including both existing variables and augmented variables. 
-->
さて、拡張データポイント \((t_i, \theta_i, r_i, \omega_i)\) を使用して、これらの物理変数の一部またはすべての間に、解釈可能なシンボリックな物理的関係を見つけたいと考えています。
今日では高校生でさえそれらの関係を知っていますが、シンボリック回帰などの説明可能なAIを使用してそれらの関係を見つける際には、根底にある物理的ルールについての知識はないと想定する必要があります。なぜなら、このタスクにおける説明可能なAIの役割と能力を示すためには、発見プロセスに事前知識を導入することを避ける必要があるからです。その結果、既存の変数から想像できる限り多くの変数を拡張し、既存の変数と拡張された変数の両方を含む、一部またはすべての変数の根底にある潜在的な関係を見つけるために、シンボリック回帰に完全に依存します。
</p><p>
<!--
As a demonstration to this process, we try to find the relationship
 between \(r\) and \(ω\) (we can apply the same process 
on other pairs of variables if we want), and to reduce the 
complexity of the power operation, we create some aug
mented variables including \(r_2=r^2, r_3=r^3\) and \(\omega_2
=\omega^2, \omega_3=\omega^3\). Finally, we use \(r_1
=r, r_2=r^2, r_3=r^3\) as 
the input variables to symbolic regress \(\omega_1=\omega, \omega_2 
=\omega^2\) and \(\omega_3=\omega^3\), respectively, and then, we repeat the process 
the other way around, i.e., use \(\omega_1=\omega, \omega_2=\omega^2, \omega_3=
\omega^3\) as the input variables to symbolic regress \(r_1=r, r_2=r^2\), and \(r_3
=r^3\), respectively. We still use four basic operations 
cosine (cos), addition (+), multiplication (\(\cdot\)) and division (/) 
for symbolic regression, same as previous experiments. In 
this process, the symbolic regression results when finding 
function for \(\omega_2 = F(r_1, r_2, r_3)\) are shown as Table 6, and 
the relationship between function size and regression error 
(in terms of negative log RMSE) is in Figure 8. 
-->
このプロセスのデモンストレーションとして、\(r\) と \(ω\) の関係を見つけようとします（必要に応じて、他の変数のペアにも同じプロセスを適用できます）。また、べき乗演算の複雑さを軽減するために、\(r_2=r^2, r_3=r^3\) や \(\omega_2=\omega^2, \omega_3=\omega^3\) などの拡張変数を作成します。最後に、\(r_1
=r, r_2=r^2, r_3=r^3\) をそれぞれシンボリック回帰 \(\omega_1=\omega, \omega_2
=\omega^2\) と \(\omega_3=\omega^3\) の入力変数として使用し、次に、このプロセスを逆順に繰り返します。つまり、\(\omega_1=\omega, \omega_2=\omega^2, \omega_3=
\omega^3\) をそれぞれシンボリック回帰 \(r_1=r, r_2=r^2\) と \(r_3
=r^3\) の入力変数として使用します。前回の実験と同様に、記号回帰には4つの基本演算、すなわち余弦(cos)、加算(+)、乗算(\(\cdot\))、除算(/)を使用します。このプロセスにおいて、\(\omega_2 = F(r_1, r_2, r_3)\)の関数を求める際の記号回帰結果は表6に示され、関数のサイズと回帰誤差(負の対数RMSEで表したもの)の関係は図8に示されています。
</p><p>
<!--
From Figure 8 we can see that the function with size 4 
has the sharpest increase in accuracy, which indicates that 
this function has the best chance to achieve a good balance 
between accuracy and complexity to reveal the physical rule 
behind data [30]. We write down the function as follows 
(recall that \(\omega_2=\omega^2, r_3=r^3\)):
-->
図8から、サイズ4の関数の精度が最も急激に向上していることがわかります。これは、この関数がデータの背後にある物理的な法則を明らかにするために、精度と複雑さのバランスをうまく取れる可能性が最も高いことを示しています[30]。この関数を次のように書きます（\(\omega_2=\omega^2, r_3=r^3\) であることを思い出してください）。

\[ 
\omega^2=\frac{0.000298491}{r^3}　or　r^3\omega^3 = c =0.000298491AU^3day^{-2}  \tag{4}
\]

<!--
Based on modern scientific knowledge, we know that 
\(r^3\omega^2=GM\), where \(G=6.674×10^{-11}m^3kg^{-1}s^{-2}\) is the gravitational constant and \(M=1.989×10^{30}kg\) is the mass of Sun. Besides, our unit for distance is \(1AU=1.496×10^{11}m\), so we have \(r^3\omega^2=GM
=2.96×10^{-4}AU^3day^{-2}\), and this number is very close to 
the constant in Eq.(4), with relative error of about 0:8%, 
which is small and reasonable considering that we only used 
the ancient data that was collected 400 years ago. This 
shows the nice ability of Explainable AI such as symbolic 
regression in discovering the physical rules underlying data. 
-->
現代科学の知識に基づくと、\(r^3\omega^2=GM\) であることが分かっています。ここで、\(G=6.674×10^{-11}m^3kg^{-1}s^{-2}\) は重力定数、\(M=1.989×10^{30}kg\) は太陽の質量です。また、距離の単位は \(1AU=1.496×10^{11}m\) なので、\(r^3\omega^2=GM
=2.96×10^{-4}AU^3day^{-2}\) となり、この数値は式(4)の定数に非常に近く、相対誤差は約0.8%です。これは、400年前に収集された古代のデータのみを使用したことを考えると小さく妥当な値です。これは、データの背後にある物理的なルールを発見するシンボリック回帰などのExplainable AIの優れた能力を示しています。
</p>
<!--
<h3>5.3. Physical Interpretation of the Results </h3>
-->
<h3>5.3. 結果の物理的な解釈</h3>
<p>
<!--
Though we have shown that (Explainable) AI is able to 
make accurate predictions and generate explainable equations,
 we still want to emphasize that AI algorithms and 
machines do not “understand” or produce “meaning” for the 
physical variables or rules that emerge in the science discovery
 process<sup>4</sup>. From the AI and machines’ perspective, the 
variables and rules are just symbols and equations, and AI 
algorithms are only responsible for data analyses so as to extract
 possibly inspiring variables and rules, while it is human 
being’s role to understand them and give meanings to the 
extracted variables and rules. For example, AI algorithms 
may discover a new combination of variables that as a whole 
is particularly useful for predicting and explaining the data 
(we will discuss with more details in the following). In this 
case, human experts may try to interpret the physical meaning
 of this combination of variables and leverage it to gain 
better understandings of the problem. Sometimes, human 
experts may also need to innovatively create new physical 
concepts up front or with the assistance of AI during the discovery
 process so as to better interpret the results, enabling 
a human-AI collaborative science discovery process. 
-->
（説明可能な）AIは正確な予測を行い、説明可能な方程式を生成できることを示しましたが、AIアルゴリズムや機械は科学的発見プロセス<sup>4</sup>で出現する物理的な変数や規則を「理解」したり「意味」を生み出したりするわけではないことを強調しておきたいと思います。AIや機械の観点から見ると、変数や規則は単なる記号や方程式であり、AIアルゴリズムはデータ分析を行い、刺激的な変数や規則を抽出する役割のみを担っています。一方、人間の役割は、それらを理解し、抽出された変数や規則に意味を与えることです。例えば、AIアルゴリズムは、全体としてデータの予測と説明に特に役立つ新しい変数の組み合わせを発見するかもしれません（詳細は後述します）。この場合、人間の専門家は、この変数の組み合わせの物理的な意味を解釈し、それを活用して問題をより深く理解しようとするかもしれません。場合によっては、人間の専門家が、結果をより適切に解釈し、人間とAIが協力して科学発見プロセスを実現するために、事前に、または発見プロセス中にAIの支援を受けて、革新的な新しい物理的概念を創造する必要もあります。

</p><p class="margin-large">

<sup>4</sup> 
<!--
We acknowledge that there exist debates over whether machines
 have their own internal “meanings” that are unknown or 
not understandable to humans, however, this is not a focus of this 
paper since we aim at science discovery for human beings. 
-->
機械が人間には未知、あるいは理解できない独自の内部的な「意味」を持っているかどうかについては議論があることは承知していますが、本論文では人間のための科学的発見を目指しているため、この点は焦点ではありません。

</p><p>
<!--
In the above experiment, once Explainable AI has generated 
the equation \(r^3\omega^2=c\) (\(c\) is a constant), we first need to 
realize that \(a=r\omega^2\) means the centripetal acceleration in 
circular motion. The deduction of centripetal acceleration 
\(a\) does not need calculus, but acceleration was still a new 
concept at Kepler’s time that needs to be created. With this 
new concept, \(r^3\omega^2=c\) can be reorganized into \(ar^2=c\), 
i.e., \(a ∝ \frac{1}{r^2}\), which is the centripetal acceleration equation. 
The centripetal acceleration equation \(a ∝ \frac{1}{r^2}\) can explain 
why the orbit of Mars is elliptical, but to really know what 
causes the elliptical orbit, we still need to know what causes 
the centripetal acceleration a, i.e., what is the underlying 
“force” that drives the Mars orbiting in such a way. 
-->
上記の実験では、Explainable AI が方程式 \(r^3\omega^2=c\) (\(c\) は定数) を生成したら、まず \(a=r\omega^2\) が円運動における求心加速度を意味することを理解する必要があります。求心加速度 \(a\) の導出には微積分は必要ありませんが、加速度はケプラーの時代にはまだ新しい概念であり、確立される必要がありました。この新しい概念を用いることで、\(r^3\omega^2=c\) は \(ar^2=c\)、つまり \(a ∝ \frac{1}{r^2}\) に再構成でき、これが求心加速度方程式となります。求心加速度方程式 \(a ∝ \frac{1}{r^2}\) は、火星の軌道が楕円形である理由を説明できますが、楕円軌道の原因を本当に知るには、求心加速度 a の原因、つまり火星をそのような軌道に回す根本的な「力」が何であるかを知る必要があります。
</p><p>
<!--
At Kepler’s time, scientists already had the concept of force, 
but they did not know the correct function of force, since 
they thought force was proportional to distance and thus 
speed. It was Newton’s greatness to realize that force is 
not the reason of speed but actually the reason of acceleration,
 and he innovatively connected force with acceleration 
by \(F=ma\). Based on this, suppose \(M\) is the mass of Sun, \(ar^2
=c\) can be reorganized as \(Mar^2=Mc\), thus \(Fr^2=Mc\), and 
\(F ∝ \frac{1}{r^2}\), leading to Newton’s inverse-square law of universal gravitation. One can see that in 
this interpretation process, humans still need to play an important
 role in understanding or creating physical concepts. 
This is partly because at Kepler and Newton’s time, measuring
 the force is almost impossible, and thus the observational 
data does not include force \(F\) 
as one of the variables. If 
force \(F\)  
were one of the variables with observed values, 
just like time \(t\) and angle \(\theta\), then (Explainable) AI methods 
might be able to extract the symbolic equation for \(F\) 
from 
data, just as we did in the above for other variables, which 
can save efforts for human exploration, intervention, interpretation
 and creation in the discovery process. However, 
even if we have observed \(F\) 
values, like in many modern 
scientific datasets, we can never fully exclude the possibility 
that human experts need to innovatively create other new 
concepts that do not yet exist in the observational data. 
-->
ケプラーの時代には、科学者たちはすでに力の概念を持っていましたが、力の正しい働きを理解していませんでした。なぜなら、力は距離、ひいては速度に比例すると考えていたからです。ニュートンの偉大さは、力が速度の理由ではなく、実際には加速の理由であることを理解したことでした。そして、彼は力と加速を\(F=ma\)によって革新的に結び付けました。これに基づき、\(M\)を太陽の質量とすると、\(ar^2
=c\)は\(Mar^2=Mc\)と整理でき、\(Fr^2=Mc\)となり、\(F ∝ \frac{1}{r^2}\)となり、ニュートンの万有引力の逆二乗の法則が導き出されます。この解釈のプロセスにおいて、人間は物理学の概念を理解したり創造したりする上で、依然として重要な役割を果たす必要があることがわかります。これは、ケプラーとニュートンの時代には力の測定がほぼ不可能だったため、観測データに力 \(F\) が変数として含まれていなかったことが一因です。もし力 \(F\) が時間 \(t\) や角度 \(\theta\) のように観測値を持つ変数の1つであったなら、（説明可能な）AI手法は、他の変数の場合と同様に、データから \(F\) の記号式を抽出できたかもしれません。これにより、発見プロセスにおける人間による探索、介入、解釈、そして創造の労力を節約できます。しかし、多くの現代の科学データセットのように \(F\) 値を観測できたとしても、人間の専門家が観測データにまだ存在しない新しい概念を革新的に創造する必要がある可能性を完全に排除することはできません。
</p>
<!--
<h3>5.4. Relation with Kepler’s Third Law </h3>
-->
<h3>5.4. ケプラーの第三法則との関係</h3>
<p>
<!--
The discovered rule \(r^3\omega^2=c\) in Eq.(4) could be mis-
interpreted as the Kepler’s Third Law \(\frac{\bar{r}^3}{T^2}=c^\prime\) 
if one applies \(\bar{\omega}=\frac{2\pi}{T}\) for circular motion. Actually, Eq.(4) should not
be interpreted as the Kepler’s Third Law, because Kepler’s 
Third Law talks about a universal rule for all planets circulating
 Sun, while Eq.(4) only talks about a rule for Mars 
since this rule is solely derived from Mars data. More specifically,
 Eq.(4) is saying that at any time \(t\), the Mars’ angular 
velocity \(ω\) 
and its corresponding distance to Sun \(r\) 
satisfy a constant rule, while Kepler’s Third Law is saying that for 
all planets circulating Sun, their mean distance to Sun and 
circulating period satisfy a constant rule. To really discovery
 and justify Kepler’s Third Law, we need to include the 
data of more planets. Actually, Kepler himself studied six 
planets: Mercury, Venus, Earth, Mars, Jupiter and Saturn. 
This example shows that we need to be extremely careful 
when trying to interpret the Explainable AI discovered rules 
and avoid from over-generalizing the results. 
-->
式(4)で発見された規則\(r^3\omega^2=c\)は、円運動に\(\bar{\omega}=\frac{2\pi}{T}\)を適用すると、ケプラーの第三法則\(\frac{\bar{r}^3}{T^2}=c^\prime\)と誤って解釈される可能性があります。実際には、式(4)はケプラーの第三法則として解釈すべきではありません。なぜなら、ケプラーの第三法則は太陽を周回するすべての惑星に適用される普遍的な規則を述べているのに対し、式(4)は火星のデータのみから導かれた規則であるため、火星にのみ適用される規則を述べているからです。より具体的には、式(4)は、任意の時刻\(t\)において、火星の角速度\(ω\)とそれに対応する太陽までの距離\(r\)が定数則を満たすことを述べています。一方、ケプラーの第三法則は、太陽を周回するすべての惑星について、太陽までの平均距離と公転周期が定数則を満たすことを述べています。ケプラーの第三法則を真に発見し、正当化するには、より多くの惑星のデータを含める必要があります。実際、ケプラー自身は水星、金星、地球、火星、木星、土星の6つの惑星を研究しました。
この例は、Explainable AIが発見したルールを解釈する際には、結果を過度に一般化することを避けるため、細心の注意を払う必要があることを示しています。
</p><p>
<!--
However, Eq.(4) is still useful and may inspire us towards 
Kepler’s Third Law. If we look at this equation from a 
macro perspective, the period \(T\) 
can be considered as an 
integrated effect of the angular velocity \(\omega\), which may lead 
us to consider whether \(T\) and \(r\) also exhibit similar rules. 
Even though we know that the Kepler’s Third Law \(\frac{\bar{r}^3}{T^2}=c^\prime\) 
needs information of other planets to justify, Eq.(4) which 
is solely derived from the Mars data may point to the right 
direction and speed up the discovery process. Actually, 
if we take \(\bar{\omega}=\frac{2\pi}{T}\) into Eq.(4), we have \(\frac{\bar{r}^3}{T^2}=\frac{c}{4\pi^3}=7.56086×10^{-6}AU^3day^{-2}\overset{\cdot}{=}c^\prime\), which is close Kepler’s result (\(7.5\times 10^{-6}AU^3day^{-2}\), error within 0.82%) and modern
 science result (\(7.495×10^{-6}AU^3day^{-2}\), error within 
0.88%). The ability of associating macro and micro perspectives
 by intuition is uniquely owned by humans instead 
of current AI, and this is one of the reasons why humans 
still play an indispensable role in modern science discovery 
process. 
-->
しかし、式(4)は依然として有用であり、ケプラーの第三法則への示唆を与える可能性があります。この式をマクロな視点から見ると、周期\(T\)は角速度\(\omega\)の積分効果と見なすことができ、\(T\)と\(r\)も同様の規則性を示すかどうかを検討することにつながる可能性があります。ケプラーの第三法則\(\frac{\bar{r}^3}{T^2}=c^\prime\)の正当性を証明するには他の惑星の情報が必要であることは分かっていますが、火星のデータのみから導かれる式(4)は正しい方向を示し、発見プロセスを加速させる可能性があります。実際、\(\bar{\omega}=\frac{2\pi}{T}\) を式(4)に代入すると、\(\frac{\bar{r}^3}{T^2}=\frac{c}{4\pi^3}=7.56086×10^{-6}AU^3day^{-2}\overset{\cdot}{=}c^\prime\) となり、これはケプラーの結果 (\(7.5\times 10^{-6}AU^3day^{-2}\)、誤差0.82%以内) や現代科学の結果 (\(7.495×10^{-6}AU^3day^{-2}\)、誤差0.88%以内) に近い値となります。直感によってマクロとミクロの視点を関連付ける能力は、現在のAIではなく人間に特有のものであり、これが人間が現代の科学発見プロセスにおいて依然として不可欠な役割を果たしている理由の一つです。
</p>
<!--
<h2>6. Conclusions and Future Work </h2>
-->
<h2>6. 結論と今後の課題 </h2>
<p>
<!--
In this paper, we highlight the role of Explainable AI in science
 discovery by demonstrating an Explainable AI-based 
paradigm for science discovery. To demonstrate the idea, we 
show how Kepler’s laws of planetary motion and Newton’s 
law of universal gravitation can be rediscovered with the 
assistance of Explainable AI based on a small amount of 
Tycho Brahe’s astronomical observation data, whose works 
were leading the scientific revolution in the 16-17th century. 
Technically, we use black-box models such as deep neural
 networks for prediction and data augmentation, and use 
white-box models such as symbolic regression for model 
explanation. Insightful discoveries and conclusions can be 
derived by interpreting the results under the assistance of 
Explainable AI. We also demonstrate the indispensable role 
of human beings in the science discovery process on creating
 new concepts, assigning meanings to the discovered 
variables and rules, and providing insightful intuitions to 
supervise the AI-based discovery process. 
-->
本稿では、科学的発見のための説明可能なAIに基づくパラダイムを示すことにより、科学的発見における説明可能なAIの役割を強調する。このアイデアを実証するために、16世紀から17世紀にかけて科学革命を牽引したティコ・ブラーエの天文観測データの少量に基づき、説明可能なAIの支援により、ケプラーの惑星運動の法則とニュートンの万有引力の法則がどのように再発見されるかを示す。技術的には、予測とデータ拡張にはディープニューラルネットワークなどのブラックボックスモデルを用い、モデルの説明にはシンボリック回帰などのホワイトボックスモデルを用いる。説明可能なAIの支援の下で結果を解釈することにより、洞察に満ちた発見と結論を導き出すことができる。また、科学の発見プロセスにおいて、新しい概念の創造、発見された変数や規則への意味の付与、そしてAIベースの発見プロセスを監督するための洞察力に富んだ直感の提供といった、人間が不可欠な役割を果たすことも示します。
</p><p>
<!--
In the future, we will further refine the Explainable AI-based 
paradigm for science discovery by considering a wider scope 
of black-box and white-box models as well as applying them 
to various different scientific fields. We will also use the 
framework for more state-of-the-art scientific problems such 
as dark matters based on modern astronomical observation 
data and particle physics based on the data collected from 
Large Hadron Colliders for discovering new knowledge 
that is unknown to human. And probably one day, we can 
even improve the performance of Explainable AI through 
the knowledge discovered by AI itself while maintaining 
complete control of the process by demanding explanations 
from AI, since we always stand on the shoulder of giants. 
-->
今後、私たちは、ブラックボックスモデルとホワイトボックスモデルをより広範囲に検討し、様々な科学分野に適用することで、説明可能なAIに基づく科学的発見のパラダイムをさらに洗練させていきます。また、このフレームワークを、現代の天文観測データに基づく暗黒物質や、大型ハドロン衝突型加速器から収集されたデータに基づく素粒子物理学など、より最先端の科学的問題にも活用し、人類が知らない新たな知識の発見を目指します。そしておそらくいつの日か、私たちは常に巨人の肩の上に立っているため、AIに説明を求めることでプロセスを完全に制御しながら、AI自身が発見した知識を通じて説明可能なAIの性能を向上させることができるでしょう。
</p>
<!--
<h2>References </h2>
-->
<h2>参考文献</h2>
<p>
<div class="styleRef">
<ul><li>
[1] Peter Godfrey-Smith. Theory and reality. University 
of Chicago Press, 2009. 
</li><br><li>[2] Robert Nola and Howard Sankey. Theories of scientific 
method: an introduction. Routledge, 2014. 
</li><br><li>[3] Anthony JG Hey, Stewart Tansley, Kristin Michele 
Tolle, et al. The fourth paradigm: data-intensive scientific
 discovery, volume 1. Microsoft research Redmond,
 WA, 2009. 
</li><br><li>[4] Ahmed Eldawy and Mohamed F Mokbel. The era 
of big spatial data: a survey. Information and Media 
Technologies, 10(2):305–316, 2015. 
</li><br><li>[5] Kamran Naim, Maria Grazia Pia, Alex Kohls, Tullio
 Basaglia, Stephanie Van De Sandt, Pamfilos 
Fokianos, Jose Gonzalez Lopez, Javier Serrano, Jelena
 Brankovic, Lars Holm Nielsen, et al. Pushing the 
boundaries of open science at cern: Submission to the 
unesco open science consultation. Technical report, 
2020. 
</li><br><li>[6] Johannes Kepler. Astronomia Nova. Translated by 
William H. Donahue, Green Lion Press, 2015. 
</li><br><li>[7] Isaac Newton. Principia. University of California 
Press, 2020. 
</li><br><li>[8] Stanislaw Ulam. Tribute to john von neumann. Bulletin
 of the American mathematical society, 64(3):1– 
49, 1958. 
</li><br><li>[9] Vernor Vinge. The coming technological singularity: 
How to survive in the post-human era. Science Fiction 
Criticism: An Anthology of Essential Writings, pages 
352–363, 1993. 
</li><br><li>[10] Matthew Sparkes. Top scientists call for caution over 
artificial intelligence. The Times (UK), 24, 2015. 
</li><br><li>[11] Irving John Good. Speculations concerning the first 
ultraintelligent machine. In Advances in computers. 
1966. 
</li><br><li>[12] Yongfeng Zhang and Xu Chen. Explainable recommendation:
 A survey and new perspectives. Foundations
 and Trends in Information Retrieval, 2020. 
</li><br><li>[13] Yongfeng Zhang, Guokun Lai, Min Zhang, Yi Zhang, 
Yiqun Liu, and Shaoping Ma. Explicit factor models 
for explainable recommendation based on phrase-level 
sentiment analysis. In SIGIR, pages 83–92, 2014. 
</li><br><li>[14] Juntao Tan, Shuyuan Xu, Yingqiang Ge, Yunqi Li, 
Xu Chen, and Yongfeng Zhang. Counterfactual explainable
 recommendation. CIKM, 2021. 
</li><br><li>[15] Lloyd S Shapley. A value for n-person games. In 
Contributions to the Theory of Games, pages 307–317, 
1953. 
</li><br><li>[16] Marco Tulio Ribeiro, Sameer Singh, and Carlos 
Guestrin. " why should i trust you?" explaining the predictions
 of any classifier. In Proceedings of the 22nd 
ACM SIGKDD international conference on knowledge 
discovery and data mining, pages 1135–1144, 2016. 
</li><br><li>[17] Mukund Sundararajan and Amir Najmi. The many 
shapley values for model explanation. In International 
Conference on Machine Learning, pages 9269–9278. 
PMLR, 2020. 
</li><br><li>[18] George AF Seber and Alan J Lee. Linear regression 
analysis, volume 329. John Wiley & Sons, 2012. 
</li><br><li>[19] J. Ross Quinlan. Induction of decision trees. Machine 
learning, 1(1):81–106, 1986. 
</li><br><li>[20] J Ross Quinlan. C4.5: programs for machine learning. 
Elsevier, 2014. 
</li><br><li>[21] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
 Neural machine translation by jointly learning to 
align and translate. ICLR, 2015. 
</li><br><li>[22] Sarah Wiegreffe and Yuval Pinter. Attention is not not 
explanation. In EMNLP, pages 11–20, 2019. 
</li><br><li>[23] Sarthak Jain and Byron C Wallace. Attention is not 
explanation. In NAACL, pages 3543–3556, 2019. 
</li><br><li>[24] John R Koza and John R Koza. Genetic programming: 
on the programming of computers by means of natural 
selection, volume 1. MIT press, 1992. 
</li><br><li>[25] Qiang Lu, Jun Ren, and Zhiguang Wang. Using genetic
 programming with prior formula knowledge to 
solve symbolic regression problem. Computational 
intelligence and neuroscience, 2016, 2016. 
</li><br><li>[26] Sohrab Towfighi. Symbolic regression by uniform 
random global search. SN Applied Sciences, 2(1):1– 
11, 2020. 
</li><br><li>[27] Douglas Adriano Augusto and Helio JC Barbosa. Symbolic
 regression via genetic programming. In Proceedings.
 Vol. 1. Sixth Brazilian Symposium on Neural 
Networks, pages 173–178. IEEE, 2000. 
</li><br><li>[28] Steven Gustafson, Edmund K Burke, and Natalio 
Krasnogor. On improving genetic programming for 
symbolic regression. In 2005 IEEE Congress on Evolutionary
 Computation, volume 1, pages 912–919. IEEE, 
2005. 

</li><br><li>[29] Ying Jin, Weilin Fu, Jian Kang, Jiadong Guo, and Jian 
Guo. Bayesian symbolic regression. arXiv preprint 
arXiv:1910.08892, 2019. 
</li><br><li>[30] Silviu-Marian Udrescu and Max Tegmark. Ai feynman:
 A physics-inspired method for symbolic regression.
 Science Advances, 6(16):eaay2631, 2020. 
</li><br><li>[31] Silviu-Marian Udrescu, Andrew Tan, Jiahai Feng, 
Orisvaldo Neto, Tailin Wu, and Max Tegmark. 
Ai feynman 2.0: Pareto-optimal symbolic regression
 exploiting graph modularity. arXiv preprint 
arXiv:2006.10782, 2020. 
</li><br><li>[32] Michael Schmidt and Hod Lipson. Distilling free-form 
natural laws from experimental data. science, 2009. 
</li><br><li>[33] Turingbot: Symbolic regression software, 2020. 
</li><br><li>[34] Eric Smalley. Ai-powered drug discovery captures 
pharma interest, 2017. 
</li><br><li>[35] Justin S Smith, Adrian E Roitberg, and Olexandr 
Isayev. Transforming computational drug discovery 
with machine learning and ai, 2018. 
</li><br><li>[36] HC Stephen Chan, Hanbin Shan, Thamani Dahoun, 
Horst Vogel, and Shuguang Yuan. Advancing drug 
discovery via artificial intelligence. Trends in pharmacological
 sciences, 40(8):592–604, 2019. 
</li><br><li>[37] Carla P Gomes, Bart Selman, and John M Gregoire. 
Artificial intelligence for materials discovery. MRS 
Bulletin, 44(7):538–544, 2019. 
</li><br><li>[38] Ehsan Haghighat, Maziar Raissi, Adrian Moure, Hector
 Gomez, and Ruben Juanes. A deep learning framework
 for solution and discovery in solid mechanics. 
arXiv preprint arXiv:2003.02751, 2020. 
</li><br><li>[39] Miles Cranmer, Alvaro Sanchez-Gonzalez, Peter 
Battaglia, Rui Xu, Kyle Cranmer, David Spergel, 
and Shirley Ho. Discovering symbolic models from 
deep learning with inductive biases. arXiv preprint 
arXiv:2006.11287, 2020. 
</li><br><li>[40] Minoru Kusaba, Chang Liu, Yukinori Koyama, Kiyoyuki
 Terakura, and Ryo Yoshida. Recreation of the 
periodic table with an unsupervised machine learning 
algorithm. Scientific reports, 11(1):1–10, 2021. 
</li><br><li>[41] John Jumper, Richard Evans, Alexander Pritzel, 
Tim Green, Michael Figurnov, Olaf Ronneberger, 
Kathryn Tunyasuvunakool, Russ Bates, Augustin 
Žídek, Anna Potapenko, Alex Bridgland, Clemens 
Meyer, Simon A. A. Kohl, Andrew J. Ballard, Andrew
 Cowie, Bernardino Romera-Paredes, Stanislav 
Nikolov, Rishub Jain, Jonas Adler, Trevor Back, Stig 
Petersen, David Reiman, Ellen Clancy, Michal Zielinski,
 Martin Steinegger, Michalina Pacholska, Tamas 
Berghammer, Sebastian Bodenstein, David Silver, 
Oriol Vinyals, Andrew W. Senior, Koray Kavukcuoglu, 
Pushmeet Kohli, and Demis Hassabis. Highly accurate 
protein structure prediction with alphafold. Nature, 
596(7873):583–589, 2021. 

</li><br><li>[42] Bill Spencer (translator). Inter Gravissimas. 2002. 
</li><br><li>[43] Edward L Cohen. Adoption and reform of the gregorian
 calendar. Math Horizons, 7(3):5–11, 2000. 
</li><br><li>[44] A Eremenko. How Kepler discovered his laws, 2016. 
</li><br><li>[45] Curtis Wilson. How did kepler discover his first two 
laws? Scientific American, 226(3):92–107, 1972. 
</li><br><li>[46] Dhananjay Ashok, Joseph Scott, Sebastian Wetzel, 
Maysum Panju, and Vijay Ganesh. Logic guided genetic
 algorithms. arXiv preprint arXiv:2010.11328, 
2020. 
</li><br><li>[47] Arthur Koestler. The sleepwalkers: A history of man’s 
changing vision of the universe. Penguin UK, 2017. 
</li><br><li>[48] Max Caspar. Kepler. Courier Corporation, 2012. 
</li><br><li>[49] Jean Meeus. When was mars last this close? Planetarian,
 2003. 
</li><br><li>[50] Curtis Wilson. Kepler’s derivation of the elliptical 
path. Isis, 59(1):4–25, 1968. 
</li><br><li>[51] William Gilbert. De magnete. Courier Corporation, 
1958 [1600]. 
</li><br><li>[52] Howard D Curtis. Orbital mechanics for engineering 
students. Butterworth-Heinemann, 2013. 
</li><br><li>[53] George Cybenko. Approximation by superpositions of 
a sigmoidal function. Mathematics of control, signals 
and systems, 2(4):303–314, 1989. 
</li><br><li>[54] Kurt Hornik. Approximation capabilities of multilayer 
feedforward networks. Neural networks, 4(2), 1991. 
</li><br><li>[55] Balázs Csanád Csáji et al. Approximation with artificial
 neural networks. Faculty of Sciences, Etvs Lornd 
University, Hungary, 24(48):7, 2001. 
</li></ul></div></p>
<!--
<h2>7. Appendix</h2>
-->
<h2>7. 付録</h2>
<p>
<!--
 In this section, we present all of the tables and figures referenced in the paper. 
-->
このセクションでは、論文で参照されているすべての表と図を紹介します。
</p>
<center><img src="images/table1.png"></center>
<p>
<!--
<center>Table 1. Position of Mars when orbiting the Sun </center>
-->
<center>表1. 太陽を周回する際の火星の位置 </center>
</p>
<center><img src="images/table2.png"></center>
<p>
<!--
<center>Table 2. Symbolic Regression Results</center> 
-->
<center>表2. シンボリック回帰の結果 </center>
</p>
<center><img src="images/table3.png"></center>
<p>
<!--
<center>Table 3. Based Functions for Symbolic Regression and their Size</center> 
-->
<center>表3. シンボリック回帰の基底関数とそのサイズ </center>

</p>
<center><img src="images/table4.png"></center>
<p>
<!--
<center>Table 4. Orbital Parameters of Mars based on Modern Science </center>
-->
<center>表4. 現代科学に基づく火星の軌道パラメータ </center>
</p>
<center><img src="images/table5.png"></center>
<p>
<!--
<center>Table 5. Closest Approaches of Mars Oppositions in History </center>
-->
<center>表5. 火星の衝の歴史上最も接近した回帰 </center>
</p>
<center><img src="images/table6.png"></center>
<p>
<!--
<center>Table 6. Symbolic Regression Result for \(r\) and \(ω\) </center>
-->
<center>表6. \(r\)と\(ω\)のシンボリック回帰結果 </center>
</p>
<center><img src="images/fig3.png"></center>
<p>
<!--
<center>Figure 3. Data Visualization before Training </center>
-->
<center>図3. トレーニング前のデータ可視化 </center>
</p>
<center><img src="images/fig4.png"></center>
<p>
<!--
<center>Figure 4. Data Visualization after Training </center>
-->
<center>図4. トレーニング後のデータ可視化 </center>
</p>
<center><img src="images/fig5.png"></center>
<p>
<!--
<center>Figure 5. Size and Negative log Error </center>
-->
<center>図5. サイズと負の対数誤差 </center>
</p>
<center><img src="images/fig6.png"></center>
<p>
<!--
<center>Figure 6. Data Visualization before Training </center>
-->
<center>図6. 学習前のデータ可視化 </center>
</p>
<center><img src="images/fig7.png"></center>
<p>
<!--
<center>Figure 7. Data Visualization after Training </center>
-->
<center>図7. 学習後のデータ可視化 </center>
</p>
<center><img src="images/fig8.png"></center>
<p>
<!--
<center>Figure 8. Size and Negative log Error for \(r\) and \(\omega\) </center>
-->
<center>図8. \(r\) と \(\omega\) のサイズと負の対数誤差 </center>
</p>
    </body>
</html>
