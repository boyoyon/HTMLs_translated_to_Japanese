<!doctype html>
<html lang="ja">
    <head>
        <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
        <meta charset="utf-8" />
        <title>CTM</title>
        <style type="text/css">
            p
            {
                padding-left: 2em;
            }
            .margin-large
            {
                margin-left: 30px;
            }
           .margin-abstract {
               margin-left: 60px; /* 左マージンを広くする */
               margin-right: 60px; /* 右マージンを広くする */
           }
        </style>
    <style>
        .two-columns {
            display: flex;
            flex-direction: row;
            gap: 20px; /* 列間のスペース */
        }
        .column {
            flex: 1; /* 各列が均等に幅を取る */
        }
    </style>
<style>
.three-columns {
  display: flex;
  gap: 10px; /* 列間の余白を設定 */
}
.column {
  flex: 1; /* 各列の幅を均等にする */
  padding: 10px; /* 内側の余白を設定 */
}
</style>
    <style>
        .styleRef { 
            text-indent: -40px; /* 最初の行の字下げを逆方向に */
            margin-left: 10px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 40px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
        .styleBullet { 
            text-indent: -20px; /* 最初の行の字下げを逆方向に */
            margin-left: 30px; /* 2行目以降の字下げを調整 */
            ul {
                  list-style-type: none; /* 箇条書き記号を非表示 */
                  padding-left: 0px; /* 全体の左余白 */
            }
            li {
            }
        }
    </style>
    <style>
            ol
            {
                margin-left: 30px;
            }
            ul
            {
                margin-left: 30px;
            }
    </style>
    <style>
        .thin-line {
            margin: 0; 
            margin-left:2em;
            border: 0;
            height: 1px;
            background-color: gray;
        }

        .thick-line {
            margin: 0; 
            margin-left:2em;
            border: 0;
            height: 2px;
            background-color: black;
        }
    </style>
    <style>
        .highlight {
            color: red; /* 好きな色に変更してください */
        }
    </style>
    </head>
    <body>
<h1>Continuous Thought Machines </h1>
連続思考マシン<br>
<br>
Luke Darlow1, Ciaran Regan1,2, Sebastian Risi1,3, Jeffrey Seely1 and Llion Jones1 
1Sakana AI, 2University of Tsukuba, 3IT University of Copenhagen 
<p>
生物学的脳は複雑な神経活動を示し、ニューロン間のタイミングと相互作用は脳の情報処理において極めて重要です。ほとんどの深層学習アーキテクチャは、時間的ダイナミクスを抽象化することで神経活動を単純化しています。本稿では、このパラダイムに挑戦します。ニューロンレベルの処理と同期を組み込むことで、神経タイミングを基礎要素として効果的に再導入することができます。本稿では、ニューロンダイナミクスを中核表現として活用するように設計されたモデル、Continuous Thought Machine (CTM) を紹介します。CTMには2つの中核的な革新があります。(1) ニューロンレベルの時間的処理（各ニューロンが固有の重みパラメータを使用して入力信号の履歴を処理する）、(2) 潜在表現として用いられるニューロン同期です。CTMは、計算効率を向上させる過度に単純化されたニューロン抽象化と生物学的リアリズムのバランスをとることを目指しています。 CTMは、深層学習に適した計算処理能力を維持しながら、本質的な時間的ダイナミクスを効果的に捉える抽象化レベルで動作します。ImageNet-1K分類、2次元迷路解法、ソーティング、パリティ計算、質問応答、強化学習タスクなど、様々な難解タスクにおいて、CTMの優れた性能と汎用性を実証しました。CTMは、豊富な内部表現の表示と内部プロセスによる自然な解釈の道筋の提供に加え、複雑な逐次推論を必要とするタスクも実行できます。CTMは適応型コンピューティングも活用でき、単純なタスクでは早期に停止し、より困難なインスタンスに直面しても計算を継続できます。本研究の目的は、最先端の新しい成果を追求することではなく、CTMとそれに関連するイノベーションを共有することです。そのため、CTMは、より生物学的に妥当で強力な人工知能システムの開発に向けた重要な一歩となると考えています。
<!--
Biological brains demonstrate complex neural activity, where the timing and interplay between neurons
is critical to how brains process information. Most deep learning architectures simplify neural activity by
abstracting away temporal dynamics. In this paper we challenge that paradigm. By incorporating neuron-level
processing and synchronization, we can effectively reintroduce neural timing as a foundational element. We
present the Continuous Thought Machine (CTM), a model designed to leverage neural dynamics as its core
representation. The CTM has two core innovations: (1) neuron-level temporal processing, where each neuron
uses unique weight parameters to process a history of incoming signals; and (2) neural synchronization
employed as a latent representation. The CTM aims to strike a balance between oversimplified neuron
abstractions that improve computational efficiency, and biological realism. It operates at a level of abstraction
that effectively captures essential temporal dynamics while remaining computationally tractable for deep
learning. We demonstrate the CTM’s strong performance and versatility across a range of challenging tasks,
including ImageNet-1K classification, solving 2D mazes, sorting, parity computation, question-answering, and
RL tasks. Beyond displaying rich internal representations and offering a natural avenue for interpretation
owing to its internal process, the CTM is able to perform tasks that require complex sequential reasoning.
The CTM can also leverage adaptive compute, where it can stop earlier for simpler tasks, or keep computing
when faced with more challenging instances. The goal of this work is to share the CTM and its associated
innovations, rather than pushing for new state-of-the-art results. To that end, we believe the CTM represents a
significant step toward developing more biologically plausible and powerful artificial intelligence systems.
-->
</p><p>
本レポートと併せて、モデルのチェックポイントを含む<a href="https://github.com/SakanaAI/continuous-thought-machines">CTMコードリポジトリ</a>を公開しました。また、CTMの機能を最大限に引き出すインタラクティブなデモをご覧いただくために、<a href="https://pub.sakana.ai/ctm/">プロジェクトページ</a>もぜひご覧ください。
<!--
Alongside this report, we release the <a href="https://github.com/SakanaAI/continuous-thought-machines">CTM code repository</a> that includes the model checkpoints. We also
encourage the reader to view <a href="https://pub.sakana.ai/ctm/">our project page</a> for interactive demonstrations to best highlight the CTM’s
capabilities.
-->
</p>
<h2>1. はじめに</h2>
<!--
<h2>1. Introduction</h2>
-->
<p>

ニューラルネットワーク（NN）はもともと生物の脳に着想を得たものですが、生物学的な脳とは大きく異なる性質を保っています。脳は時間とともに進化する複雑な神経ダイナミクスを示しますが、現代のNNは大規模な深層学習を容易にするために、そのような時間的ダイナミクスを意図的に抽象化しています。例えば、標準的なNNの活性化関数は、ニューロンの発火率を意図的に抽象化し、生物学的プロセスの時間的ダイナミクスを単一の静的な値に置き換えたものと見ることができます。このような単純化は、大規模機械学習の大きな進歩を可能にしましたが（Goodfellow et al., 2016; LeCun et al., 2015; Wei et al., 2022）、生物学的ニューラルコンピューティングを支配する基本原理からの逸脱をもたらしました。
<!--
Neural networks (NNs) were originally inspired by biological brains, yet they remain significantly
distinct from their biological counterparts. Brains demonstrate complex neural dynamics that evolve
over time, but modern NNs intentionally abstract away such temporal dynamics in order to facilitate
large-scale deep learning. For instance, the activation functions of standard NNs can be seen as an
intentional abstraction of a neuron’s firing rate, replacing the temporal dynamics of biological processes
with a single, static value. Such simplifications, though enabling significant advancements in largescale
machine learning (Goodfellow et al., 2016; LeCun et al., 2015; Wei et al., 2022), have resulted
in a departure from the fundamental principles that govern biological neural computation.
-->
</p><p>

数億年にわたる進化は、生物の脳にスパイクタイミング依存可塑性（STDP）（Caporale and Dan, 2008）やニューロン振動といった豊かな神経ダイナミクスを与えてきました。これらのメカニズム、特にスパイクタイミングと同期に固有の時間的コーディングを模倣することは、大きな課題となります。その結果、現代のニューラルネットワークは、計算を実行するために時間的ダイナミクスに依存せず、むしろ単純さと計算効率を優先しています。この抽象化は、特定のタスクのパフォーマンスを向上させる一方で、人間の認知の柔軟で一般的な性質と現在のAI機能との間に認識されているギャップの一因となっており、時間的処理に関連する可能性のある基本的な要素が現在のモデルに欠けていることを示唆しています（Chollet, 2019; Lake et al., 2017; Marcus, 2018）。
<!--
Over hundreds of millions of years, evolution has endowed biological brains with rich neural dynamics,
including spike-timing-dependent plasticity (STDP) (Caporale and Dan, 2008) and neuronal
oscillations. Emulating these mechanisms, particularly the temporal coding inherent in spike timing
and synchrony, presents a significant challenge. Consequently, modern neural networks do not rely
on temporal dynamics to perform compute, but rather prioritize simplicity and computational efficiency.
This abstraction, while boosting performance on specific tasks, contributes to a recognized
gap between the flexible, general nature of human cognition and current AI capabilities, suggesting
fundamental components, potentially related to temporal processing, are missing from our current
models (Chollet, 2019; Lake et al., 2017; Marcus, 2018).
-->
</p><p>

<strong>なぜこの研究を行うのか？</strong> 実際、多くの実用分野における現代のAIの目覚ましい高性能は、ニューラルダイナミクスのエミュレーションが不当であること、あるいは知能の時間的側面を明示的に考慮することが非実用的であることを示唆しています。しかしながら、人間の知能は非常に柔軟で、データ効率が高く、未知の状況にもうまく外挿できる流動性を備えており、学習と適応が時間の矢に結びついたオープンワールドに存在します。したがって、人間の知能には常識、オントロジー推論を活用する能力、透明性／説明可能性、そして強力な一般化が含まれます。AIはまだこれらの特性を説得力を持って示していません（Chollet, 2019; Hohenecker and Lukasiewicz, 2020; Marcus, 2018; Thompson et al., 2020）。
<!--
<strong>Why do this research?</strong> Indeed, the notably high performance of modern AI across many practical
fields suggests the emulation of neural dynamics is unwarranted, or that explicitly accounting for
temporal aspects of intelligence is anti-pragmatic. However, human intelligence is highly flexible,
data-efficient, is fluid in that it extrapolates well to unseen circumstances, and exists in an open
world where learning and adaptation are tied to the arrow of time. Consequently, human intelligence
includes common sense, the ability to leverage ontological reasoning, transparency/explainability,
and strong generalization. AI does not yet convincingly display these properties (Chollet, 2019;
Hohenecker and Lukasiewicz, 2020; Marcus, 2018; Thompson et al., 2020).
-->
</p><p>

これらの理由から、我々は、人工知能が最終的に人間の脳に匹敵する、あるいは凌駕するレベルの能力を達成するためには、時間がその中心的な要素となるべきだと主張する（Cariani and Baker, 2022; Maass, 2001）。したがって、本研究では、神経活動を知性の中心的な側面として見落とすことによって生じる大きな制約に対処する。我々は、神経タイミングを基礎要素として明示的に組み込むように設計された、新しいニューラルネットワークアーキテクチャである連続思考マシン（CTM）を導入する。我々の貢献は以下の通りである。
<!--
For these reasons, we argue that time should be a central component of artificial intelligence in order
for it to eventually achieve levels of competency that rival or surpass human brains (Cariani and
Baker, 2022; Maass, 2001). Therefore, in this work, we address the strong limitation imposed by
overlooking neural activity as a central aspect of intelligence. We introduce the Continuous Thought
Machine (CTM), a novel neural network architecture designed to explicitly incorporate neural timing
as a foundational element. Our contributions are as follows:
-->

<div class="styleBullet">
<ul><li>

1. 我々は、神経活動の時間的進化をモデル化する新たなアプローチとして、分離した内部次元を導入する。我々はこの次元を、人工ニューラルシステムにおいて思考が展開される次元と捉えており、それがこの命名法の由来である。内部再帰性はニューラルネットワークにおける新しい概念ではないが、我々の革新性は、この再帰性を利用して神経活動パターンを明示的に構築・操作することにある。離散的な内部ティック（Kirsch and Schmidhuber, 2021; Kirsch et al., 2022; Pedersen et al., 2024; Schwarzschild et al., 2021）を辿ることで、この内部次元はCTMが複雑で時間依存的な神経ダイナミクスを構築することを可能にし、神経イベントのタイミングが神経計算にとって重要であるという生物学的原理に直接的に取り組んでいる。これは、動的な神経活動を生成することよりも、主にシーケンシャルデータの処理に重点を置く従来の再帰的手法とは対照的です。
</li><br><li>2. 我々はニューロンの中間レベルの抽象化、すなわちニューロンレベルモデル（NLM）を提供します。NLMでは、各ニューロンが独自の内部重みを持ち、入力信号（すなわち、事前活性化）の履歴を処理して次の活性化を計算します（例えば、静的なReLUとは対照的です）。このアプローチは実装が簡単で、既存の深層学習アーキテクチャと適切にスケーリングでき、静的活性化関数よりも高い変動性を示す複雑なニューラル活性化ダイナミクス（すなわち、ニューラル活動）を生み出します（セクション3.2および5を参照）。
</li><br><li>3.我々は、CTMが観察（例えば、注意クエリを通して）し、予測（例えば、ロジットへの射影を通して）するための潜在表現として、神経同期を直接的に用います。この生物学的に着想を得た設計選択は、CTMが示す可能性のあるあらゆる知能発現において、神経活動が重要な要素であることを示しています。
<!--
1. We introduce an decoupled internal dimension, a novel approach to modeling the temporal
evolution of neural activity. We view this dimension as that over which thought can unfold in
an artificial neural system, hence the choice of nomenclature. While internal recurrence is not a
new concept in neural networks, our innovation lies in leveraging this recurrence to explicitly
construct and manipulate neural activity patterns. By progressing through discrete internal
ticks (Kirsch and Schmidhuber, 2021; Kirsch et al., 2022; Pedersen et al., 2024; Schwarzschild
et al., 2021), this internal dimension allows the CTM to build up complex, time-dependent
neural dynamics, directly addressing the biological principle that the timing of neural events
is crucial for neural computation. This contrasts with traditional uses of recurrence, which
primarily focus on processing sequential data rather than generating dynamic neural activity.
</li><br><li>2. We provide a mid-level abstraction for neurons, which we call neuron-level models (NLMs),
where every neuron has its own internal weights that process a history of incoming signals (i.e.,
pre-activations) to calculate its next activation (as opposed to a static ReLU, for example). This
approach is simple to implement, scales well with existing deep learning architectures, and results in the emergence of complex neural activation dynamics (i.e., neural activity), exhibiting
a higher degree of variability than static activation functions (see Sections 3.2 and 5).
</li><br><li>3. We use neural synchronization directly as the latent representation with which the CTM
observes (e.g., through an attention query) and predicts (e.g., via a projection to logits). This
biologically-inspired design choice puts forward neural activity as the crucial element for any
manifestation of intelligence the CTM might demonstrate.
-->
</li></ul></div>
</p><p>

<strong>推論モデルと再帰性</strong>。人工知能の最先端は重大な岐路に立たされています。それは、単純な入出力マッピングを超えて、真の推論能力へと移行することです。既存モデルのスケーリングは目覚ましい進歩をもたらしましたが、それに伴う計算コストとデータ需要は持続不可能であり、このアプローチの長期的な実行可能性に疑問が生じています。シーケンシャルデータの場合、長年用いられてきた再帰型アーキテクチャ（Dey and Salem, 2017; Hochreiter and Schmidhuber, 1997; Medsker and Jain, 1999）は、主にトランスフォーマーベースのアプローチ（Vaswani et al., 2017）に取って代わられました。しかしながら、再帰性はモデルの複雑性を拡張するための自然な手段として再び浮上しています。再帰性は、反復処理と時間の経過に伴う情報の蓄積を可能にするため、有望です。現代のテキスト生成モデルでは、中間世代を、テスト時に追加の計算を可能にする再帰的な形式として用いています。最近、他の研究によって、潜在層の再帰的適用の利点が実証されています (Geiping et al., 2025; Jaegle et al., 2021; Yang et al., 2023)。
<!--
<strong>Reasoning models and recurrence.</strong> The frontier of artificial intelligence faces a critical juncture:
moving beyond simple input-output mappings towards genuine reasoning capabilities. While scaling
existing models has yielded remarkable advancements, the associated computational cost and
data demands are unsustainable and raise questions about the long-term viability of this approach.
For sequential data, longstanding recurrent architectures (Dey and Salem, 2017; Hochreiter and
Schmidhuber, 1997; Medsker and Jain, 1999) have largely been superseded by transformer-based
approaches (Vaswani et al., 2017). Nevertheless, recurrence is re-emerging as a natural avenue for
extending model complexity. Recurrence is promising because it enables iterative processing and the
accumulation of information over time. Modern text generation models use intermediate generations
as a form of recurrence that enables additional compute during test-time. Recently, other works have
demonstrated the benefits of the recurrent application of latent layers (Geiping et al., 2025; Jaegle
et al., 2021; Yang et al., 2023).
-->

</p><p>

これらの手法は生物学的脳の再帰構造に近づく一方で、根本的なギャップが依然として残っています。再帰は不可欠ではあるものの、パズルの一部に過ぎないと私たちは考えています。再帰によって解き明かされる時間的ダイナミクス、つまり神経活動の正確なタイミングと相互作用も同様に重要です。CTMは既存のアプローチと3つの点で異なります。(1) 内部の「思考」次元により、考えられるあらゆるデータモダリティにおける逐次的な思考が可能になります。(2) プライベートなニューロンレベルのモデルにより、正確な神経タイミングを考慮することができます。(3) 神経同期を、タスク解決のための表現として直接使用できます。
<!--
While such methods bring us closer to the recurrent structure of biological brains, a fundamental gap
nevertheless remains. We posit that recurrence, while essential, is merely one piece of the puzzle.
The temporal dynamics unlocked by recurrence – the precise timing and interplay of neural activity –
are equally crucial. The CTM differs from existing approaches in three ways: (1) the internal ‘thought’
dimension enables sequential thought on any conceivable data modality; (2) private neuron-level
models enables the consideration of precise neural timing; and (3) neural synchronization used
directly as a representation for solving tasks.
-->
</p><p>

<strong>有用な副作用</strong>　CTMの内部的な再帰性は思考に類似しており（そのため、この名称が付けられました）、より単純なタスク（例えば、識別しやすい画像、図5参照）では「思考」を早期に停止し、より困難なタスク（例えば、長い迷路、セクション4.3参照）ではより深く思考することで、ある種の適応型計算を可能にします。特に、CTMは、調整が困難な追加の損失を必要とせずに、一種の適応型計算を実現します（Graves, 2016）。実際、解釈可能で直感的な問題解決戦略の出現が観察されており、ニューラルタイミングを活用することで、より多くの新たなメリットと、潜在的により効果的なAIシステムにつながる可能性があることを示唆しています。神経タイミングを明示的に設定することのもう一つのプラス効果は、情報をこのタイミング内に符号化できることです。その結果、文脈化能力が向上します。私たちはこれを検証するために2D迷路解法チャレンジを設計しました（セクション4）。
<!--
<strong>Useful side effects</strong>　The CTM’s internal recurrence is analogous to thought (hence the chosen
nomenclature), where it can stop ‘thinking’ earlier for simpler tasks (e.g., an easily identifiable image;
see Figure 5), or go deeper for more challenging tasks (e.g., a long maze; see Section 4.3), thus
enabling a form of adaptive compute. In particular, the CTM achieves a kind of adaptive computation
without the need for additional losses that are difficult to tune (Graves, 2016). Indeed, we observe
the emergence of interpretable and intuitive problem-solving strategies, suggesting that leveraging
neural timing can lead to more emergent benefits and potentially more effective AI systems. Another
positive effect of being explicit about neural timing is that information can be encoded within this
timing, the result of which is a greater capacity for contextualization – we design our 2D maze solving
challenge to test this (Section 4).
-->
</p><p>

本論文の残りの部分は以下のように構成されています。第2節ではCTMの技術的詳細を説明します。第3節から第10節では、CTMを画像分類、2次元迷路、ソート、パリティ、質問応答、そして単純な強化学習タスクに適用します。各実験は特定の特性を調査するように設計されており、可能な限りベースラインと比較します。第12節では、得られた知見を考察し、今後の研究の方向性を示します。第13節では最終的な結論を導き出します。CTMを通して神経タイミングを明示的にモデル化することで、より生物学的に妥当で高性能な人工知能システムへの道を切り開くことを目指します。
<!--
The rest of this paper is structured as follows. In Section 2 we give the technical details of the CTM.
In Section 3 through 10 we apply the CTM to image classification, 2D mazes, sort, parity, questionanswering,
and simple reinforcement learning tasks. Each experiment is designed to investigate
specific characteristics and we compare to baselines wherever possible. In Section 12 we discuss our
findings, suggesting avenues for future work. We draw final conclusions in Section 13. By explicitly
modeling neural timing through the CTM, we aim to pave the way for more biologically plausible and
performant artificial intelligence systems. 
-->
</p>

<h2>2. 手法</h2>
<!--
<h2>2. Method</h2>
-->
<p>

連続思考マシン（CTM）は、データ思考への新たなアプローチを可能にするニューラルネットワークアーキテクチャです。従来のフィードフォワードモデルとは異なり、ニューラルダイナミクスの概念を機能の中核要素として明示的に組み込んでいます。図1はCTMの概要を示しており、番号1から番号9はフローを示しています。リスト1は、分かりやすくするために簡略化された概要リストを示しています。図1の黄色の番号は、本稿の残りの部分で参照されます。
<!--
The Continuous Thought Machine (CTM) is a neural network architecture that enables a novel
approach to thinking about data. It departs from conventional feed-forward models by explicitly
incorporating the concept of neural dynamics as the central component to its functionality. Figure 1
gives an overview of the CTM, with numbers ① to ⑩ designating flow, and Listing 1 gives a simplified
overview listing for clarity. The yellow numbers in Figure 1 will be referred to throughout the rest of
this paper.
-->

</p>
<center><img src="images/fig1.png"></center>
<p>
図1 | CTMアーキテクチャの概要。シナプスモデル（重みは青線で示される、式1）は、ニューロン間の相互作用をモデル化し、事前活性化を生成します。各ニューロンについて、事前活性化の履歴が保持され（式2）、その最新の履歴がニューロンレベルモデル（重みは赤線で示される、式3）によって事後活性化の生成に使用されます。事後活性化の履歴も保持され（式4）、同期行列（式5および式10）を計算するために使用されます。同期行列からニューロンペアが選択（セクション2.4.1を参照）され、CTMが出力（式6）を生成し、相互注意（式7および式8）を通じてデータを変調するための潜在表現が生成されます。変調されたデータ（例えば、注意出力）は、次の内部ティックのポストアクティベーションと連結されます。
<!--
Figure 1 | CTM architecture overview. The ① synapse model (weights depicted as blue lines; Equation 1) models the
cross-neuron interactions to produce pre-activations. For each neuron, a ② history of pre-activations is kept (Equation 2),
the most recent of which are used by the ③ neuron-level models (weights depicted as red lines, Equation 3) to produce
④ post-activations. A ⑤ history of post-activations is also kept (Equation 4) and used to ⑥ compute a synchronization
matrix (Equation 5 and Equation 10). Neuron pairs are ⑦ selected (see Section 2.4.1) from the synchronization matrix,
yielding the ⑧ latent representations with which the CTM ⑨ produces outputs (Equation 6) and modulates data through
cross-attention (Equation 7 and 8). Modulated data (e.g., attention outputs) are ⑩ concatenated with post-activations for
the next internal tick.
-->
</p><p>

他の再帰型アーキテクチャ（RNNなど）は、データとは別の内部時間次元を組み込むように設定できます（Graves, 2016; Kirsch and Schmidhuber, 2021; Kirsch et al., 2022; Pedersen et al., 2024; Schwarzschild et al., 2021）が、CTMは2つの重要な点で異なります。(1)従来の活性化関数を使用する代わりに、CTMはそれぞれ独自の重みを持つニューロンレベルのモデルを事前活性化の履歴に適用して、複雑なニューロンレベルの活動を生成します（例についてはセクション3を参照）。(2)CTMは、データを変調して出力を生成する際に、ニューラルネットワークの同期を潜在表現として直接使用します（セクション2.4を参照）。これにより、ニューロンの正確なタイミングと相互作用を作成、維持、活用する新しいレベルの能力が効果的に実現されます。以下のサブセクションでは、CTMについて詳しく説明します。
<!--
Other recurrent architectures (e.g., RNNs) can be set up to incorporate an internal time dimension
that is separate from data (Graves, 2016; Kirsch and Schmidhuber, 2021; Kirsch et al., 2022; Pedersen
et al., 2024; Schwarzschild et al., 2021), but the CTM differs in two crucial ways: (1) instead of
using conventional activation functions, the CTM applies neuron-level models, each with their own
weights, to histories of pre-activations in order to produce complex neuron-level activity (see Section 3
for examples); and (2) the CTM uses neural synchronization directly as the latent representation
when modulating data and producing outputs (see Section 2.4), effectively enabling a new depth of
capacity where it creates, maintains, and leverages the exact timing and interplay of neurons. In the
following subsections we will describe the CTM in detail.
-->

</p><p>

<code>
# 定義 ( 簡潔にするためにハイパーパラメータは示していない )<br>
# バックボーンとしては、例えば画像用の ResNet などが考えられる。<br>
backbone = FeatureEncoder ()<br>
# Q, KVプロジェクター、および標準アテンションモジュール<br>
q_projector , kv_projector = Linear (), Linear ()<br>
attn = MultiHeadAttention ()<br>
# シナプスモデルは線形、MLP、U-NETのいずれか<br>
synapses = MLP ()<br>
# ニューロンレベルモデル（リスト2参照）<br>
neuron_level_models = NLMS ()<br>
# 同期からの出力プロジェクター（リスト3を参照）<br>
output_proj = Linear ()<br>
# 事前活性化とZを学習可能なパラメータとして初期化する<br>
# Dはモデルの幅<br>
z_init = Parameter ( size =(D))<br>
# Mはニューロンの記憶長<br>
pre_acts_history_init = Parameter ( size =(D, M))<br>
# MODEL LOGIC <br>
# バックボーンを使用して入力を特徴付け、KVトークンを計算する<br>
kv = kv_projector ( backbone ( inputs ))<br>
# 各ミニバッチで、学習可能なpre_act_historyを初期化する<br>
pre_acts_history = pre_acts_history_init . unsqueeze (0). repeat (B, dim =0) # (B, D, M)<br>
# そして、学習可能なz_initでpost_acts_historyを開始する<br>
post_acts_history = [ z_init . unsqueeze (0). repeat (B, dim =0)]<br>
outputs_history = []<br>
# クエリデータの初期アクション同期を取得する<br>
synch_a = compute_synch ( post_acts_history , type =" action ")<br>
# その他の初期化（学習可能な開始履歴と最初の事前attn roundを含む）<br>
for step in range ( n_thought_steps ):<br>
# Project attention query の同期をオフにする<br>
q = q_projector ( synch_a )<br>
attn_out = attn (q, kv , kv)<br>
# アテンションの出力を連結し、シナプスを介して処理する<br>
pre_acts = synapses ( concat (( attn_out , z )))<br>
# 事前アクティベーションの履歴を保存する。これはFIFO構造<br>
pre_acts_history = concat (( pre_acts_history [:, :, : -1] , pre_acts ), dim = -1)<br>
# 履歴を使用してポストアクティベーションを計算する（リスト2を参照）<br>
z = neuron_level_models ( pre_acts_history )<br>
post_acts_history . append (z)<br>
# 同期を計算する（リスト3を参照）<br>
synch_a = compute_synch ( post_acts_history , type =" action ")<br>
synch_o = compute_synch ( post_acts_history , type =" output ")<br>
# プロジェクト予測/出力オフ同期<br>
outputs_history . append ( output_proj ( synch_o ))<br>
# 損失関数の思考ステップごとの出力を返す<br>
return outputs_history<br>
</code>
<br>
リスト1 | CTMコードの簡略化された概要。特徴はバックボーン（画像の場合はResNetレイヤーなど）を用いてエンコードされ、データはニューラルネットワークの同期からクエリを投影することで処理されます。情報はMLPシナプスモデルを用いてニューロン間で共有され、事前活性化が生成されます。追跡された事前活性化の履歴にプライベートニューロンレベルモデルが適用されます（リスト2を参照）。同期は追跡された事後活性化の履歴から計算されます（リスト3を参照）。そして、出力は同期から投影されます。すべてのコードは<a href="https://github.com/SakanaAI/continuous-thought-machines">ここから</a>入手できます。
<!--
Listing 1 | Simplified overview of the CTM code. Features are encoded using a backbone (e.g., ResNet layers for images),
data is attended to by 9 projecting a query from neural synchronization, information is shared across neurons using an
1 MLP synapse model to produce pre-activations, 3 private neuron-level models are applied to a 2 tracked history of
pre-activations (see Listing 2), synchronization is computed from a 5 tracked history of post-activations (see Listing 3),
and outputs are 9 projected off of synchronization. All code is available here.
-->
</p>
<h3>2.1. 継続的な思考：内部シーケンスの次元</h3>
<!--
<h3>2.1. Continuous thought: the internal sequence dimension</h3>
-->
<p>
まず、認知が生じ得る内部次元 \(𝑡∈{1, . . . , 𝑇}\) を導入する。この内部次元の1つのステップは、図1から図2への流れとして示される。この次元はデータとは分離されており、内部的に展開され、どのデータ次元にも結び付けられていない。内部次元に沿った再帰性は決して新しい概念ではない（Chahine et al., 2023; Geiping et al., 2025; Jaeger, 2007）。近年、現代のAIに推論機能を組み込もうとする動きが高まっているため、この概念はますます注目を集めている。 RNNやTransformerといった従来のシーケンシャルモデルとは異なり、CTMはデータに内在するシーケンス（例えば、文中の単語や動画のフレーム）に従って入力を段階的に処理しますが、CTMは内部の「思考ステップ」という自己生成タイムラインに沿って動作します。この内部展開により、画像や迷路といった静的または非シーケンシャルなデータを処理する場合でも、モデルは反復的に表現を構築し、改良することができます。その結果、CTMは外部タイミングから切り離された思考プロセスを行うことができ、より柔軟で解釈しやすく、生物学に着想を得た計算が可能になります。関連研究（Kirsch and Schmidhuber, 2021; Kirsch et al., 2022; Pedersen et al., 2024; Schwarzschild et al., 2021）で使用されている既存の命名法に従い、以降はこれらの思考ステップを「内部ティック」と呼びます。 CTMの内部次元は、神経活動のダイナミクスが展開される領域です。私たちは、このようなダイナミクスが知的思考の礎となる可能性が高いと考えています。リスト1のforループは、図1に示したプロセスを表現しています。
<!--
We start by introducing the internal dimension over which cognition can occur: \(𝑡 ∈ {1, . . . , 𝑇}\), a
single step of which is shown as the flow from ① to ⑩ . This dimension is decoupled from the data
in that it unfolds internally and is not tied to any data dimensions. Recurrence along an internal
dimension is by no means a new concept (Chahine et al., 2023; Geiping et al., 2025; Jaeger, 2007),
and it is garnering increased focus owing to a recent drive to build reasoning capabilities into modern
AI. Unlike conventional sequential models – such as RNNs or Transformers – that process inputs
step-by-step according to the sequence inherent in the data (e.g., words in a sentence or frames in a
video), the CTM operates along a self-generated timeline of internal ‘thought steps.’ This internal
unfolding allows the model to iteratively build and refine its representations, even when processing
static or non-sequential data such as images or mazes. As a result, the CTM can engage in a thought
process that is decoupled from external timing, enabling more flexible, interpretable, and biologically
inspired computation. To conform with existing nomenclature used in related works (Kirsch and
Schmidhuber, 2021; Kirsch et al., 2022; Pedersen et al., 2024; Schwarzschild et al., 2021), we refer to
these thought steps as ‘internal ticks’ from here on. The CTM’s internal dimension is that over which
the dynamics of neural activity can unfold. We believe that such dynamics are likely a cornerstone of
intelligent thought. The for loop in Listing 1 captures the process depicted in Figure 1.
-->
</p>
<h3>2.2. 再帰重み：シナプス</h3>
<!--
<h3>2.2. Recurrent weights: synapses</h3>
-->
<p>
①シナプスモデル \(𝑓_{𝜃_{syn}}\) は、共有𝐷次元潜在空間 \(z^𝑡 ∈ \mathbb ℝ^𝐷\) のニューロンを相互接続します。
ここで、𝑡 はCTMの再帰的展開における現在の内部ティックです。𝜃syn は再帰的シナプスモデルの重みです。シナプスモデルは、標準的な活性化関数が続く単一の線形投影としてパラメータ化することも、多層パーセプトロン (MLP) としてパラメータ化することもできます。実験的に、U-NET風 (Ronneberger et al., 2015) MLPアーキテクチャがすべてのタスクでより優れたパフォーマンスを発揮することがわかりました (シナプスモデルの詳細については付録B.1を参照)。これは、シナプス接続が追加のより深い計算から恩恵を受けることを示しています。シナプスモデルを適用すると、内部ティック \(𝑡\) における事前活性化と考えられるものが生成されます。
<!--
A ① synapse model, \(𝑓_{𝜃_{syn}}\) , interconnects the neurons of a shared 𝐷-dimensional latent space, \(z^𝑡 ∈ \mathbb ℝ^𝐷\),
where 𝑡 is the current internal tick in the recurrent unfolding of the CTM. 𝜃syn are the weights of
the recurrent synapse model. The synapse model can be parameterized as a single linear projection
followed by a standard activation function, or it can be a multi-layer perceptron (MLP). We found
experimentally that a U-NET-esque (Ronneberger et al., 2015) MLP architecture performed better for
all tasks (see Appendix B.1 for details of the synapse model). This indicates that synaptic connections
benefit from additional, deeper compute. Applying the synapse model produces what we consider
pre-activations at internal tick \(𝑡\):
-->
\[
a^𝑡 = 𝑓_{𝜃_{syn}} (concat(z^𝑡 , o^𝑡)) ∈ \mathbb ℝ^𝐷 \tag{1}
\]

ここで、\(o^𝑡\)は入力データ（直接またはアテンションの出力として。式8を参照）からのものであり、2.4節で説明します。
<!--
where \(o^𝑡\) is from input data (either directly or as the output of attention; see Equation 8), which we
will explain in Section 2.4.
-->
</p><p>

最新のM個の事前アクティベーションは、事前アクティベーションの「履歴」②に収集されます。
<!--
The 𝑀 most recent pre-activations are then collected into ② a pre-activation ‘history’:
-->
\[
A^𝑡 = [a^{𝑡−𝑀+1}\; a^{𝑡−𝑀+2}\;\cdots a^𝑡 ]∈ \mathbb ℝ^{𝐷×𝑀}  \tag{2}
\]

履歴の最初の \(𝑀\) 要素と最初の \(z^{𝑡=1}\) を初期化する必要があります。当初はこれらの2つのゼロを初期化する実験を行いました（RNNでも同様の戦略が採用されています）。しかし、これらのパラメータを学習可能にすることが最適であることがわかりました。
<!--
The first \(𝑀\) elements in the history and the first \(z^{𝑡=1}\) need to be initialized. We initially experimented
with initializing these two zeros (a similar strategy is undertaken for RNNs), but found that making
these learnable parameters was best.
-->
</p>

<h3>2.3. プライベートパラメータ化されたニューロンレベルモデル</h3>
<!--
<h3>2.3. Privately-parameterized neuron-level models</h3>
-->
<p>
<code>
# Initialisations<br>
weights_1 = Parameter ( shape =(M, d_hidden , d_model ))<br>
bias_1 = zeros ( shape =(1 , d_hidden , d_model ))<br>
weights_2 = Parameter ( shape ( d_hidden , d_model ))<br>
bias_2 = zeros ( shape =(1 , d_model ))<br>
# Forward pass<br>
# b=batch , M= memory , d= d_model , h= d_hidden<br>
# inputs are shape (b, d, M)<br>
inputs = pre_acts_history [-M:]<br>
out = einsum ('bdM ,Mhd -> bdh ', inputs , weights_1 ) + bias_1<br>
out = einsum ('bdh ,hd ->bd ', out , weights_2 ) + bias_2<br>
</code>
<br>
リスト 2 | ニューロンレベルモデル：③。einsum を使用すると、ニューロンレベルモデルの適用が大幅に簡素化され、高速化されます。出力を並列に計算できるためです。最初の einsum は、入力履歴（最新の 𝑀 に切り捨てられた）から各ニューロンの h 次元潜在変数を計算します（②）。次に、2 番目の einsum は、ニューロンごとの単一の活性化を計算します（ここでは簡潔にするために「1」次元は無視します）。
<!--
Listing 2 | Neuron-level models: ③ . Using einsum greatly simplifies and speeds up the application of neuron-level models<br>
as their outputs can be computed in parallel. The first einsum computes a h-dimension latent for each neuron from the<br>
(truncated to 𝑀 most recent) incoming history, ②. The second einsum then computes the single activation per-neuron<br>
(ignore the ‘1’ dimension here for simplicity).<br>
-->
</p><p>
𝑀は、各ニューロンレベルモデルが扱う事前活性化の履歴の長さを実質的に定義します。𝑀の値の範囲をテストした結果、10～100の範囲が効果的であることがわかりました。各ニューロン \(\{1, . . . , 𝐷\}\) には、それぞれ独自の③プライベートパラメータ化モデルが与えられ、このモデルは、我々が④事後活性化と呼ぶものを生成します。
<!--
𝑀 effectively defines the length of the history of pre-activations that each neuron-level model works
with. We tested a range of values for 𝑀, and found a range of 10-100 to be effective. Each neuron,
\(\{1, . . . , 𝐷\}\), is then given its own ③ privately parameterized model that produces what we consider
④ post-activations:
-->
\[
z_d^{𝑡+1} = 𝑔_{𝜃_𝑑} (A_d^𝑡) \tag{3}
\]

ここで、\(𝜃_𝑑\) はニューロン \(𝑑\) の一意のパラメータであり、\(z_d^{𝑡+1}\) はベクトル内の全ての事後活性化を含む単一のユニットです。幅 𝑑hidden の単一の隠れ層を持つ MLP を使用します。\(A_d^𝑡\) は \(𝑀\) 次元ベクトル（時系列）です。ニューロンに独自の内部モデルを持たせるには、追加のパラメータが必要となり、\(𝐷 × (𝑀 × 𝐻_{𝑑𝑖𝑚} + 𝐻_{𝑑𝑖𝑚})\) のようにスケーリングされます（ここで、\(𝐻_{𝑑𝑖𝑚}\) はニューロンレベルのMLPの幅であり、単純化のためバイアスパラメータは無視します）。しかし、この追加のパラメータコストにより、モデリングの自由度が高まります。
<!--
where \(𝜃_𝑑\) are the unique parameters for neuron \(𝑑\), and \(z_d^{𝑡+1}\) is a single unit in the vector that contains
all post-activations. We use an MLP with a single hidden layer of width 𝑑hidden. \(A_d^𝑡\) is a \(𝑀\)-dimensional
vector (time series). Letting neurons have their own internal models does require additional parameters,
scaling as \(𝐷 × (𝑀 × 𝐻_{𝑑𝑖𝑚} + 𝐻_{𝑑𝑖𝑚})\) (where \(𝐻_{𝑑𝑖𝑚}\) is the width of the neuron-level MLPs, ignoring
bias parameters for simplicity). This additional parameter cost enables more modeling freedom,
however.
-->
</p><p>

ニューロンの事後活性化の全セットは、アテンション出力（セクション2.4を参照）と連結され、\(𝑓_{𝜃_1}\)に再帰的に入力され、展開される思考プロセスにおける次のステップ（\(𝑡 +1\)）の事前活性化を生成します。
CTMが採用する再帰的思考プロセスは、リスト1と2に示されています。ここでは、CTMが同期を通じてデータ（入力と出力の両方）とどのように相互作用するかについて説明します。
<!--
The full set of neuron post-activations are then 10 concatenated with attention output (see Section 2.4)
and fed recurrently into \(𝑓_{𝜃_1}\) to produce pre-activations for next step, \(𝑡 +1\), in the unfolding thought process.
The recurrent thought-process employed by the CTM is captured in Listings 1 and 2. We will nonow
discuss how the CTM interacts with data (both inputs and outputs) through synchronization.
-->
</p>
<h3>2.4. 神経同期：データと出力の調整</h3>
<!--
<h3>2.4. Neural synchronization: modulating data and outputs</h3>
-->
<p>
<code>
# AT INITIALISATION :<br>
# Pre choose D_chosen neuron pairs from D total neurons<br>
# D_chosen can be D_out or D_action<br>
# Other neuron selection strategies exist , but here we show random selection<br>
idxs_left = randint (low =0, high =D, size = D_chosen )<br>
idxs_right = randint ( low =0, high =D, size = D_chosen ) # can overlap<br>
# Define learnable exponential decay scaling factors per neuron pair<br>
r = Parameter ( zeros (1, D_chosen , 1))<br>
# INITIALISATION OVER .<br>
# IN FORWARD PASS :<br>
S = stack ( post_acts_history , 1) # S is of shape [B, T= history length ]<br>
# decay BACK in time<br>
t_back = range (T -1, -1, -1). reshape (1, T, 1)<br>
# Compute per NEURON PAIR exponential decays , and expand over D_chosen<br>
exp_decay = exp(- t_back * r). expand (1, T, D_chosen )<br>
# Compute weighted inner dot products using differet subsets of neurons<br>
S_multiplied = S[: ,: , idxs_left ] * exp_decay * S[: ,:, idxs_right ] # [B, T, D_chosen ]<br>
# Sum over the free T dimension and normalise by sqrt of AUC of decays<br>
synch_representation = ( S_multiplied ). sum (1)/ sqrt ( exp_decay . sum (1)) # [B, D_chosen ]<br>
</code>
<br>
リスト3 | リスト1で使用した潜在表現を作成するためのニューラル同期。慎重な再形成とブロードキャストにより、ニューロンペアごとに学習可能な指数関数的減衰を同期に使用できるようになり、CTMは複雑なタイミング依存性を学習できます。減衰パラメータはゼロ（つまり減衰なし）に初期化されます。このプロセスは出力とアクションに対して繰り返されます（セクション2.4.1を参照）。実際には、計算オーバーヘッドを大幅に削減する再帰的なアプローチを使用します。付録Kを参照してください。
<!--
Listing 3 | Neural synchronization to create the latent representations used in Listing 1. Careful reshaping and broadcasting
enables the use of per neuron-pair learnable exponential decays for synchronization, which lets the CTM learn complex
timing dependencies. The decay parameters are initialized as zeros (i.e., no decay). This process is repeated for output and
action (see Section 2.4.1). In practice we use a recursive approach that greatly reduces compute overhead; see Appendix K.
-->
</p><p>

CTMは外界とどのように相互作用するべきでしょうか？具体的には、CTMはどのように入力を消費し、出力を生成するべきでしょうか？私たちは、思考に似た何かが展開できるタイミングの次元を導入しました。また、CTMとデータとの関係（いわば相互作用）は、ニューロンの状態（ある時点）のスナップショットではなく、ニューロン活動の進行中の時間的ダイナミクスに依存するようにしたいと考えています。<sup>1</sup> 解決策として、私たちは再び自然の脳に着目し、神経同期の概念（Uhlhaas et al., 2009）が適切かつ強力であることを見出しました。同期を実現するために、私たちはまず、活性化後の活動を活性化後の「履歴」に収集することから始めます。
<!--
How should the CTM interact with the outside world? Specifically, how should the CTM consume
inputs and produce outputs? We introduced a timing dimension over which something akin to
thought can unfold. We also want the CTM’s relationship with data (its interaction, so to speak) to
depend not on a snapshot of the state of neurons (at some 𝑡), but rather on the ongoing temporal
dynamics of neuron activities.<sup>1</sup> By way of solution, we turn again to natural brains for inspiration
and find the concept of neural synchronization (Uhlhaas et al., 2009) both fitting and powerful. For
synchronization we start by collecting the post-activations into ⑤ a post-activation ‘history’:
-->
</p><p class="margin-large">
<sup>1</sup>
私たちはスナップショット表現から始めましたが、ニューロンの振動的な挙動が現れたため、安定した挙動を得るのに苦労しました。
<!--
We did begin with snapshot representations but struggled to get stable behavior owing to the emergent oscillatory
behavior of neurons.
-->
</p><p>

\[
\mathbf Z^𝑡 =[z^1\; z^2\;· · ·\; z^𝑡] ∈ \mathbb ℝ^{𝐷×𝑡} \tag{4}
\]

\(\mathbf Z^𝑡\) の長さは現在の内部ティックに等しいため、この次元は固定されておらず、任意の大きさになり得る。神経同期は、活性化後の履歴間の内部ドット積によって生成される行列として定義される。
<!--
The length of \(\mathbf Z^𝑡\) is equal to the current internal tick, meaning that this dimension is not fixed and
can be arbitrarily large. We define neural synchronization as the matrix yielded by 6 the inner dot
product between post-activation histories:
-->
\[
\mathbf S^𝑡 = \mathbf Z^𝑡 · (\mathbf Z^𝑡)^⊺ ∈ \mathbb ℝ^{𝐷×𝐷} \tag{5}
\]
<h4>2.4.1. ニューロンペアリング：サブサンプリングアプローチ</h4>
<!--
<h4>2.4.1. Neuron pairing: a sub-sampling approach</h4>
-->
<p>

この行列は \(\mathcal O(D^2)\) でスケールするため、ニューロン \(𝑖\) と \(𝑗\) 間の同期を捉える \((𝑖, 𝑗)\) 行列ペアをサブサンプリングするのが実際的です。これを行うには、\(\mathbf S\) から \(𝐷_{out}\) と \(𝐷_{action} (𝑖, 𝑗)\) のペアをランダムに選択し、2 つの同期表現 \(\mathbf S_{out}^𝑡 ∈ \mathbb ℝ^{𝐷_{out}}\) と \(\mathbf S_{action}^𝑡 ∈ \mathbb ℝ^{𝐷_{action}}\) を収集します。
\(\mathbf S_{out}^𝑡\) は次のように出力空間に投影できます。
<!--
Since this matrix scales in \(\mathcal 𝑂(𝐷^2)\) it makes practical sense to subsample \((𝑖, 𝑗)\) row-column pairs, which
capture the synchronization between neurons \(𝑖\) and \(𝑗\). To do so we randomly select \(𝐷_{out}\) and \(𝐷_{action} (𝑖, 𝑗)\) pairs from \(\mathbf S\), thus collecting two synchronization representations, \(\mathbf S_{out}^𝑡 ∈ \mathbb ℝ^{𝐷_{out}}\) and \(\mathbf S_{action}^𝑡\) ∈ \mathbb ℝ^{𝐷_{action}}\) .
\(\mathbf S_{out}^𝑡\) can then be projected to an output space as:
-->
\[
\mathbf y^𝑡 = \mathbf W_{out} · \mathbf S_{out}^𝑡  \tag{6}
\]
そして、\(\mathbf S_{action}^𝑡\) は世界に対してアクションを起こすために使われる（例えば、我々の設定では注意を介して）。
<!--
and \(\mathbf S_{action}^𝑡\) can be used to take actions in the world (e.g., via attention as is in our setup):
-->
\[
\mathbf q^𝑡 = \mathbf W_{in} · \mathbf S_{action}^𝑡  \tag{7}
\]

ここで、\(\mathbf W_{out}\) と \(\mathbf W_{in}\) は学習済みの重み行列であり、同期を観測用ベクトル（例：注意クエリ、\(\mathbf q^𝑡\)）または出力用ベクトル（例：ロジット、\(\mathbf y^𝑡\)）に投影する。\(\mathbf S^𝑡、𝐷_{out}\) と \(𝐷_{action}\) には \((𝐷 × (𝐷 + 1))/2\) 個の一意のペアリングが存在するが、この値よりも桁違いに小さくなる可能性がある。とはいえ、完全な同期行列は大きな表現であり、将来的に大きな可能性を秘めている。
ほとんどの実験では、標準的なクロスアテンション（Vaswani et al., 2017）を使用した。
<!--
where \(\mathbf W_{out}\) and \(\mathbf W_{in}\) are learned weight matrices that project synchronization into vectors for observation
(e.g., attention queries, \(\mathbf q^𝑡\)) or outputs (e.g., logits, \(\mathbf y^𝑡\)). Even though there are \((𝐷 × (𝐷 + 1))/2\) unique pairings in \(\mathbf S^𝑡, 𝐷_{out}\) and \(𝐷_{action}\) can be orders of magnitude smaller than this. That said, the
full synchronization matrix is a large representation that has high future potential.
In most of our experiments we used standard cross attention (Vaswani et al., 2017):
-->

\[
\mathbf o^𝑡 = Attention(𝑄 = \mathbf q^𝑡 , 𝐾𝑉 = FeatureExtractor(data))  \tag{8}
\]

ここで、まずResNet (He et al., 2016)などの「FeatureExtractor」モデルを用いて、キーと値の有用な局所特徴を構築します。\(\mathbf o^𝑡 ∈ \mathbb ℝ^{𝑑_{input}}\) は、\(𝑛_{heads}\) ヘッドを用いたアテンションの出力であり、次の繰り返しサイクルのために \(\mathbf z^{𝑡+1}\) と連結されます。わかりやすくするために、リスト3に、学習可能な時間的依存性のスケーリング（下記参照）を含め、このプロセスがコードでどのように見えるかを示します。
<!--
where a ‘FeatureExtractor’ model, e.g., a ResNet (He et al., 2016), is first used to build useful local
features for the keys and values. \(\mathbf o^𝑡 ∈ \mathbb ℝ^{𝑑_{input}}\) is the output of attention using \(𝑛_{heads}\) heads and is ⑩ concatenated with \(\mathbf z^{𝑡+1}\) for the next cycle of recurrence. For clarity, Listing 3 demonstrates what this
process looks like in code, including learnable temporal dependency scaling (see below).
-->

</p><p>

<strong>時間依存性のスケーリング</strong>　 \(\mathbf S^𝑡\) はステップ \(𝑡\) までのすべての内部ティックからの情報を集約するため、後のステップは同期への影響が減少する可能性があります。CTMに過去の活動の影響を調整する柔軟性を提供するために、学習可能な指数関数的に減少する再スケーリング係数を導入します。各ニューロンペア\(𝑖𝑗\)に対して学習可能なスケーリング係数\(𝑟_{𝑖𝑗} ≥ 0\)が与えられた場合、\(𝑡\) にわたる再スケーリング係数は次のように計算されます。
<!--
<strong>Scaling temporal dependency</strong>　Since S𝑡 aggregates information from all previous internal ticks up
to step 𝑡, later steps could potentially have a diminishing influence on synchronization. To provide the
CTM with the flexibility to modulate the influence of past activity, we introduce learnable exponentially
decaying rescaling factors. Given learnable scaling factors \(𝑟_{𝑖 𝑗} ≥ 0\) for each neuron pair \(𝑖 𝑗\), the rescaling
factors over 𝑡 are computed as:
-->

\[
\mathbf R_{ij}^𝑡 =[\exp(−𝑟_{𝑖 𝑗} (𝑡 − 1))\; \exp(−𝑟_{𝑖 𝑗} (𝑡 − 2))\; · · ·\; \exp (0)]^T ∈ \mathbb ℝ^𝑡  \tag{9}
\]

\(\mathbf R_{ij}^𝑡\) は同期ドット積の要素を再スケールするために使用されます。
<!--
\(\mathbf R_{ij}^𝑡\) is then used to rescale the components of the synchronization dot product:
-->
\[
\mathbf S_{ij}^𝑡 = \frac{(\mathbf Z_i^𝑡)^⊺· diag(\mathbf R_{ij}^𝑡) ·(\mathbf Z_j^𝑡)}{\sqrt{\sum_{\tau=1}^t \left[\mathbf R_{ij}^t \right]_\tau}} \tag{10}
\]

次に、\(\mathbf R_{ij}^𝑡\) が使用されます。直感的に、\(𝑟_{𝑖𝑗}\) の値が大きいほど、ドット積をより最近の内部ティックに偏らせることで、より短期的な依存関係が生じます。一方、\(𝑟_{𝑖𝑗} = 0\) は標準的なドット積を復元します（これもゼロに初期化します）。平方根正規化により、単一の \(𝑖𝑗\) の組み合わせが下流処理を支配するのを防ぎます。(Vaswani et al., 2017)。実際には、サブサンプリングされた同期ペアに対してのみ \(\mathbf R_{ij}^𝑡\) を計算すればよく、これは出力表現とアクション表現に対して個別に行います。 CTMは異なるニューロンペア間で減衰率を変更することを学習できるため、学習可能なパラメータに𝑟を含めることで、CTMのニューラルダイナミクスへの依存度が効果的に高まります。完全な開示のために、CTMはImageNet分類（セクション3を参照）ではこれを一度も活用していないことがわかりました。ImageNet分類では、\(\mathbf S_{out}^𝑡\) 内の8196個の(𝑖,𝑗)ニューロンペアのうち、意味のある減衰を示したのはわずか3個でした。2D迷路のナビゲーション（セクション4を参照）では、\((𝑖,𝑗)\)ペアの約3%に意味のある減衰が見られました。これは、明確な順次推論を伴うタスクでは、より局所的な視点（つまり、同期へのより速い減衰）が必要であることを示しています。同期ドット積の要素を再スケールします。
<!--
Intuitively, higher \(𝑟_{𝑖𝑗}\) values result in shorter-term dependency by biasing the dot product towards more
recent internal ticks, while \(𝑟_{𝑖𝑗} = 0\) recovers the standard dot product (we also initialise to zeros). The
square-root normalization prevents any single 𝑖 𝑗 combination fromdominating downstream processing
(Vaswani et al., 2017). In practice we only need to compute \(\mathbf R_{ij}^𝑡\) for subsampled synchronization pairs,
which we do separately for output and action representations. Since CTM can learn to alter the decay
rates across different neuron pairs, the inclusion of 𝑟 into the learnable parameters effectively enhances
the complexity of the CTM’s reliance on neural dynamics. For full disclosure, we found that the CTM
never leveraged this for ImageNet classification (see Section 3), where only 3 of 8196 (𝑖, 𝑗) neuron
pairs in \(\mathbf S_{out}^𝑡\) had any meaningful decay. For navigating 2D mazes (see Section 4) approximately 3%
of \((𝑖, 𝑗)\) pairs had meaningful decay, indicating that a task with clear sequential reasoning warrants a
more local perspective (i.e., a faster decay to synchronization).
-->

</p><p>

<strong>潜在的なスナップショット依存性の回復</strong>　興味深いことに、CTMは現在の状態z𝑡への依存性を回復することを学習できます。\(𝑖 = 𝑗\)と設定し、\(𝑟_{𝑖𝑗}\)が非常に小さい場合、これは\(𝑖\)個のサンプリングされたニューロンごとに\(\mathbf z^𝑡\)の要素ごとの2乗を計算することとほぼ等価です。実際にはこれは不要であることが判明していますが、いくつかのサブサンプリング戦略を検討し、付録B.2でそれらについて説明しました。
<!--
<strong>Recovering latent snapshot dependency</strong>　Interestingly, the CTM could learn to recover a dependency
on the current state z𝑡, if we set \(𝑖 = 𝑗\) and \(𝑟_{𝑖𝑗}\) is very small, since this would be approximately
equivalent to computing the element-wise square of \(\mathbf z^𝑡\) for each \(𝑖\) sampled neuron. In practice this
turns out to be unnecessary, but we did explore several subsampling strategies and discuss these in
Appendix B.2.
-->
</p>
<h3>2.5. 損失関数：内部ティック間の最適化</h3>
<!--
<h3>2.5. Loss function: optimizing across internal ticks</h3>
-->
<p>
CTMは各内部ティック\(𝑡\)で出力を生成します。重要な疑問が生じます。この内部時間次元にわたってモデルをどのように最適化するかです。\(\mathbf y^𝑡 ∈ \mathbb ℝ^𝐶\)を内部ティック𝑡における予測ベクトル（例えば、クラスの確率）とします。ここで𝐶はクラスの数です。𝑦𝑡𝑟𝑢𝑒を真のターゲットとします。各内部ティックにおける損失は、クロスエントロピーなどの標準的な損失関数を用いて計算できます。<sup>2</sup>
<!--
The CTM produces outputs at each internal tick, \(𝑡\). A key question arises: how do we optimize the
model across this internal temporal dimension? Let \(\mathbf y^𝑡 ∈ \mathbb ℝ^𝐶\) be the prediction vector (e.g., probabilities
of classes) at internal tick 𝑡, where 𝐶 is the number of classes. Let 𝑦𝑡𝑟𝑢𝑒 be the ground truth target. We
can compute a loss at each internal tick using a standard loss function, such as cross-entropy:<sup>2</sup>
-->
</p><p class="margin-large">
<sup>2</sup>
実際には、任意の適切な損失関数を使用できます。
<!--
In practice any appropriate loss function could be used.
-->
</p><p>

\[
\mathcal L^𝑡 = CrossEntropy(\mathbf y^𝑡 , 𝑦_{𝑡𝑟𝑢𝑒})  \tag{11}
\]

および対応する確実性の尺度 \(\mathbf C^𝑡\) 。確実性は単純に 1 正規化エントロピーとして計算します。
\(𝑡 ∈ \{1, . . . , 𝑇\}\) すべてについて \(\mathcal L^𝑡\) と \(\mathbf C^𝑡\) を計算し、内部ティックあたりの損失と確実性 \(\mathcal L ∈ \mathbb ℝ^𝑇\) と \(\mathbf C ∈ \mathbb ℝ^𝑇\) を生成します。
<!--
and a corresponding certainty measure, \(\mathbf C^𝑡\) . We compute certainty simply as 1 - normalized entropy.
We compute \(\mathcal L^𝑡\) and \(\mathbf C^𝑡\) for all \(𝑡 ∈ \{1, . . . , 𝑇\}\), yielding losses and certainties per internal tick, \(\mathcal L ∈ \mathbb ℝ^𝑇\) and \(\mathbf C ∈ \mathbb ℝ^𝑇\) .
-->
</p><p>

当然、次のような疑問が生じます。学習のために、\(\mathcal L\) をスカラー損失にどのように縮減すればよいのでしょうか。私たちの損失関数は、内部思考次元全体にわたってCTMのパフォーマンスを最適化するように設計されています。モデルがその特定のステップでのみ出力するように誘導する可能性のある単一のステップ（例えば最後のステップ）に依存するのではなく、2つの内部ティック（損失が最小となるポイントと確実性が最大となるポイント）から情報を動的に集約します。このアプローチにはいくつかの利点があります。(1) CTMが複数の内部ティックにわたって意味のある表現と計算を開発することを促すこと。(2) カリキュラム学習効果が自然に促進され、モデルは最初はより複雑な処理のために後の内部ティックを利用し、徐々により単純な処理のために前のステップに移行することができます。(3) CTMは、データセット内の個々のデータポイントの固有の難易度に基づいて計算を適応させることができます。この目的のために、2つの内部ティックにわたって \(\mathcal L\) を（データポイントごとに）動的に集約します。
<!--
A natural question arises: how should we reduce \(\mathcal L\) into a scalar loss for learning? Our loss function
is designed to optimize CTM performance across the internal thought dimension. Instead of relying
on a single step (e.g., the last step), which can incentivize the model to only output at that specific
step, we dynamically aggregate information from two internal ticks: the point of minimum loss and
the point of maximum certainty. This approach offers several advantages: (1) it encourages the
CTM to develop meaningful representations and computations across multiple internal ticks; (2) it
naturally facilitates a curriculum learning effect, where the model can initially utilize later internal
ticks for more complex processing and gradually transition to earlier steps for simpler processing; and
(3) it enables the CTM to adapt its computation based on the inherent difficulty of individual data
points within a dataset. To this end, we aggregate \(\mathcal L\) dynamically (per data point) over two internal ticks:
-->

<div class="styleBullet">
<ul><li>
1. 損失が最小となる点: \(𝑡_1 = argmin(\mathcal L)\); および
</li><br><li>2. 確実性が最大となる点: \(𝑡_2 = argmax(\mathbf C)\).
<!--
1. the point of minimum loss: \(𝑡_1 = argmin(\mathcal L)\); and
</li><br><li>2. the point of maximum certainty: \(𝑡_2 = argmax(\mathbf C)\).
-->
</li></ul></div>
</p><p>
最終的な損失は次のように計算されます。
<!--
The final loss is then computed as:
-->
\[
\mathcal L =\frac{\mathcal L^{𝑡_1} + \mathcal L^{𝑡_2}}{2}  \tag{12}
\]

確率的勾配降下法を用いてモデルパラメータ\(𝜃_{syn}\)と\(𝜃_{𝑑=1...𝐷}\)を最適化します（式1と式3を参照）。
<!--
and stochastic gradient descent is used to optimize the model parameters, \(𝜃_{syn}\) and \(𝜃_{𝑑=1...𝐷}\) (see
Equations 1 and 3).
-->
</p><p>

このアプローチにより、CTMは高い確実性が正しい予測に帰属することを確実にしながら、その「最良の」予測を効果的に改善することができます。リスト4は損失の計算方法を示しており、確実性が1 - 正規化エントロピーとして計算されることを示しています。このアプローチにより、CTMは必要に応じて思考プロセスを動的に調整することもできます。
<!--
This approach effectively enables the CTM to improve its ‘best’ prediction while making sure that high
certainty is attributed to correct predictions. Listing 4 shows how the loss is calculated, demonstrating
how the certainty is computed as 1 - normalized entropy. This approach also enables the CTM to
dynamically adjust its thought process as needs be.
-->
</p><p>
<code>
def atm_loss ( logits , targets ):<br>
　B, C, T = logits . shape<br>
　# B= minibatch size , C= classes , T= thought steps<br>
　# Targets shape : [B]<br>
　# Compute certainties as 1 - normalised entropy<br>
　p = F. softmax ( logits , 1)<br>
　log_p = torch . log_softmax ( logits , 1)<br>
　entropy = -torch . sum (p * log_p , dim =1)<br>
　max_entropy = torch . log (C)<br>
　certainties = 1 - ( entropy / max_entropy )<br>
　# Certainties shape : [B, T]<br>
　# Expand targets over thought steps<br>
　targets_exp = torch . repeat_interleave ( targets . unsqueeze ( -1) , T, -1)<br>
　# Loss function could be other things , but we use cross entropy without reduction<br>
　loss_fn = nn. CrossEntropyLoss ( reduction ='none ')<br>
　# Losses are of shape [B, T]<br>
　losses = loss_fn ( predictions , targets_exp )<br>
　# Get indices of lowest loss thought steps for each item in the minibatch<br>
　lowest_idx = losses . argmin ( -1)<br>
　# Get indices of most certain steps for each item in the minibatch<br>
　certain_idx = certainties . argmax ( -1)<br>
　loss = ( losses [:, lowest_idx ] + losses [:, certain_idx ])/2<br>
　return loss . mean ()<br>
</code>
<br>
リスト 4 | CTM 損失関数。これにより、CTM は特定のデータ ポイントに使用される内部ティックの数に関して柔軟に対応できるようになります。
<!--
Listing 4 | CTM loss function, enabling the CTM to be flexible regarding the number of internal ticks used for any given data point.
-->
</p><p>

CTMの基本的な機能要素としてタイミングを導入することには、多くの利点があります。その一つは、CTMが使用する内部ティック数に制限を設けることなく学習できることです。このような自由度は微妙ではありますが、実際には非常に重要で、CTMはデータポイントごとに異なる計算量を割り当てることができます。適応型/動的計算（Graves, 2016）の考え方は、現代のテスト時計算と整合していますが、この求められているモデリング特性は、事後的に適用されたり学習中に制約として課されたりするのではなく、結果としてCTMから除外されるという点が異なります。損失関数には、この動作を明示的に促進するものは何もないことに注意してください。ある意味で、CTMは一​​種の帰納的バイアスを実装しており、モデリングプロセスの複雑さ（使用される内部ティック数で概算）をデータに合わせて調整できます。これは、難易度が変動する問題（例えば、画像の分類が容易か困難かなど）を解決するための、はるかに自然な手段であると考えています。このような特性が生物学的妥当性の向上の結果として生じることは驚くべきことではありませんが、喜ばしいことです。第5章では、CTMの性能と特性を他のモデルや人間の基準と比較します。
<!--
Introducing timing as a fundamental functional element of the CTM has a number of beneficial
properties, one of which is that we can train the CTM without any restriction on how many internal
ticks it should use. Such freedom, while subtle, is actually quite profound as it lets the CTM attribute
variable amounts of compute to different data points. The idea of adaptive/dynamic compute (Graves,
2016) is aligned with modern test-time compute, with the difference being that this sought-after
modeling property falls out of the CTM as a consequence, rather than it being applied post-hoc or as
a restriction during learning. Note that there is nothing in the loss function that explicitly encourages

this behavior. In some sense, the CTM implements a form of inductive bias, where the complexity
of the modeling process (approximated by the number of internal ticks used) can be tailored to
the data. We believe that this is a far more natural means by which to solve problems of variable
difficulty (e.g., easy versus difficult to classify images). That such a property occurs as a consequence
of improving biological plausibility is not surprising, but it is gratifying. We contrast the performance
and characteristics of the CTM against other models and a human baseline in Section 5.
-->
</p><p>

<strong>実験的評価</strong><br>
以下のセクションでは、多様な課題における連続思考マシン（CTM）の包括的な評価を示します。これらの実験の主な目的は、CTMの中核となる設計原理、すなわちニューロンレベルの時間処理と、神経同期を直接的な潜在表現として用いること、から生まれる能力と特性を探求することです。内部神経活動の展開を明示的にモデル化し、活用することで、CTMがどのようにして知性のさまざまな側面を必要とする問題にアプローチできるようになるのかを理解することを目指します。
<!--
<strong>Experimental evaluation</strong><br>
The following sections present a comprehensive evaluation of the Continuous Thought Machine (CTM)
across a diverse suite of challenging tasks. The primary goal of these experiments is to explore the
capabilities and characteristics that emerge from the CTM’s core design principles: neuron-level
temporal processing and the use of neural synchronization as a direct latent representation. We
aim to understand how explicitly modeling and leveraging the unfolding of internal neural activity
allows the CTM to approach problems requiring different facets of intelligence.
-->
</p><p>

まず、ImageNet-1Kのような標準的な知覚タスクにおけるCTMの解析から始めます（第3節）。CTMの内部ダイナミクスの豊かさ、創発的な推論プロセス、キャリブレーション特性、そして適応的計算に焦点を当てて分析します。その後、CTMとCIFAR-10における人間のパフォーマンスを比較する研究（第5節）と、CIFAR-100におけるアブレーション研究（第6節）を実施します。
<!--
We begin by examining the CTM on standard perception tasks like ImageNet-1K (Section 3), focusing
on analyzing the richness of its internal dynamics, its emergent reasoning processes, calibration
properties, and adaptive computation. We supplement these later with studies to compare the
CTM to human performance on CIFAR-10 (Section 5) and perform ablation studies on CIFAR-100
(Section 6).
-->
</p><p>

次に、内部世界モデルの形成を必要とするように設計された困難な2D迷路ナビゲーションタスクを用いて、CTMの複雑な逐次推論、計画、および空間理解能力を具体的に検証する（第4節）。
さらに実験を行い、思考の時間的展開が重要となる、実数のソート（第7節）や累積パリティ計算（第8節）といったシーケンスベースのタスクにおいて、CTMがアルゴリズム手順を学習し実行する能力を調査する。また、MNIST数字を用いた質問応答タスクを通して、記憶、検索、および記号操作能力をテストする（第9節）。
最後に、CTMを強化学習環境に拡張し、逐次的な意思決定と外部世界との継続的な相互作用への適用可能性を示す（第10節）。
<!--
We then specifically probe the CTM’s capacity for complex sequential reasoning, planning, and spatial
understanding using a challenging 2D maze navigation task designed to necessitate the formation of
an internal world model (Section 4).
Further experiments investigate the CTM’s ability to learn and execute algorithmic procedures on
sequence-based tasks such as sorting real numbers (Section 7) and cumulative parity computation
(Section 8), where the temporal unfolding of thought is critical. We also test its capacity for memory,
retrieval, and symbolic manipulation through a question-answering task on MNIST digits (Section 9).
Finally, we extend the CTM to reinforcement learning environments to demonstrate its applicability
to sequential decision-making and continuous interaction with an external world (Section 10).
-->
</p><p>

これらの実験は総合的に、計算を神経ダイナミクスに根ざすことでCTMが内部思考プロセスをどのように発達させ、活用できるようになるかについての洞察を提供することを目的としており、従来のモデルとは異なるアプローチを提供し、より生物学的に妥当な人工知能への一歩を踏み出すものです。
<!--
Collectively, these experiments are designed to provide insights into how grounding computation in
neural dynamics allows the CTM to develop and utilize internal thought processes, offering a distinct
approach compared to conventional models and taking a step towards more biologically plausible
artificial intelligence.
-->
</p>
<h2>3. ImageNet-1K分類</h2>
<!--
<h2>3. ImageNet-1K classification</h2>
-->
<p>

このセクションでは、ImageNet-1K分類タスクでCTMをテストします。CTMが分類精度の点で最先端であると主張するわけではありません。最適なトレーニングレシピを見つけるには、かなりの労力とチューニングが必要になります（Vryniotis and Cord, 2021）。むしろ、CTMがこのタスクを解決する方法が斬新であり、検証する価値があると主張しています。モデルのセットアップとハイパーパラメータについては、付録C.1で詳しく説明します。ResNet-152バックボーン<sup>3</sup>を使用したCTMは、トリミングされていないImageNet-1K検証データ（ただし、画像の短辺の長さが256になるようにスケーリング）で評価した場合、トップ1検証精度72.47%、トップ5検証精度89.89%を達成しました。この結果は現時点では最先端技術と比較できるものではありませんが、ニューラルダイナミクスを表現として用いてImageNet-1Kを分類する初の試みでもあります。今後の進歩、ハイパーパラメータの調整、そしてCTMに合わせた特徴抽出器の開発によって、このギャップを埋められると期待しています。
<!--
In this section we test the CTM on the ImageNet-1K classification task. We are not claiming that the
CTM is state-of-the-art in terms of classification accuracy, which would require a substantial amount
of effort and tuning to find an optimal training recipe (Vryniotis and Cord, 2021), but rather that the
way in which the CTM solves this task is novel and worth inspection. We detail the model setup and
hyperparameters in Appendix C.1. With a ResNet-152 backbone <sup>3</sup>, the CTM achieves 72.47% top-1
validation accuracy and 89.89% top-5 validation accuracy, when assessed on uncropped ImageNet-1K
validation data (but scaled such that the short side of the image is length 256). While this result
is currently not comparable with state-of-the-art techniques, it is also the first attempt to classify
ImageNet-1K using neural dynamics as a representation. We anticipate closing this gap that with
further advances, more hyperparameter tuning, and feature extractors tailored to the CTM.
-->
</p><p class="margin-large">
<sup>3</sup>

受容野を制限するため、初期畳み込みカーネルを7×7ではなく3×3に変更しました。詳細については付録C.1を参照してください。
<!--
altered such that the initial convolution is kernel is 3 × 3 as opposed to 7 × 7 to constrain the receptive field – see
Appendix C.1 for a discussion thereon
-->
</p>
<h3>3.1. 予測分析：思考次元の力</h3>
<!--
<h3>3.1. Prediction analysis: the power of the thought dimension</h3>
-->
<p>
図2は、選択した最小確実性に達したときにCTMの内部ティックがどのように切り捨てられるか、および期待されるトップ5精度がどの程度になるかを示しています。例えば、すべてのデータに対して0.5の確実性に達するには、画像あたり20個未満の内部ティックが必要ですが、しきい値を0.8に選択した場合、すべてのデータが常にこのしきい値に達するわけではありません。後者の場合、ユーザーの必要に応じて計算を切り捨てることができます。許容可能な内部しきい値に達したときに内部ティックを停止することで、一種の適応型計算を利用できます。
<!--
Figure 2 shows how the internal ticks for the CTM could be truncated when a chosen minimum
certainty is reached, and what the expected top-5 accuracy would be. For instance, it takes fewer
than 20 internal ticks per image to reach a certainty of 0.5 for all data, but when choosing a threshold
of 0.8, not all of the data always reaches this threshold. In the latter case, compute could be truncated
as needed by the user. By halting the internal ticks when an acceptable internal threshold is met, a
form of adaptive compute can be utilized.
-->
</p>
<center><img src="images/fig2.png"></center>
<p>

図2 | 固定された確信度の閾値を超えて予測を行った場合のみの上位5つの精度（検証）。低い閾値（a）0.5の場合、CTMは約4内部ティック以降、100%の確率で予測を行いますが、（b）確信度の閾値を0.8に設定すると、データの約80%のみを予測します。これらの評価は、確信度の閾値を調整して適応型計算を可能にし、必要に応じて計算を停止するために使用できます。
<!--
Figure 2 | Top-5 accuracies (validation) only when making a prediction past fixed certainty thresholds. At a lower threshold
of (a) 0.5, the CTM will make a prediction 100 % of the time from approximately 4 internal ticks and onward, but (b) will
only predict on approximately 80 % of the data when setting a certainty threshold of 0.8. These assessments could be used
to tailor a certainty threshold to enable adaptive compute, halting compute as needed.
-->
</p><p>

<strong>予測メカニズム：確実性を考慮する</strong> 図3aは、異なる予測メカニズムが全体的なパフォーマンスにどのように影響するかを示しています。ここでは、「瞬間的な」予測（つまり、各内部ティックにおける予測）と、確実性に基づく予測（特定のステップまでの最大確実性、および確実性によってロジットを重み付けした場合）を比較しています。興味深いことに、約15内部ティック以降は、確実性を明示的に考慮することが望ましいことがわかります。ロジットの重み付けされていない平均を使用すると、最悪のパフォーマンスが得られます。これは、CTMが実際に予測を改善するプロセスを経ている一方で、確実性の低い誤った予測を通過する可能性があることを示唆しています。図5bは、さらなる証拠として、確実性の低いインスタンスの具体的な例を示しています。
<!--
<strong>Prediction mechanisms: accounting for certainty.</strong>　Figure 3a shows how different prediction
mechanisms can affect overall performance. We show an ‘instant’ prediction (i.e., the prediction at
each internal tick) compared to predictions based on certainty: the maximum certainty up to a given
step, and when weighting logits by certainty. Interestingly, after approximately 15 internal ticks
it becomes preferable to take explicit account of certainty. Using an unweighted average of logits
yields the worst performance, implying that the CTM does indeed undergo a process to improve its
prediction, while potentially moving through incorrect predictions of low certainty. Figure 5b gives
concrete examples of low-certainty instances for further evidence.
-->
</p><p>

図3bは、CTMが少なくとも0.8の確信度を生成した場合の内部ティックの分布を示しています。これは、データの大部分が10個未満の内部ティックを必要とし、最大50個の内部ティックに向かって長い裾野を持つことを示しています。図3cのキャリブレーションプロットは、CTMが非常に良好なキャリブレーションを持っていることを示しているため、おそらく最も印象的です。これは、CTMが内部ティックを通じて次第に確信度を増していく様子によるものです。特定のインスタンスの予測確率は、選択されたクラスの内部ティック全体の平均確率であるとみなします。図5のデモンストレーションは、内部ティックを通じて確信度がどのように増加するかを示しています。明らかに、内部プロセスに従うことで、CTMはより信頼性の高いクラス確率を生成できるようです。これは通常、トレーニング後の調整や特別なトレーニング設定を必要とする特性です（Guo et al., 2017）。
<!--
Figure 3b shows the distribution of internal ticks when the CTM yields a certainty of at least 0.8,
indicating that the majority of the data requires fewer than 10 internal ticks, with a long tail toward
a maximum of 50 internal ticks. The calibration plots in Figure 3c are perhaps most striking as they
show that the CTM has very good calibration. This is owing to how the CTM becomes increasingly
certain over internal ticks: we consider the predicted probability of a given instance to be the average
probability over internal ticks of the chosen class. The demonstration in Figure 5 shows how certainty
increases over internal ticks. Evidently, following an internal process seems to enable the CTM
to produce more trustworthy class probabilities – a characteristic that usually needs post-training
adjustments or special training setups (Guo et al., 2017).
-->
</p>
<center><img src="images/fig3.png"></center>
<p>

図3 | CTMの性能と有用性の調査。内部ティックとImageNet-1Kの上位5つの精度の関係を示しています。(a)は、4つの異なる方法で出力予測を決定する際の内部ティックに対する精度を示しています。約15ステップまでは、特定の内部ティックでの予測を採用することが合理的であり、そこからは確実性を成功の尺度と見なす方が適切であることを示しています。(b)は、各内部ティックについて、確実性0.8を超えるデータ数のヒストグラムを示しています。色はクラスインデックスを示しています。(c)は、キャリブレーションプロットを示しています。ここでは、CTMの予測確率は、特定の内部ティックまでの平均確率とみなされており、これが良好なモデルキャリブレーションにつながることを示しています。
<!--
Figure 3 | Exploration of the performance and utility of the CTM, showing the relationship between internal ticks and
top-5 ImageNet-1K accuracy. In (a) we show the accuracy versus internal ticks when determining the output prediction
in 4 different ways, showing how taking the prediction at a given internal tick is sensible until approximately 15 steps,
where it becomes better to consider the certainty as a measure of success. In (b) we show a histogram of data counts
exceeding a certainty of 0.8 for each internal tick; color denotes class indices. In (c) we show calibration plots, where
predicted probabilities for the CTM are considered to be the average probability up to a given internal tick, showing how
this results in good model calibration.
-->
</p>
<h3>3.2. ニューラルダイナミクス解析</h3>
<!--
<h3>3.2. Neural dynamics analysis</h3>
-->
<p>
図4は、このCTMの活性化後の神経ダイナミクスを視覚化したものです。これらのダイナミクスは多様で構造が豊かであり、CTMが行動を起こし、意思決定を行うための表現を形成します。この図の目的は、CTMが実際に多様な神経活動を生み出し、そのダイナミクスを相互の関係（すなわち同期）で測定し、下流のタスクのための強力な潜在表現として使用できることを示すことです。第4節では、このような表現が問題解決において高い有用性を持つことを示す証拠を示します。
<!--
Figure 4 visualizes the post-activation neural dynamics of this CTM. These dynamics are diverse
and rich in structure, and they form the representation with which the CTM takes action and
makes decisions. The purpose of this figure is to show that the CTM does indeed yield a diverse
set of neural activities, the dynamics of which can be measured in relationship to one another (i.e.,
synchronization) and used as a powerful latent representation for downstream tasks. In Section 4 we
provide evidence that such a representation has high-utility for problem solving.
-->
</p>
<center><img src="images/fig4.png"></center>
<p>

図4｜活性化後のニューロンのダイナミクス（図1の5）。各サブプロット（ランダムな色で表示）は、内部の目盛りにおける1つのニューロンのダイナミクスを示しています。異なる画像からの複数の例が薄い背景線で示され、前景の線は1つの例です。データ間の多様性を示すために、複数の例を示しています。同期を計算する際に使用されるのはこれらのダイナミクスであり、CTMの基本的な処理要素を形成します。
<!--
Figure 4 | Post-activation neuron dynamics ( 5 in Figure 1). Each subplot (in a random color) shows the dynamics of a
single neuron over internal ticks, where multiple examples from different images are shown as faint background lines
and the foreground line is a single example. We show multiple examples as evidence of diversity across data. It is these
dynamics that are used when computing synchronization and they form the fundamental processing element of the CTM.
-->
</p><p>

<strong>まとめ</strong>　図4は、CTM内のニューロンが複雑なマルチスケールパターンを示していることを示していますが、これがなぜ有用であるかという実用的な根拠は示していません。これを示した理由は、CTMが真のダイナミクスを構築し、活用している証拠として、つまり、神経活動のパターンが非自明かつ多様であることを示すためです。これらのダイナミクスとそれに含まれる複雑さは、神経計算の背後にある生物学的に妥当なメカニズムに近いと考えられる、新しい種類の表現を形成します。
<!--
<strong>Take-home message. </strong>Figure 4 shows that the neurons in the CTM exhibit complex multiscale
patterns, but have not provided any pragmatic rationale for why this might be useful. The reason we
show this is as evidence that we the CTM builds and leverages true dynamics, where the patterns of
neural activity are non-trivial and diverse. These dynamics and the complexity contained within form
a new kind of representation that we believe is closer to the biologically plausible mechanisms behind
neural computation.
-->
<p>

<h3>3.3. デモンストレーション: CTMはプロセスに従います</h3>
<!--
<h3>3.3. Demonstrations: the CTM follows a process</h3>
-->
<p>

図5は、CTMがImageNet-1K検証セットをどのように認識しているかを示す例です。付録C.3にさらに例を示します。これらの視覚化は動画で視聴することをお勧めします。動画には50フレーム（内部ティックごとに1フレーム）あり、CTMの内部思考プロセスにおける注意マップの経時的な変化と、異なる領域への移行を示しています。画像のさまざまな部分への注意のスムーズな移行は、トレーニング中に特性として現れます。この一時的な注意の一部を矢印で示し、注意が顕著な領域を直感的に移動する様子を示しました。これらの注意マップの進行の興味深い側面をすべて解明することは、本稿では不可能です。その代わりに、これらの例では、注意パターンが複雑なプロセスを示す様子を示します。また、時間の経過に伴う確実性も示しており、CTMが推論するにつれて確実性が高まる様子を示しています。
<!--
Figure 5 shows examples from the ImageNet-1K validation set, as the CTM sees it. We give more
examples in Appendix C.3. We encourage the reader to view these visualizations in video form as there
are 50 frames (1 per internal tick) that show how the attention maps change over time, shifting
to different regions over the CTM’s internal thought process. The smooth transition of attention to
various parts of the image emerges as a property during training. We attempted to show some of this
transitory attention by way of arrows, showing how the attention moves over salient areas an intuitive
fashion. Unpacking every interesting facet of these attention map progressions is simply infeasible in
this paper. Instead, for these examples we show how the attention patterns demonstrate a complex
process. Also shown is the certainty over time, indicating how the CTM becomes more certain as it
reasons.
-->
</p><p>
CTMは情報検索にアテンションを使用するため、固定サイズの画像に限定されません（また、将来の研究では任意の長さのトークンシーケンスに適用できます）。そのため、我々は切り取られていない検証データで評価を行っています。複数の入力解像度を用いてトークンの階層を構築し、CTMが（学習中ではなく推論中に）多数のトークンの集合に注意を向けるようにすることも考えられますが、この検討は将来の研究のために残しておきます。
<!--
Note that since the CTM uses attention to retrieve information, it is not limited to fixed-size images
(and, for future work, can be applied to arbitrarily length token sequences), hence our evaluations on
uncropped validation data. One could conceivably build a hierarchy of tokens by using multiple input
resolutions, letting the CTM attend to a large collection of tokens (during inference, not training),
but we reserve this exploration for future work.
-->
</p>
<center><img src="images/fig5.png"></center>
<p>

図5 | 検証セットからランダムに抽出されたImageNet-1Kのユースケース。このデモは内部ティックが50個あるため動画として表示するのが最適ですが、ここでは最終ステップのみを示しています。左側には、16個の注意ヘッドすべての重み付けの平均（内部ティック全体）を示し、右側には、全50ステップにおけるそれらの集合平均（詳細は付録C.1を参照）の重心の近似値を赤から青への矢印で示しています。CTMの内部ティックの連続性により、各ヘッドの注意が領域から領域へとスムーズに移行し、時には特定の顕著な特徴（鼻、境界など）に集中したり、時にはより広い領域に広がったり、さらには識別可能な方向（例：下から上へ）に移動したりする様子が見られます。付録C.3には、さらにいくつかのデモが含まれています。
<!--
Figure 5 | ImageNet-1K use cases, randomly drawn from the validation set. This demonstration is ideal when viewed
as a video as there are 50 internal ticks, but we are showing only the final step. On the left we show the average (over
internal ticks) of all 16 attention heads’ weightings, and on the right we show an approximation of the center of mass
of their collective average (see Appendix C.1 for details) over the full 50 steps as arrows from red to blue. Owing to the
sequential nature of the CTM’s internal ticks, we observe each head’s attention shifting smoothly from region to region, at
times zoning into specific salient features (nose, boundaries, etc.), while at other times spreading over wider areas, or even
moving in identifiable directions (e.g., from bottom to top). Appendix C.3 contains several additional demonstrations.
-->
</p><p>

<strong>CTMは時間の経過とともに観察を学習します。</strong>　実験中、CTMの学習が進むにつれてその機能性を監視しました。本論文では明示的に示していませんが、学習中にニューラルダイナミクスの複雑さ、ひいてはCTMが行う観察プロセスの複雑さが増加します。最初は、CTMは図5のように「周囲を見回す」ことはなく、時間の経過とともにその行動を学習するだけです。Xuら (2015) による初期の研究では、RNNを用いて画像からテキストキャプションを推論する方法が示されました。CTMの推論プロセスは、入力データとターゲットデータの両方から分離された内部次元に沿って展開されるという点で異なりますが、それでも複雑な注意パターンを生み出し、意思決定の際に注意を集中させる場所を強調します。
<!--
<strong>The CTM learns to observe over time.</strong>　During our experimentation we monitored the functionality
of the CTM as it progressed through its training. While we do not explicitly show it in this paper,
the complexity of the neural dynamics and consequently the complexity of the observation process
the CTM undertakes increases during learning. At first the CTM does not ‘look around’ as it does in
Figure 5, only learning that behavior over time. An early work by Xu et al. (2015) demonstrated how
to use an RNN to reason over an image for text captioning; the CTM’s reasoning process differs in
that it unfolds along an internal dimension that is decoupled from both the input and target data, yet
it still yields a complex attention pattern that highlights where it focuses its attention when making
decisions.
-->
</p><p>

<strong>自然知能に向けての一歩</strong>　生物学的知能は、多くの場合、依然としてAIよりも優れています（Chollet et al., 2024; Lake et al., 2017; Phan et al., 2025; Ren and Xia, 2024）。生物学的脳は、従来のニューラルネットワークとは非常に異なる方法でタスクを解決します。これが、その理由を説明できるかもしれません。本研究では、生物学的脳とより一致した方法で問題解決にアプローチするモデルの開発を目指し、この類似性を達成する上での神経ダイナミクスの中心的な役割を強調しました。私たちの観察は、CTMが画像から情報を順次取得するプロセスを実行していることを示唆しています。付録C.3に、興味深い、またはユニークなパターンや結果を示すさらなる例を示します。
<!--
<strong>Taking steps toward natural intelligence.</strong>　Biological intelligence is still superior to AI in many
cases (Chollet et al., 2024; Lake et al., 2017; Phan et al., 2025; Ren and Xia, 2024). Biological
brains solve tasks very differently to conventional neural networks, which might explain why this is
the case. In this work, we aimed to develop a model that approaches problem-solving in a manner
more aligned with biological brains, emphasizing the central role of neural dynamics in achieving
this similarity. Our observations suggest that the CTM undertakes a process, where it sequentially
retrieves information from an image. We show more examples in Appendix C.3, where each instance
shows interesting or unique patterns or outcomes.
-->
</p>
<center><img src="images/fig6.png"></center>
<p>
図6 | CTMが画像を観察し、思考する様子を観察する様子。付録Jには、UMAP (McInnes et al., 2018) を用いてニューロンがどのように配置されたかの詳細が記載されています。色は、低（青）から高（赤）までの活動レベルを示しています。左上から右下にかけて、内部の目盛りに沿って神経活動の進行を示しています。注意深く観察すると、複数のスケールで明確な構造が見つかります。この視覚化は、動画で見るのが最適です。
<!--
Figure 6 | Observation of the neurons in the CTM as it observes and thinks about an image. Appendix J gives details of
how the neurons were arrange using UMAP (McInnes et al., 2018). The colors indicate activations that range from low
(blue) to high (red). We show the progression of the neural activity over internal ticks from top left to bottom right. Upon
careful inspection one can discover clear structures at multiple scales. This visualization is best viewed in video form.
-->
</p><p>

最後に比較対象として、低周波進行波について考察する。これは皮質ダイナミクスにおいて広く報告され、様々な神経計算に関与していることが示唆されている現象である（Muller et al., 2018）。図6は、UMAP（McInnes et al., 2018）を用いてCTMのニューロンを2次元特徴空間にマッピングしたものである。この空間における各ニューロンの位置は、その活性化「プロファイル」、すなわち時間と複数の刺激に対する応答パターンによって決定される（付録Jを参照）。このマッピングを内部ティック上で視覚化すると、特徴空間全体に伝播する低周波構造が明らかになる（動画で表示するのが最も効果的である）。重要な点は、CTMがこの構造を明示的な駆動信号なしに創発的に生成することである。同様の現象はKuramoto振動子のネットワークでも発生する（Miyato et al., 2024）。我々のケースでは、波は全対全ネットワークにおいて学習された特徴マップ全体に伝播する。同時進行する研究は、長距離通信のための進行波の明示的な符号化についても研究している（Jacobs et al., 2025）。我々は、これらの観測された波に機能的な意味を与えるのではなく、CTMの思考プロセスにおけるそれらの明確な存在を強調する。
<!--
As a final point of comparison, we consider low-frequency traveling waves, a phenomenon widely
documented in cortical dynamics and implicated in various neural computations (Muller et al., 2018).
We present Figure 6, where we map the CTM’s neurons to a 2D feature space using UMAP (McInnes et al., 2018). Each neuron’s position in this space is determined by its activation ‘profile’ – its response
pattern over both time and multiple stimuli (see Appendix J). Visualizing this mapping over internal
ticks reveals low-frequency structures propagating across the feature space (best viewed as a video).
Importantly, the CTM generates this structure in an emergent fashion, without any explicit driving
signal. Analogous phenomena occur in networks of Kuramoto oscillators (Miyato et al., 2024); in our
case, waves propagate across a learned feature map in an all-to-all network. Concurrent work also
explores explicitly encoding traveling waves for long-range communication (Jacobs et al., 2025). We
do not assign functional meaning to these observed waves but highlight their distinct presence during
the CTM’s thought process.
-->
</p>
<h3>4. 2D迷路：複雑な順序立てた推論を必要とする設定</h3>
<!--
<h3>4. 2D Mazes: a setup that requires complex sequential reasoning</h3>
-->
<p>
このセクションでは、2次元迷路をツールとして用い、CTMが計画とナビゲーションを行う際の挙動を調査します。2次元迷路の解法は、適切な帰納的バイアス、つまり出力空間が入力空間の次元と一致するようにすることで容易になります。入力空間の各ピクセルにおいて、モデルは2値分類を実行する必要があります。このような設定は、機械が反復的なアルゴリズムによる解を学習できるため（Bansal et al., 2022; Schwarzschild et al., 2021）、設計上機械に適しており、より自然な方法で考える必要がなくなります。それでも、モデルの学習可能性は疑問視されており、多くの場合、大規模な迷路への一般化を優先する慎重なモデル設計や目的関数設計に依存しています（Bansal et al., 2022; Zhang et al., 2025）。このような一般化は、確かに知能の重要な側面の一つです。
<!--
In this section, we use 2D mazes as a tool to investigate the behavior of the CTM when asked to plan
and navigate. Solving a 2D maze can be easy with the right inductive bias: by ensuring the output
space matches the dimensions of the input space, where at each pixel a model must perform binary
classification. Such a setup is amenable to machines by design, as they can learn iterative algorithmic
solutions (Bansal et al., 2022; Schwarzschild et al., 2021), and it excludes the need to think in a more
natural fashion. Even so, the trainability of models is questionable, with techniques often relying on
careful model and/or objective design that favors generalization to larger mazes (Bansal et al., 2022;
Zhang et al., 2025). Such generalization is certainly one important aspect of intelligence.
-->
</p><p>
しかし、迷路の解を単に見つけることと、思考プロセスに従って解を導き出すことの間には、決定的な違いがあります。このようなシステムの創発的な行動は印象的ですが（例えば、はるかに大きなサイズの迷路への一般化（Bansal et al., 2022））、これらのモデルが知性を示しているかどうかを判断するのは困難です。2D迷路課題をより困難にし、人間のような解法が必要となるようにするにはどうすればよいでしょうか。私たちは以下のことを提案します。
<!--
However, there is a critical distinction between simply finding the solution to a maze, versus following
a thought process to form said solution. While the emergent behavior of such systems can be
impressive (e.g., generalizing to mazes far greater in size (Bansal et al., 2022)), it is difficult to
reconcile whether these models are demonstrating intelligence. How can we make the 2D maze task
more challenging, such that a human-like solution is required? We propose the following:
-->
<div class="styleBullet">
<ul><li>
1. 出力空間を、開始（赤色のピクセルで示される）から終了（緑色のピクセルで示される）までのステップの集合として直接制約します。ステップごとに5種類の移動タイプ（左、右、上、下、または待機 <sup>5</sup>）のいずれかを含む、固定サイズの配列（長さ100 <sup>4</sup>）の形式の解が必要です。これにより、前述の単純な解法の影響を受けにくくなり、対象となる迷路に対するより深い理解が必要になります。
<!--
1. Constrain the output space directly as a set of steps from start (denoted by a red pixel) to
finish (green pixel). We require a solution in the form of a fixed-sized array (length 100<sup>4</sup>)
containing 1 of 5 movement types (Left, Right, Up, Down, or Wait<sup>5</sup>) per step. This mitigates
against the types of simple solutions described above and requires more of an understanding of
the target maze.
-->
</li></ul></div>

</p><p class="margin-large">
<sup>4</sup>
これは、一部の迷路では必要な長さよりも短い場合があり、その場合は後のステップを無視します。<br>
<br>
<!--
This may be shorter than required for some mazes, in which case we ignore later steps.
-->
<sup>5</sup>
ルートが100より短いインスタンスには「待機」クラスを使用し、ターゲットベクトルを待機クラスで埋めます。
<!--
We use ‘wait’ classes for instances where the route is shorter than 100, and fill the target vector with wait classes
-->
</p><p>
<div class="styleBullet">
<ul><li>
2. 注意を使用する際に位置埋め込みを禁止します。これには2つの理由があります。(1) モデルに内部的な「世界表現」の構築を強制し、データの継続的な理解に基づいて注意クエリを作成することしかできなくなるため。(2) より大きな迷路画像へのシームレスなスケーリングが可能になるためです（セクション4.3を参照）。
<!--
</li><br><li>2. Disallow positional embeddings when using attention. There are two reasons for this: (1) it
forces the model to build an internal ‘world representation’, where it can only craft attention
queries based on its ongoing understanding of the data; and (2) it enables seamless scaling to
bigger maze images (see Section 4.3).
-->
</li></ul></div>
</p><p>
2D迷路課題のこの新たな表現が、思考プロセスを追跡できるモデルを浮き彫りにする、挑戦的なベンチマークとなることを期待しています。私たちは、迷路データセットリポジトリ(Ivanitskiy et al., 2023)を用いて、訓練用に39×39の迷路、一般化テスト用に99×99の迷路を生成しました <sup>6</sup>。比較のために、以下の3つのモデルバリアントを訓練しました。
<!--
It is our hope that this new phrasing of the 2D maze task provides a challenging benchmark that
can highlight models that are able to follow a thought process. We used the maze-dataset repository
(Ivanitskiy et al., 2023) to generate 39 × 39 mazes for training and 99 × 99 for generalization tests6.
We trained three model variants for comparison:
-->

</p><p class="margin-large">
<sup>6</sup>
<a href="https://github.com/SakanaAI/continuous-thought-machines">CTM コード リポジトリ</a> を参照してください。
<!--
See the <a href="https://github.com/SakanaAI/continuous-thought-machines">CTM code repository</a>
-->
</p><p>

<div class="styleBullet">
<ul><li>
1. 制約付きResNet-34バックボーンを持つCTM。最初の2つのハイパーブロックのみを使用します。このCTMの構造は、画像分類で使用されるCTM（セクション3）とほぼ同じです。各内部ティックにおいて、CTMは開始位置からの経路を定義する行列y𝑡∈ℝを出力します（式6参照）。これは、可変内部ティック損失（式12）を用いて学習されます。また、損失関数を調整してカリキュラムアプローチを適用し、経路の初期ステップを後期ステップよりも最適化します。付録D.2にハイパーパラメータの詳細を、付録D.3にカリキュラムアプローチについて説明します。

</li><br><li>2. CTMと同じモデル幅を使用した1層、2層、および3層のLSTMベースライン（詳細は付録D.4を参照）。 LSTMベースラインもカリキュラムアプローチを採用していますが、迷路の少数のステップを超えて学習することはできませんでした。
</li><br><li>3. フィードフォワードのみ（つまり、再帰なし）のモデル（FF）。特徴量は隠れ層（CTMと同じ幅）を介して予測に投影されます（詳細は付録D.4を参照）。CTMモデルとLSTMモデルでは位置埋め込みを使用しないため、モデルは観測しているデータの内部表現を構築することを学習する必要がありますが、FFモデルではそのようなメカニズムは利用できません。そのため、最終的なResNet特徴量を平坦化し、代わりにy𝑡に投影することで、FFモデルが空間コンテキストを直接学習できるようにします。
<!--

1. A CTM with a constrained ResNet-34 backbone, using the first two hyper-blocks only. This
CTM is nearly identical in structure to those used in image classification (Sections 3). At each
internal tick the CTM outputs a matrix that defines a route from the start location, y𝑡 ∈ ℝ
100×5
(see Equation 6). It is trained with the variable-internal tick loss (Equation 12). We also adjust
the loss function to use a curriculum approach, optimizing for early steps in the route over
later steps. Appendix D.2 details hyper-parameters and Appendix D.3 explains the curriculum
approach.

</li><br><li>2. 1, 2, and 3-layer LSTM baselines using the same model width as the CTM (see Appendix D.4 for
details). The LSTM baseline also uses a curriculum approach, but was unable to learn beyond a
small number of steps in the maze.
</li><br><li>3. A feed-forward-only (i.e., no recurrence) model (FF) where the features were projected via a
hidden layer (same width as the CTM) to the prediction (see Appendix D.4 for details). Since
we use no positional embedding for the CTM and LSTM models they must learn to build an
internal representation of the data they are seeing, but no such mechanism is available to the
FF model. Therefore, we flatten the final ResNet features and project those to y𝑡 instead as this
lets the FF model learn spatial context directly.
-->
</li></ul></div>
</p><p>
同じ隠し幅を使用した場合、CTMは最も少ないパラメータを必要としました。詳細は付録D.4を参照してください。
<!--
Using the same hidden width, the CTM required the fewest parameters. See Appendix D.4 for more
details.
-->
</p>
<h3>4.1. 結果</h3>
<!--
<h3>4.1. Results</h3>
-->
<p>

図7aは、CTMとベースラインの精度を示しています。FFモデルと最良のLSTMモデルはどちらも過学習の兆候を示しており（損失曲線については付録D.5を参照）、その構造が問題に適していないことを示しています。このタスクで高い精度を達成したのはCTMのみです。私たちの実験では、LSTMで同じ性能を達成することはできませんでしたが、50内部ティックを使用した単層LSTMが最高の性能を達成しました。解を調べると、図7bのオレンジ色の曲線（「LSTM=1、50ティック」）に示すように、LSTMは解を学習し始めていますが、それを超えることはできないことがわかります。
<!--
Figure 7a shows the accuracies of the CTM versus baselines. The FF model and the best LSTM model
both show signs of overfitting (see Appendix D.5 for loss curves), indicating that their structure
is poorly suited to the problem. Only the CTM achieves high accuracy on this task. During our
experimentation we simply could not get the LSTM to achieve the same performance, with the
single-layer LSTM using 50 internal ticks achieving the best performance. Upon inspection of the
solution, and as shown by the orange curve (“LSTM=1, 50 ticks”) in Figure 7b, we can see that the
LSTM is beginning to learn a solution, but is unable to push beyond that.
-->
</p><p>

<strong>学習可能性</strong>　この場合、CTMとLSTMのパフォーマンスに大きな差があることから、学習可能性に関する疑問が生じます。CTMの方がはるかに最適化が容易です。迷路課題の解決は複雑です。なぜなら、データの相互作用を調整し、経路予測を生成し、さらにこれまでの位置の記憶を保持する複雑な表現を作成するモデルが必要だからです（詳細な議論はセクション4.4を参照）。CTMが最小限の変更（予測の形式のみ）でこれを実行できるという事実は、その有用性を証明しています。
<!--
<strong>Trainability.</strong>　The large disparity in performance between the CTM and LSTM in this case raises
questions of trainability, with the CTM being far easier to optimize. Solving the maze task is complex
because it requires a model to create and complex representation that modulates data interaction,
produces a route prediction, and also maintains a memory of its positioning thus far (see Section 4.4
for a longer discussion). The fact that the CTM can do this with minimal modifications (only the form
of the predictions) is testament to its utility.
-->
</p><p>

図7bは、ホールドアウトテストセットにおける経路長に対する精度を示しています。CTMは明らかに長い迷路を解く能力が高いのに対し、ベースライン手法は早い段階で性能が低下し始め、最も性能の高いLSTMでさえ迷路経路に沿って約20歩進んだところで性能が低下しています。これは、CTMの方が難しい問題を解く学習能力が高いことを示しています。深さ1のLSTMはパラメータ数で最も近い値を示しましたが、すべてのベースラインはより多くのパラメータを持っていました。言い換えれば、CTMの性能が優れているのは、パラメータ数が多いからではなく、ニューラルダイナミクスと同期が有用であるという考え方に基づいているからです。
<!--
Figure 7b shows accuracies versus route length on the held-out test set. The CTM is clearly more
capable of solving longer mazes, while the baseline methods start failing early on, with the best
performing LSTM losing capability after approximately 20 steps along maze paths. What this indicates
is that the CTM is more capable of learning to solve difficult problems. The depth 1 LSTMs were the


closest in terms of parameter counts, but all baselines had more parameters. In other words, the CTM
is not performing better because it has more parameters, but rather because of the ideas it is based
upon: neural dynamics and synchronization are useful.
-->
</p>
<center><img src="images/fig7.png"></center>
<p>

図7 | CTMとフィードフォワードベースラインおよび複数のLSTM設定の比較。CTMは、学習データに十分に適合し（ほぼ完璧な学習精度）、過適合せず（帰納的バイアスの適切な選択を示している（Utgoff, 2012））、長いパスで高いテスト精度を達成する唯一のモデルです。
<!--
Figure 7 | CTM versus a feed-forward baseline and several LSTM setups. The CTM is the only model that can fit sufficiently
to the training data (nearly perfect train accuracy), does not overfit (indicating a good choice of inductive bias (Utgoff,
2012)), and achieves high test accuracy for longer paths.
-->
</p>
<h3>4.2. デモンストレーション: CTMが一般的な手順を学習する</h3>
<!--
<h3>4.2. Demonstrations: the CTM learns the general procedure</h3>
-->
<p>

図8はCTMが辿るプロセスを示しています。時間経過に伴う平均（ヘッド全体）の注意重みを視覚化することで、CTMが迷路の終わりと予測される地点に到達するまで、妥当な経路に沿って系統的に進んでいく様子を見ることができます。この問題解決プロセスは、人間が上から下に向かって迷路を解く方法と全く同じではありません。ここで読者の皆様にご注意いただきたいのは、この迷路解法CTMは位置埋め込みを一切使用していないということです。つまり、迷路を通る経路を辿るためには、迷路の将来の状態を「想像」することで交差注意クエリを作成する必要があるのです。これは人間において「エピソード的未来思考」（Atance and O’Neill, 2001）として知られるプロセスです。
<!--
Figure 8 shows the process followed by the CTM. By visualizing the average (across heads) attention
weights over time, we can see how the CTM methodically steps along a plausible path until it reaches
what it predicts to be the end of the maze. This problem-solving process is not quite entirely unlike how
a human might approach solving a maze from the top down. We remind the reader to note now that
this maze-solving CTM is not using any positional embedding, meaning that in order for it to follow a
path through the maze it must craft the cross-attention query by ‘imagining’ the future state of the
maze: a process known as ‘episodic future thinking’ (Atance and O’Neill, 2001) in humans.
-->

</p>
<center><img src="images/fig8.png"></center>
<p>

図8 | 自然な迷路解法。各行は、CTMが異なる39×39の迷路を解く様子を示しています。左端の画像は、思考プロセス全体を通して注意の重心を色付きの矢印で示し、CTMが解の経路に沿ってどのように注意を払っているかを示しています。右側の画像は、CTMが異なる内部ティックで出力している解のスナップショットで、注意ヒートマップ（矢印と同じ色）が重ねて表示されています。(a)は典型的な例を示し、(b)は、CTMがトレーニング中に使用した内部ティックを超えて経路に沿って注意を払い続ける様子を示しています（このため、CTMはトレーニング時の2倍の長さで展開します）。プロジェクトページでは、追加の例と、CTMを操作してこのような迷路を解くインタラクティブなデモンストレーションを提供しています。
<!--
Figure 8 | A natural maze solving approach. Each row shows how the CTM solves a different 39 × 39 maze. The leftmost
images show, as colored arrows, the center of mass of attention throughout the thought processes, demonstrating how
the CTM attends along the solution route. The images to the right are snapshots of the solution the CTM is outputting at
different internal ticks, overlayed with an attention heatmap (color matched to the arrows). (a) shows a quintessential
example, and (b) shows how the CTM continues to attend along the route even beyond the internal ticks used during
training (for this we let the CTM unfold 2× longer than it was trained for). We give additional examples and provide an
interactive demonstration where you can interact with the CTM to solve mazes like this on our project page.
-->
</p><p>

このCTMは、開始位置から最大100歩先までを予測するように学習されました。図8aでは、CTMが迷路の終点（右端の緑のヒートマップ、約75個の内部目盛り）に注目している様子がわかります。これは、CTMが予測可能な100歩以内であるためです。これに対し、図8bでは、真のパスが100歩をはるかに超えています。学習時に使用したよりも多くの内部目盛りを使用して注意マップを評価すると、注意パターンはパスの残りの部分をトレースし続けます。これらの視覚化を作成するために、学習に使用した内部目盛りの2倍の回数でCTMを実行しました。
<!--
This CTM was trained to predict up to 100 steps outward from the start location. In Figure 8a
we can see how the CTM fixates its attention on the end of the maze (rightmost green heatmap;
approximately 75 internal ticks) since this is within the 100 steps it can predict. Contrast this with
Figure 8b, where the ground-truth path is far longer than 100 steps. The attention pattern continues
to trace out the remainder of the path when we assess the attention maps using more internal
ticks than what was used during training: to produce these visualizations we ran the CTM for 2× the
internal ticks it was trained on.
-->
</p><p>
この行動は創発的であり、CTMが単に訓練データを記憶するのではなく、基礎となる迷路課題の一般的な手順を学習したことを示唆しています。
<!--
This behavior is emergent and suggests that the CTM has learned a general procedure for the
underlying maze task, as opposed to merely memorizing the training data.
-->
</p><p>
次のセクションでは、このCTMが訓練に使用した迷路よりも大きな迷路にどのように一般化できるかを示します。
<!--
In the following section we demonstrate how this CTM can generalize to mazes bigger than what it
was trained on.
-->
</p>
<h3>4.3. より長い経路とより大きな迷路への一般化</h3>
<!--
<h3>4.3. Generalizing to longer paths and bigger mazes</h3>
-->
<p>
前のセクションでの観察から、CTMは学習に使用したデータを超えて一般化できる可能性があることが示唆されました。位置埋め込みを一切行わないことにした理由の一つは、このようなモデルは変更を加えることなくあらゆるサイズの迷路に適用できるからです。これを検証するために、CTMをより長い経路とより大きな迷路に適用しました。設定は以下のようにしました。
<!--
Our observations in the previous section suggested that the CTM might generalize beyond the data it
was trained on. One of the reasons we decided to forgo any positional embedding was that such a
model could be applied to a maze of any size without changes. To test this we applied the CTM to
longer paths and bigger mazes. We set this up as follows:
-->
<div class="styleBullet">
<ul><li>
1. より長い経路をテストするために、訓練で使用したのと同じサイズの迷路（39 × 39）にCTMを適用しました。ただし、100（CTMの出力値）を超える経路を持つ迷路に遭遇するたびに、CTMを再適用しました。再適用では、CTMの最終内部ティック（75）で出力された経路をたどる際に、開始点（赤いピクセル）を最終的な有効位置に移動しました。
</li><br><li>2. より大きな迷路に一般化する場合は、長い経路の場合と同じ手順に従いますが、99 × 99のサイズの迷路でテストします。
<!--
1. To test for longer paths we applied the CTM to the same-sized mazes as were used in training
(39 × 39), but re-applied the CTM whenever a maze was encountered that had a path longer
than 100 (that which the CTM was trained to output). For re-application we simply moved the
starting point (red pixel) to the final valid position when following the path output by the
CTM at its final internal tick (of 75).
</li><br><li>2. When generalizing to bigger mazes, we follow the same protocol as longer paths, but test on
mazes of size 99 × 99.
-->
</li></ul></div>
</p><p>

図9は、より長い経路やより大きな迷路に一般化した場合の結果を示しています。CTMは39×39の迷路ではどの長さの経路でもほぼ完璧なパフォーマンスを発揮しますが、99×99のより大きな迷路ではパフォーマンスが低下し始めます。これはおそらく、大きな迷路では開始点と終了点間の絶対距離が大きくなるためです。今後の研究では、以下の連続的なトレーニング方法を検討する予定です。(1) CTMによって予測された終了点を考慮し、(2) 現在のニューラルダイナミクスを維持し、(3) 開始点を予測された終了点に「テレポート」し、(4) そこから次のミニバッチを継続します。このような設定は、CTMのシーケンシャルな性質により適しています。読者の皆様には、プロジェクトページにあるインタラクティブなデモをご利用いただき、CTMを操作してこのような迷路を解くことができることをお勧めします。「オープンワールド」トレーニングに関する議論については、セクション12の今後の研究に関する議論を参照してください。
<!--
Figure 9 shows the results when generalizing to longer routes and bigger mazes. The CTM performs
nearly perfectly for any length route on the 39 × 39 mazes, but performance begins to taper off for
the larger 99 × 99 mazes. This is probably owing to the larger absolute distances between start and
end points for larger mazes. For future work, we expect to explore a continuous training regime that:
(1) accounts for the end point predicted by the CTM, (2) keeps the current neural dynamics, (3)
‘teleports’ the starting point to the predicted end, and (4) continues from there for the next minibatch.
Such a setup would be better suited to the sequential nature of the CTM. We encourage readers to
use our interactive demonstration where you can interact with the CTM to solve mazes like this
on our project page. See the future work discussion in Section 12 for a discussion on ‘open-world’
training.
-->
</p>
<center><img src="images/fig9.png"></center>
<p>

図9 | より長い経路とより大きな迷路に一般化した場合のCTMの精度。このCTMは、経路長100（トレーニングデータでは経路長が長い場合は切り捨て）までの39×39サイズの迷路を解くように学習されました。(b)では、開始点をCTMが特定の迷路に対して予測する終点に移動すると「再適用」が発生します。(c) 39×39と(d) 99×99の迷路の一般化例を示します。虹色（赤から青）は、再適用ごとの予測ステップ数を示しています。初期の開始点と終点は、見やすさを考慮して大きく表示されています。
<!--
Figure 9 | CTM accuracy when generalizing to longer paths and bigger mazes. This CTM was trained to solve mazes of size
39 × 39, up to a route length of 100 (truncated for longer routes in the training data). In (b) ‘re-application’ occurs when
we move the start point to the end of where the CTM predicts for a given maze. We show the generalization examples
for (c) 39 × 39 and (d) 99 × 99 mazes, where the rainbow of colors (from red to blue) denote the predicted steps per
re-application. The initial start and end points are made larger for viewing clarity.
-->
</p>
<h3>4.4. 考察：世界モデルと認知マップの必要性</h3>
<!--
<h3>4.4. Discussion: the need for a world model and cognitive map</h3>
-->
<p>

世界の内部モデルと認知マップは、知能システムの重要な側面を表しています(Gornet and Thomson, 2024; Ha and Schmidhuber, 2018; LeCun, 2022)。この場合、世界モデルとは外部環境の内部表現であり、エージェントの世界の構造、ダイナミクス、そしてその中での自身の行動可能な位置に関する知識を包含するものであると考えます。優れた世界モデルは、エージェントが世界について推論し、計画を立て、行動の結果を予測できるようにする必要があります。認知マップ(Gornet and Thomson, 2024)は、特に空間関係とナビゲーションに焦点を当てています。これらの内部表現を構築し、活用する能力は、高度な知能の強力な指標であり、おそらく前提条件でもあります。「エピソード的未来思考」という概念(Atance and O’Neill, 2001)は、人間の知能の代表的な特徴とさえ考えられています。世界モデルを持たないエージェントは、反応的な行動しかとれません。同様に、認知マップを持たないエージェントは、複雑な空間環境内を効果的に移動したり相互作用したりする能力が著しく制限されます。したがって、世界モデルと認知マップの存在と洗練度は、知能を評価するためのベンチマークとして役立ちます。
<!--
Internal models of the world and cognitive maps represent crucial aspects of intelligent systems
(Gornet and Thomson, 2024; Ha and Schmidhuber, 2018; LeCun, 2022). In this case, we consider a
world model to be an internal representation of the external environment, encapsulating an agent’s
knowledge about the world’s structure, its dynamics, and its actionable place therein. A good world
model should enable an agent to reason about the world, plan, and predict the consequence of its
actions. Cognitive maps (Gornet and Thomson, 2024) specifically focus on spatial relationships and
navigation. The ability to construct and utilize these internal representations is a strong indicator,
and arguably a prerequisite, for sophisticated intelligence. The notion of ‘episodic future thinking’
(Atance and O’Neill, 2001) is even considered a hallmark feature of human intelligence. An agent
devoid of a world model would be limited to reactive behaviors. Similarly, lacking a cognitive map
would severely restrict an agent’s ability to navigate and interact effectively within complex spatial
environments. Therefore, the presence and sophistication of world models and cognitive maps can
serve as a benchmark for evaluating intelligence.
-->
</p><p>

この目的のため、我々は迷路課題を、解くために優れた内部世界モデルが必要となるように設計した。これは、(1) 局所アルゴリズムで迷路を解くのではなく、モデルが直接経路を出力することを要求すること (Schwarzschild et al., 2021)、(2) 画像表現における位置の埋め込みを放棄すること、つまり、モデルが課題を解決するために独自の空間認知マップを構築する必要があること (Gornet and Thomson, 2024) によって実現された。実際、CTMのNLMと同期コンポーネントにより、CTMは2D迷路課題を解くことができ、訓練した最高のベースラインをはるかに上回る結果が得られた。これらの結果は、CTMが環境の内部モデルを構築し、活用する能力がより優れていることを示唆している。
<!--
To this end, we designed the maze task such that it would require a good internal world model
to solve. This was achieved by (1) requiring the model to output a route directly, as opposed to
solving the maze with a local algorithm (Schwarzschild et al., 2021), and (2) forgoing any positional
embedding in the image representation, meaning that the model must build its own spatial cognitive
map in order to solve the task (Gornet and Thomson, 2024). Indeed, we saw that the NLMs and
synchronization components of the CTM enables it to solve our 2D maze task, far surpassing the best
baselines we trained. These results suggest that the CTM is more capable of building and utilizing an
internal model of its environment.
-->
</p>
<h2>5. CIFAR-10: CTMと人間およびベースライン</h2>
<!--
<h2>5. CIFAR-10: the CTM versus humans and baselines</h2>
-->
<p>

このセクションでは、CIFAR-10を用いてCTMをテストし、人間のパフォーマンス、フィードフォワード（FF）ベースライン、およびLSTMベースラインと比較します。モデルベースのベースラインでは、特徴量化後のモデル構造（CTM、LSTM、FF）による差異を強調するために、制約付き特徴量化バックボーンを使用しました。また、CTMとLSTMに「考える時間」を与えるために、50の内部ティックを使用しました。アーキテクチャの詳細は付録Eに記載しています。人間のベースラインとモデルのベースラインは、次のように設定されました。
<!--
In this section we test the CTM using CIFAR-10, comparing it to human performance, a feed-forward
(FF) baseline, and an LSTM baseline. For the model-based baselines, we used a constrained featurization
backbone in order to emphasize the differences owing to the model structure post-featurization
(i.e., CTM versus LSTM versus FF). We also used 50 internal ticks to give the CTM and LSTM ‘time to
think’. We give full architecture details in Appendix E. The human and model baselines were set up
as follows:
-->
<div class="styleBullet">
<ul><li>
• 人間のベースライン。CIFAR-10には、人間のラベルを用いた2つのデータセットを使用しました。難易度のキャリブレーションを行っていることから、これらをCIFAR-10D (Ho-Phuoc, 2018)、そして元々人間の不確実性を定量化するために使用されていたCIFAR-10H (Peterson et al., 2019)と呼んでいます。7 CIFAR-10Dは簡単なサンプルと難しいサンプルを判別するために使用し、CIFAR-10Hは人間の直接的なベースラインとして使用しました。
<!--
• Human baseline. We used two datasets of human labels for CIFAR-10; we call these CIFAR-10D
(Ho-Phuoc, 2018) owing to its calibration of difficulty levels, and CIFAR-10H (Peterson et al.,
2019) originally used to quantify human uncertainty.7 We used CIFAR-10D to determine easy
versus difficult samples, and CIFAR-10H as a direct human baseline.
-->
</li></ul></div>

</p><p class="margin-large">
<sup>7</sup>
CIFAR-10D は <a href="https://sites.google.com/site/hophuoctien/projects/virec/cifar10-c
lassification">https://sites.google.com/site/hophuoctien/projects/virec/cifar10-c
lassification</a> でご覧いただけます。CIFAR-10H は <a href="https://github.com/jcpeterson/cifar-10h">https://github.com/jcpeterson/cifar-10h</a> でご覧いただけます。
<!--
CIFAR-10D can be found at <a href="https://sites.google.com/site/hophuoctien/projects/virec/cifar10-c
lassification">https://sites.google.com/site/hophuoctien/projects/virec/cifar10-c
lassification</a>; CIFAR-10H can be found at <a href="https://github.com/jcpeterson/cifar-10h">https://github.com/jcpeterson/cifar-10h</a>
-->
</p><p>

<div class="styleBullet">
<ul><li>
• FFベースライン。フィードフォワードのみのベースライン（FFと表記）。平均プーリング後にResNet特徴量にMLPを適用し、隠れ層の幅は本実験のCTMのパラメータ数と一致するように設定しました。
</li><br><li>• LSTMベースライン。内部思考次元で展開するように設定されたLSTM。隠れ層の幅はCTMのパラメータ数と一致するように設定されています。LSTMは各ステップで画像に注目し、有効な比較のためにATMと同じ損失を使用しました。

<!--
• FF baseline. A feed-forward only baseline (denoted FF). An MLP was applied to ResNet features
after average pooling, where the width of the hidden layer was set to match the parameter
count of the CTM for this experiment.
</li><br><li>• LSTM baseline. An LSTM set up to unroll with an internal thought dimension, with a hidden
width set to match the parameter count of the CTM. The LSTM could attend to the image at
each step and used the same loss as the ATM for valid comparison.
-->
</li></ul></div>
</p><p>

図10は、CTM、FF、LSTMモデルの学習曲線と、それぞれのキャリブレーションプロットを示しています。これには、CIFAR-10Hを用いた人間によるキャリブレーションの推定値も含まれています。FFベースラインは早い段階で高い学習精度に達しますが、汎化ギャップが小さいことも示されています。LSTMは学習中の安定性が低く（このため、すべての実験で学習率を0.0001に設定する必要がありました）、テスト精度がわずかに向上しています。CTMはより安定しており、パフォーマンスも優れています。
<!--
Figure 10 shows the training curves of the CTM, FF, and LSTM models, and calibration plots for
each, including an estimation of human calibration using CIFAR-10H. The FF baseline reaches a high
training accuracy early on, but also demonstrates a poor generalization gap. The LSTM is less stable
during training (we had to set the learning rate to 0.0001 for all experiments because of this) and
yields a marginally improved test accuracy. The CTM is more stable and performant.
-->
</p>
<center><img src="images/fig10.png"></center>
<p>
図10 | CIFAR-10の学習曲線（3シードの平均）と、CTM、フィードフォワードのみのベースライン、LSTMベースラインのキャリブレーションプロット。CTMはLSTMよりもフォワードパスあたり±2.4倍遅いものの、学習中はより安定しています。CTMは最高のテスト性能を示しています。キャリブレーションプロットを見ると、人間のベースライン（Peterson et al., 2019）でさえキャリブレーションが不十分であるのに対し、CTMは良好なキャリブレーションを示しており、人間と驚くほど似た方法で失敗していることがわかります。
<!--
Figure 10 | CIFAR-10 training curves (average over 3 seeds) and calibration plots for the CTM, a feed-forward only baseline,
and an LSTM baseline. The CTM is slower than the LSTM per forward pass (±2.4×) but is also more stable during learning.
The CTM has the best test performance. The calibration plot shows that even a human baseline (Peterson et al., 2019) is
poorly calibrated, and that the CTM demonstrates good calibration, failing in a way that is strikingly similar to humans.
-->
</p><p>
人間によるキャリブレーションには、CIFAR-10Hで提供されている確率を使用しました。これは、複数の人間による推測に基づいて計算されたものです。ここでも、ImageNet-1Kと同様にキャリブレーションを計算しました（図3c参照）。つまり、選択されたクラスのすべての内部ティックにおける平均確率として予測確率を計算しました。どのモデルも完璧にキャリブレーションされているわけではありませんが、CTMは人間と比較しても最高のキャリブレーションを示しています。驚くべきことに、CTMは人間よりも優れたキャリブレーションを示していますが、LSTMは人間の自信不足を反映しています。
<!--
For the human calibration we used the probabilities provided in CIFAR-10H, which were computed
using guesses from multiple humans. We computed calibration here as we did for ImageNet-1K (see
Figure 3c): we compute the predictive probability as the average probability for the chosen class over
all internal ticks. None of the models are perfectly calibrated, but the CTM demonstrates the best
calibration, even when compared to humans. Strikingly, the CTM has even better calibration than
humans, while the LSTM follows the human under-confidence.
-->
</p><p>

図11aは、CIFAR-10Dデータセットを用いて決定された難易度に対して、モデルとCIFAR-10Hを比較しています。この場合、各モデルと人間は同様の傾向を示していますが、CTMはCIFAR-10Hに最もよく似ています。図11bと11cは、CTMとLSTMの不確実性を人間の不確実性と比較しています（不確実性の代理としてCIFAR-10Hの反応時間を使用）。CTMとLSTMの不確実性は、正規化エントロピー（セクション2.5を参照）を内部ティックで平均して計算します。これは、各モデルが観測データに関して持つ全体的な不確実性を近似するためです。CTMとLSTMはどちらも人間の反応時間と同様の傾向を示しています。
<!--
Figure 11a compares models and CIFAR-10H against the difficulty determined using the CIFAR-10D
dataset. Each model and humans have similar trends in this case, although the CTM follows most
closely to CIFAR-10H. Figures 11b and 11c compare the uncertainties of the CTM and LSTM to
the uncertainties of humans (using reaction times from CIFAR-10H as a proxy for uncertainty). We
compute the CTM and LSTM uncertainties using the normalized entropies (see Section 2.5) averaged
over internal ticks as this approximates the total uncertainty each model has regarding the observed
data. Both the CTM and LSTM exhibit trends similar to human reaction times.
-->
</p>
<center><img src="images/fig11.png"></center>
<p>
図11｜モデルと人間のパフォーマンスと難易度の関係分析。Ho-Phuoc (2018) の難易度較正を使用し、CIFAR-10H (Peterson et al., 2019) の人間の予測値と比較しました。人間の反応時間は不確実性の適切な代理指標であると仮定し、これをCTMとパラメータマッチングされたLSTMベースラインの不確実性の傾向と比較します。ここで視覚化されている誤差は、尺度標準偏差です。
<!--
Figure 11 | Analysis of model and human performance versus difficulty. We used the difficulty calibration from Ho-Phuoc
(2018) and compared human predictions from CIFAR-10H (Peterson et al., 2019). We assume that human reaction times
are a reasonable proxy for uncertainty and compare this to the trend in uncertainty for the CTM and a parameter-matched
LSTM baseline. The error visualized here is a scaled standard deviation.
-->
</p><p>

図12は、CTMとLSTMベースラインの神経活動を示しています。CTMは、周期的な動作（周期的な駆動関数は存在しない）を含む複数の興味深い特徴を備えた、豊かで多様かつ複雑なダイナミクスを生み出します。CTMとLSTMの神経活動の明確な違いは、CTMの2つの新しい要素（NLMと表現としての同期）が、神経ダイナミクスを基本的な計算ツールとして利用できることの証拠です。
<!--
Figure 12 shows the neural activities for the CTM and the LSTM baseline. The CTM yields rich,
diverse, and complex dynamics with multiple interesting features, including periodic behavior (there
is no periodic driving function). The distinct difference between the CTM and LSTM neural activities
is evidence that the two novel elements of the CTM (NLMs and synchronization as a representation)
enable neural dynamics as a fundamental computational tool.
-->


</p>
<center><img src="images/fig12.png"></center>
<p>

図12 | CTMとLSTMベースラインのニューロントレース。CTMがCIFAR-10の分類時においても複雑なニューラルダイナミクスを生成・利用している様子を示しています。LSTMはここに示した活性化後の履歴においてある程度の動的な挙動を示していますが、LSTMほどの程度ではありません。各サブプロット（ランダムな色で表示）は、内部の目盛りにおける1つのニューロンの活動を示しています。異なる画像の複数の例は薄い背景線で示され、前景の線はランダムに選択された例から取得されています。
<!--
Figure 12 | Neuron traces for the CTM and an LSTM baseline, showing how the CTM produces and uses complex neural
dynamics even when classifying CIFAR-10. The LSTM yields some dynamic behavior in the post-activation histories shown
here, but not nearly to the same degree. Each subplot (in a random color) shows the activity of a single neuron over internal
ticks, where multiple examples for different images are shown as faint background lines, and the foreground line is from a
randomly chosen example.
-->

</p>
<h2>6. CIFAR-100：アブレーション解析</h2>
<!--
<h2>6. CIFAR-100: ablation analysis</h2>
-->
<p>
このセクションでは、CTMの2つの側面、(1)幅（つまりニューロン数）、(2)内部ティック数について考察します。CIFAR-100はCIFAR-10よりも難易度が高いデータセットでありながら、計算負荷は比較的低いため、以下の実験ではCIFAR-100を使用しました。
<!--
In this section we explore two aspects of the CTM: (1) width (i.e., number of neurons), and (2)
number of internal ticks. We used CIFAR-100 in the experiments discussed below as it is a more
challenging dataset than CIFAR-10, while remaining relatively low-demand regarding compute.
-->
</p>
<h3>6.1. ニューロン数の変化</h3>
<!--
<h3>6.1. Varying the number of neurons</h3>
-->
<p>
図13aは、固定バックボーンネットワーク（詳細は付録F.1を参照）におけるCIFAR-100の精度とモデル幅（ニューロン数）の関係を示しています。この図では、テスト性能がある程度向上した後、性能が低下していることがわかります。この性能低下は過学習に関連している可能性もありますが、モデル幅が広くなるほどより多くのトレーニングが必要になる（トレーニング反復回数は固定）ことも原因の一つと考えられます。
<!--
Figure 13a shows CIFAR-100 accuracy versus model width (i.e., the number of neurons) for a fixed
backbone network (details of which in Appendix F.1), evidencing improved test performance to a
point, and then a reduction in performance. The performance drop-off might be related to overfitting,
but it might also be that a wider model requires more training (we set a fixed number of training
iterations).
-->
</p><p>

図13bと13cは、モデルの幅とニューロン活動の多様性の関係を示しています。
直感的に、ニューロン数が多いほどニューロン活動の度合いも高くなると予想されますが、これらの分布はまさにそのことを示しています。図13bでは、ニューロンレベルでデータポイント全体（全ニューロン平均）のコサイン類似度を測定すると、モデルの幅が広いほどゼロ付近の分布が狭くなっていることがわかります。これは、モデルの幅が広いほどニューロンの類似度が低くなることを意味します。これは、CTMがニューロンの数が多いほど、ニューラルダイナミクスにおいてデータポイントに関するより多くの情報をエンコードできることを示しています。図13cは、同様の量を示しています。これは、同じデータポイントについてニューロン間のコサイン類似度を測定したもの（多くの異なるデータポイント平均）です。この場合、モデルの幅が広いほど分布がわずかに狭くなるだけです。
<!--
Figures 13b and 13c show a relationship between model width and the diversity of neural activity.
Intuitively, we expect that with more neurons we would observe a greater degree of neural activity,
and these distributions show exactly that. In Figure 13b we see that when measuring cosine similarity
on a neuron-level across data points (averaged over all neurons), a wider model results in a tighter
distribution around zero. This means that a wider model results in less similar neurons, indicating
that the CTM can encode more information about a data point in its neural dynamics when there
are more neurons to work with. Figure 13c shows a similar quantity, where we measure the cosine
similarity across neurons for the same data points (averaged over many different data points). In this
case the wider model only results in a slightly tighter distribution.
-->
</p>
<center><img src="images/fig13.png"></center>
<p>

図13 | 異なるモデル幅におけるCIFAR-100の精度とニューロン類似度。(b) データ全体のニューロン類似度については、128枚の画像サンプルにおけるすべてのニューロンペアについて、対応するニューロン間の平均（ニューロン全体）コサイン類似度を計算しました。各バーは、この平均ニューロン類似度を持つ画像ペアの割合です。(c) ニューロン全体のニューロン類似度については、各モデル内のすべてのニューロンペアについて、平均（データ全体）コサイン類似度を計算しました。各バーは、この平均コサイン類似度を持つニューロンの割合です。コサイン類似度が0に絶対的に近いほど、非類似性が高く、ニューロンの多様性が向上していることを示します。
<!--
Figure 13 | CIFAR-100 accuracies and neuron similarities for different model widths. For (b) neuron similarity across data,
we computed the average (over neurons) cosine similarities between matched neurons for all pairings across a sample of
128 images – each bar is the proportion of image pairings that have this average neuron similarity. For (c) neuron similarity
across neurons, we compute the average (over data) cosine similarities for all pairs of neurons within each model – each
bar is the proportion of neurons having that average cosine similarity. Cosine similarity absolutely closer to zero indicates
dissimilarity, and hence improved neuron diversity.
-->
</p>
<h3>6.2. より長い思考の影響</h3>
<!--
<h3>6.2. The impact of longer thinking</h3>
-->
<p>
図14は、内部ティックがCTMに与える影響を示しており、(a) 内部ティックに対する精度と、(b) CTMが最も確実性の高い内部ティックの分布を示しています。図14aの精度はほぼ同じですが、50個の内部ティックを使用したCTMが最も高いパフォーマンスを示しました。これは、内部ティックの数が多いほど、より多くのトレーニングが必要であることを改めて示唆しています。
<!--
Figure 14 explores the impact of internal ticks on the CTM, showing (a) accuracies versus internal
ticks and (b) the distributions over internal ticks where the CTM is most certain. The accuracies
in Figure 14a are close, although the CTM using 50 internal ticks was the most performant. This
suggests once more that with more internal ticks more training might be warranted.
-->
</p><p>
図14bにおいて、確信度の高い領域が2つ出現していることは興味深い。これは、これらのCTMが、データに応じて内部的に2つの異なるプロセスを経て、より多くの「考える時間」を持つことで実際に恩恵を受けていることを示しているからである。なぜこのような結果が現れるかを正確に説明するのは困難であるが、これらの分布が均一とは程遠いという事実は、単に結果を厳密にフィードフォワード的に計算するよりも複雑なプロセスがあることを示唆しており、今後の研究ではさらなる分析が必要である。

<!--
The emergence of two regions of high certainty in Figure 14b is interesting as it indicates that these
CTMs do indeed benefit from having more ‘time to think’, perhaps following two different processes
internally depending on the data. Although it is difficult to say exactly why this emerges, the fact that
these distributions are far from uniform indicates a more complex process than simply computing the
result in a strictly feed-forward nature; more analysis is required in future work.
-->
</p>
<center><img src="images/fig14.png"></center>
<p>
図14 | CIFAR-100の精度と内部ティック分析。(b)の分布と精度は、CTMが最も確実であった内部ティック（x軸）について計算されたものである（セクション2.5参照）。いずれの場合も、CTMには、使用される内部ティックの数に関わらず、初期と後期の2つの確実性領域が存在する。
<!--
Figure 14 | CIFAR-100 accuracies and internal tick analysis. The distributions and accuracies in (b) are computed for those
internal ticks (x-axis) where the CTM’s were the most certain (see Section 2.5). In each case the CTM has two regions of
certainty, early on and later, regardless of how many internal ticks are used.
-->
</p>
<h2>7. ソート</h2>
<!--
<h2>7. Sorting</h2>
-->
<p>
このセクションでは、正規分布から抽出された30個の数値をソートするタスクにCTMを適用します。
実数のソートは、Graves (2016) が適応型計算用のRNNを設計する際に検討したタスクであり、CTMのような適応型計算システムにおける計算の役割を理解するためのテストベッドを提供します。この場合、CTMはアテンションを使用せず、ランダムにシャッフルされた入力データ（30個の実数）を直接取り込みます。これは、図1の⑩をアテンション機構に置き換え、単純な連結に置き換えることで実装されます。
<!--
In this section, we apply the CTM to the task of sorting 30 numbers drawn from the normal distribution.
Sorting real numberswas a task explored by Graves (2016) when designing RNNs for adaptive compute,
and it provides a test bed for understanding the role of compute for an adaptive-compute system, such
as the CTM. In this case the CTM does not use attention, but rather ingests the randomly shuffled
input data (30 real numbers) directly. This is implemented by replacing the attention mechanism
with a straightforward concatenation, replacing ⑩ in Figure 1.
-->
</p><p>
<strong>ATMは時系列出力を生成できるか？</strong>　この実験では、CTMを内部ティック全体にわたってシーケンスを出力するように設定しました。これはシーケンスをモデリングするためのより標準的なアプローチであり、CTMをこの方法でトレーニングできるかどうかを理解したかったのです。各内部ティックにおいて、CTMは長さ31のベクトルを出力します。これには、ソート用の30個のインデックスと、よく知られているコネクショニスト時間分類（CTC）損失（Graves et al., 2006）に使用される「空白」トークンが含まれます。次に、このCTC損失をCTMの内部ティック全体にわたる出力に適用しました。
<!--
<strong>Can the ATM produce sequential outputs?</strong>　For this experiment we set the CTM up to output a
sequence over its internal ticks. This is a more standard approach to modeling sequences and we
wanted to understand whether the CTM could be trained in this fashion. At each internal tick the
CTM output a vector of length 31, including 30 indices for sorting and the ‘blank’ token used for the
well-known connectionist temporal classification (CTC) loss (Graves et al., 2006). We then applied
this CTC loss over the full output of the CTM over its internal ticks.
-->
</p><p>

図15は、ソートタスクにおけるCTMの結果を示しています。CTMが辿るプロセスには明確なパターンがあり、待機時間と現在のシーケンスインデックス(a)、および出力中の前の値と現在の値の差(b)との相関関係が見られます。同様のタスクがGraves (2016)によって検討されており、適応型計算RNNを用いて15個の数値をソートしました。彼らのケースでは、出力開始前（最初のシーケンス要素に類似）とシーケンスの終了近くで同様の待機時間が観測されました。待機時間と現在のデータ値と前のデータ値の差（図15bで「データデルタ」と呼んでいるもの）の関係を分析した結果、CTMがデータのレイアウトに依存する内部アルゴリズムを使用していることが示されました。また、このCTMがトレーニングデータ以外の分布にも一般化できることも示しています。
<!--
Figure 15 gives the results of the CTM on the sorting task. There is a clear pattern to the process
it follows, as evidenced by a correlation between wait times and both the current sequence index
(a) and the difference between the previous value and the current value being output (b). A similar
task was explored by Graves (2016), who sorted 15 numbers using an adaptive compute RNN. In
their case, they observed similar wait times before beginning output (analogous to our first sequence
element) and also near the end of the sequence. Our analysis of the relationship between wait times
and the difference between current and previous data values (what we call ‘data delta’ in Figure 15b
constitutes evidence that the CTM is using an internal algorithm that depends on the layout of the
data. We also show that this CTM generalizes to distributions outside of the training data.
-->
</p>
<center><img src="images/fig15.png"></center>
<p>

図15 | N(0,𝐼30)でソートした結果。(a)では、平均待ち時間に明らかなパターンが見られます。初期の待ち時間（内部ティック数）は長く、その後最低値まで下がり、シーケンスの終わりに向かってわずかに上昇しています。(b)では、CTMがさまざまな待ち時間を採用していますが、前回の出力値と現在の出力値の差（「データデルタ」）が待ち時間に影響を与えていることがわかります。(c)では、このCTMが異なる正規分布から抽出されたデータにどのように適応できるかがわかります。
<!--
Figure 15 | Results when sorting on N(0, 𝐼30). In (a) we can see an evident pattern in the average wait times, where the
initial wait time (number of internal ticks) is high, goes to its lowest point, and has a slightly higher bump toward the end
of the sequence. In (b) we see that the CTM employs various wait times, but that the difference between the previous
output value and the current output value (‘data delta’) impacts wait time. In (c) we see how this CTM can scale to data
drawn from different normal distributions.
-->
</p><p>
図16は、実際のユースケースにおけるCTMの待機時間を示しています。赤いバーは、特定のインデックスの平均よりも長い待機時間を示し、緑のバーは平均よりも短い待機時間を示しています。待機時間が長くなると、データポイント間のギャップ（図15bの「データデルタ」）が大きくなる傾向があります。
<!--
Figure 16 demonstrates the CTM’s wait times in a real use-case. The red bars indicate longer than
average wait times for a given index, and green bars indicate shorter than average wait times. Longer
wait times tend to be related to bigger gaps between data points (‘data delta’ in Figure 15b).
-->

</p>
<center><img src="images/fig16.png"></center>
<p>
図16 | ソートのデモンストレーション。入力データは縦線で表され、その色は元のシャッフル位置（「レインボー」カラーマップでは紫から赤）を表します。赤と緑のバーは、それぞれ平均待ち時間（シーケンス内の各インデックスについて図15aを参照）からの正と負の偏差を示します。
<!--
Figure 16 | Sorting demonstration. The input data is represented as vertical lines whose colors denote their original
shuffled position (from purple through to red in the ‘rainbow’ colormap). The red and green bars show positive and negative
deviation from the mean wait time (Figure 15a for each index in the sequence), respectively.
-->
</p>
<h2>8. パリティ</h2>
<!--
<h2>8. Parity</h2>
-->
<p>

バイナリシーケンスのパリティは、その要素の積の符号によって与えられます。シーケンスを要素ごとに処理する際、RNN は内部状態を維持し、負の数に遭遇するたびに内部の「スイッチ」を切り替えることでパリティを計算できると考えられます。しかし、シーケンス全体が同時に提供されると、入力に含まれる異なるパターンの数が増えるため、タスクの難易度が上昇します。以前の研究 (Graves, 2016) では、静的に提示されたデータに対してシーケンシャルアルゴリズムを学習できるリカレントモデルを用いてこの課題に取り組んでいます。このように提示されたパリティ計算は、CTM の能力をテストするのに適しています。
<!--
The parity of a binary sequence is given by the sign of the product of its elements. When processing a
sequence element by element, an RNN could conceivably compute parity by maintaining an internal
state, flipping an internal ‘switch’ whenever a negative number is encountered. However, if the entire
sequence is provided simultaneously, the task increases in difficulty due to the increasing number
of distinct patterns in the input. Previous work (Graves, 2016) has addressed this challenge using
recurrent models, which can learn sequential algorithms for statically presented data. Computing
parity, as posed in this manner, is well-suited for testing the capabilities of the CTM.
-->
</p><p>
ランダムな位置に値1と-1を含む64ビット長のシーケンスのパリティを計算するタスクにCTMを適用します。Graves (2016)とは異なり、モデルがシーケンスの最終パリティだけでなく、すべてのインデックスにおける累積パリティを計算するようにタスクを設定します。例を図17に示します。値-1と1は、入力データの取り込みにAttentionを使用し、位置埋め込みと組み合わせた学習可能なベクトルとして埋め込まれます。CTMは、セクション2.5で説明した損失関数を用いて学習します。ベースラインとしてLSTMも学習しましたが、LSTM学習において最良の結果と安定性が得られるため、最終反復を𝑡2に設定しました。詳細は付録Gを参照してください。
<!--
We apply the CTM to the task of computing the parity of a 64-length sequence containing the values
1 and -1 at random positions. Unlike Graves (2016), we set up the task such that the model computes

the cumulative parity at every index of the sequence, not just the final parity. An example is shown
in Figure 17. The values -1 and 1 are embedded as learnable vectors combined with positional
embeddings, using attention to ingest input data. We train the CTM with the loss function described
in Section 2.5. As a baseline we also trained an LSTM, but set 𝑡2 to be the final iteration since this
gave the best results and stability for LSTM training. See Appendix G for more details.
-->
</p>
<center><img src="images/fig17.png"></center>
<p>
図17 | パリティタスク。入力(a)は64個のバイナリ値のシーケンス（左上から右下）であり、ターゲット(b)は各位置における累積パリティです。ここで、□は正パリティ、■は負パリティを示します。
<!--
Figure 17 | Parity task. The input (a) is a sequence of 64 binary values (top left to bottom right), and the target (b) is the
cumulative parity at each position. Here □ indicates positive parity and ■ indicates negative parity.
-->
</p>
<h3>8.1. 結果</h3>
<!--
<h3>8.1. Results</h3>
-->
<p>
<strong>精度は思考時間とともに向上します。</strong> 図18aと18bは、CTMの様々な構成における学習曲線と最終的な精度を示しています。ここでは、内部ティック数(𝑇)とメモリ長(𝑀)を変化させています。また、比較のために、パラメータを一致させたLSTMベースラインもプロットしています。
一般的に、CTMの精度は内部ティック数が増えるにつれて向上します。最も優れたモデルは、内部ティック数が75または100のCTMで、シード実行によっては100%の精度に達することもありました。一方、LSTMベースラインはタスクの学習に苦労し、内部ティック数が10の最も優れたLSTMでも、精度は67% ± 0.05%でした。内部ティック数が10を超えるLSTMベースラインは、学習が不安定な挙動を示しています。これは、第4.1節で述べた、単純な回帰モデルは必ずしも内部思考プロセスの展開に適しているわけではないという観察結果と一致しています。CTMははるかに安定した学習結果を示していますが、ランダムシードの選択により最終的な精度にかなりのばらつきがあります。この点については付録G.4で詳しく説明します。
<!--
<strong>Accuracy increases with thinking time.</strong>　Figures 18a and 18b show the training curves and final
accuracies for various configurations of the CTM, where we changed the number of internal ticks
(𝑇) and memory length (𝑀). We also plot parameter-matched LSTM baselines for comparison.
Generally, the accuracy of the CTM improves as the number of internal ticks increases. The bestperforming
models were CTMs with 75 or 100 internal ticks, which could reach 100% accuracy
in some seeded runs. The LSTM baselines, on the other hand, struggle to learn the task, with the
best performing LSTM, which had 10 internal ticks, achieving an accuracy of 67% ± 0.05%. The
LSTM baselines with over 10 internal ticks demonstrate unstable learning behavior; this mimics
our observations in Section 4.1, that simple recurrent models are not necessarily well-suited to
unfolding an internal thought process. Although the CTM exhibits much more stable training, there
is considerable variance in final accuracies due to the choice of random seed. This is discussed in
more detail in Appendix G.4.
-->
</p>
<center><img src="images/fig18.png"></center>
<p>
図18 | 様々なCTMおよびLSTM構成における学習曲線（左）と、内部ティックに対する最終精度（右）。
網掛け部分とエラーバーは、シード間の1標準偏差を表します。CTMでは、思考時間の増加がパフォーマンスの向上につながります。
<!--
Figure 18 | The training curve (left) and the final accuracy vs internal ticks (right) for various CTM and LSTM configurations.
The shaded areas and error bars represent one standard deviation across seeds. For the CTM, increased thinking time leads
to an increase in performance.
-->
</p><p>

<strong>CTMはシーケンシャルアルゴリズムを学習します。</strong>　CTMがパリティタスクをどのように解決するかを分析するために、図19は、入力シーケンス内の64個の要素それぞれについて、トレーニングのさまざまな段階で、3つの異なる内部ティック構成における精度を示しています。モデルはまず、最初の要素のパリティを予測することを学習し、トレーニングが進むにつれて、より後の要素の位置を予測することを学習します。内部ティックが増えるほど、モデルはターゲットシーケンス内のより多くの要素を正確に予測できます。
<!--
<strong>The CTM learns a sequential algorithm.</strong>　To analyze how the CTM learns to solve the parity task,
Figure 19 shows the accuracy for each of the 64 elements in the input sequence at different stages of
training, for three different internal tick configurations. The models first learn to predict the parity of
the initial elements, and as training proceeds, learn to predict later and later positions. With more
internal ticks, the model can accurately predict more elements in the target sequence.
-->
</p>
<center><img src="images/fig19.png"></center>
<p>

図19 | 様々な内部ティック構成における、異なるトレーニング段階（色で表示）での64要素シーケンス全体の精度。トレーニング初期段階では、すべてのCTMはシーケンスの最初の要素についてのみパリティを正確に予測し、トレーニングが進むにつれて後の要素のパリティ予測精度は徐々に向上します。内部ティックの数が多いモデルはより高い精度を達成し、10ステップモデル（a）はシーケンスの約半分を正しく予測し、75ステップモデル（c）は累積パリティシーケンス全体を正しく予測します。
<!--
Figure 19 | Accuracy across the 64-element sequence at different training stages (indicated by color) for various internal
tick configurations. Early in training, all CTMs accurately predict parity only for initial sequence elements, gradually
improving for later elements as training progresses. Models with more internal ticks achieve higher accuracy, with the
10-step model (a) correctly predicting approximately half the sequence and the 75-step model (c) correctly predicting the
entire cumulative parity sequence.
-->
</p><p>

モデルが累積パリティタスクをどのように解くかを理解するために、2つの異なるモデルについて、トレーニングの複数の段階における全64要素におけるCTMの注意パターン、精度、および最も確信度の高いポイントを図20に視覚化しました。注意と確信度のパターンは、これらのCTMが累積パリティタスクを解くために異なるアルゴリズムを活用していることを示しています。100内部ティックを使用する場合、注意はシーケンスの先頭から末尾に移動し、それに伴い、モデルはその位置での予測の確信度を高めます。一方、75反復のCTMは、シーケンスを逆順に注意するように学習し、最後の内部ティック中にシーケンスの大部分のパリティを同時に正確に予測します。このデータの逆方向検索は、CTMが何らかの計画を実行し、シーケンスの累積パリティに関する最終決定を下す前に、観測データに対する理解を深めていることを示唆しています。これらの結果は、この課題を解決するための複数の戦略が存在し、その中には他の戦略よりも解釈しやすいものもあるものの、CTMは戦略を形成し、それに従う能力を明確に示していることを強調しています。
<!--
To gain insight into how the model solves the cumulative parity task, we visualize the CTM’s attention
patterns, accuracy, and points of highest certainty across all 64 elements at multiple stages of training
in Figure 20 for two different models. The attention and certainty patterns evidence that these CTMs
are leveraging different algorithms to solve the cumulative parity task. When using 100 internal ticks,
attention moves from the beginning to the end of the sequence, and with it, the model increases its
certainty of the prediction at that position. The CTM with 75 iterations, on the other hand, learns
to attend to the sequence in reverse order, accurately predicting the parity of the majority of the
sequence simultaneously during the final internal ticks. This reverse search through the data suggests
that the CTM is carrying out a form of planning, building up its understanding of the observed data
before making a final decision on the cumulative parity of the sequence. These results highlight that
although multiple strategies exist for solving this task, some of which are more interpretable than
others, the CTM clearly demonstrates the ability to form and follow a strategy.
-->
</p>
<center><img src="images/fig20.png"></center>
<p>

図20 | 100内部ティック(a)と75内部ティック(b)で学習したCTMの、学習中の異なる時点における注意パターン(上)と精度(下)。精度プロットの黒い点は、モデルが最大の確信度に達した内部ティックを示し、エラーバーはサンプル全体の1標準偏差を示す。
<!--
Figure 20 | Attention patterns (top) and accuracy (bottom) at different points in training, for a CTM trained with 100
internal ticks (a) and 75 internal ticks (b). The black points in the accuracy plots denote the internal tick at which the
model reached maximum certainty, with the error bars denoting one standard deviation across samples.
-->
</p>
<h3>8.2. デモンストレーション</h3>
<!--
<h3>8.2. Demonstrations</h3>
-->
<p>

図21に2つのデモンストレーションを示します。最初の例（上）は、データセットの典型的なサンプルを示しており、ランダムな位置に1と-1の値が含まれています。この場合、CTMは累積パリティを完全に予測します。アテンションヘッドのダイナミクス（a）は、図20と一致して、アテンションが入力データ内を順次移動していることを示しています。さらに、一部のヘッドは正または負の値のみに注意を払い、他のヘッドは両方の値に注意を払っていることがわかります。2番目の例（下）は、モデルの失敗例を示しています。正のパリティのみを含む入力シーケンスが提示された場合、モデルは累積パリティを正確に予測するのに苦労し、エッジケースの制限が浮き彫りになります。
<!--
We show two demonstrations in Figure 21. The first example (top) depicts a typical sample from
the dataset, which contains values of 1 and −1 at random positions. In this case, the CTM perfectly
predicts the cumulative parity. The dynamics of the attention heads (a) shows that the attention
moves sequentially through the input data, in agreement with Figure 20. Furthermore, we can see
that some heads attend to only positive or negative values, while other heads attend to both. The
second example (bottom) shows a failure case of the model. When presented with an input sequence
containing only positive parities, the model struggles to accurately predict the cumulative parity,
highlighting an edge-case limitation.
-->
</p>
<center><img src="images/fig21.png"></center>
<p>

図21 | パリティ課題の2つのサンプルソリューションにおけるアテンションダイナミクスの可視化。上段 (a, b, c) は完璧な予測を、下段は失敗したケース (d, e, f) を示しています。8つのアテンションヘッドそれぞれに対するアテンション軌跡（アテンション重みにおけるargmaxの位置）は (a, d) に示されています。各点は、特定のタイムステップにおけるアテンション重みが最も高い入力位置を示しています。色は時間経過による変化を表し、明るい色はより遅い内部ティックを示しています。十字 (×) は、モデルが予測において最大の確信度に達したタイムステップを示しています。アテンションヘッドは通常、入力位置を順番に移動します。あるヘッドは一貫して正または負の入力値のみに注意を向けますが、他のヘッドは正と負の入力値を交互に注意を向けます。同様に、あるヘッドは比較的静止したままですが、他のヘッドはデータ上を素早く移動します。(b, e) モデルの予測。(c, f) ターゲット。
<!--
Figure 21 | Visualization of attention dynamics for two sample solutions to the parity task. The top row (a, b, c) depicts
a perfect prediction, while the bottom row depicts a failure case (d, e, f). Attention trajectories (i.e., positions of the
argmax in the attention weights) for each of the eight attention heads are shown in (a, d). Each point indicates the input
position with the highest attention weight at a given timestep. Color represents progression over time, with brighter colors
indicating later internal ticks. The cross (×) marks the timestep at which the model reached maximum certainty in its
prediction. Attention heads typically move sequentially through input positions. Certain heads consistently attend only to
positive or negative input values, whereas others alternate between positive and negative input values. Similarly, some
heads remain relatively static, while others move quickly over the data. (b, e) The model’s predictions. (c, f) The target.
-->
</p>
<h2>9. Q&A MNIST</h2>
<p>
CTMの記憶、検索、算術計算能力を評価するために、Manhaeveら (2018) やSchlagとSchmidhuber (2021) を彷彿とさせる質問応答（Q&A）MNISTタスクを考案しました。このタスクでは、モデルは一連のMNIST数字（LeCunら、1998）を順次観測し、続いて、観測された数字の中からどの数字を選択し、それらに対してどのモジュラー演算を実行するかを決定する、織り交ぜられた一連のインデックスと演算子の埋め込みを適用します。これにより、CTMが、画像に描かれた数字や数字間の関係に関する事前知識なしに、手描きの数字を認識し、以前の観測を思い出し、それらに対して論理計算を実行できるかどうかを調べることができます。さらに、訓練時に観測されたよりも多くの演算を推論時に適用することで、CTMの一般化可能性をテストできます。
<!--
To assess the CTM’s capabilities for memory, retrieval, and arithmetic computation, we devise a
Question and Answering (Q&A) MNIST task, reminiscent of Manhaeve et al. (2018) or Schlag and
Schmidhuber (2021). In this task, the model sequentially observes a series of MNIST digits (LeCun
et al., 1998), followed by an interwoven series of index and operator embeddings that determine which
of the observed digits to select and which modular operation to perform over them. This allows us to
probe whether the CTM can simultaneously recognize hand-drawn digits, recall previous observations,
and perform logical computation on them without any prior knowledge of the digits depicted in the
images or the relationships between them. Furthermore, by applying more operations at inference
time than observed during training time, we can test the generalizability of the CTM.
-->
</p><p>
具体的には、モデルはまず、𝑁𝑑 MNIST の数字を𝑡𝑑 内部ティックごとに順次観測します。次に、モデルは𝑁idx インデックス埋め込み（選択する数字を示す）と𝑁op 演算子埋め込み（モジュラー加算または減算のいずれかを指定し、各中間結果は 0～9 の範囲に収まるように 10 を法として取られる）の織り交ぜたシーケンスを受け取ります。これらはそれぞれ𝑡idx と𝑡op 内部ティックごとに提示されます。最後に、モデルは𝑡ans 内部ティックのゼロテンソルを観測し、モデルに答えを生成するように指示します。0～9 の間のターゲットは、指定されたすべてのモジュラー算術演算の合成から得られます。例を図 22 に示します。
<!--
Specifically, the model first observes 𝑁𝑑 MNIST digits sequentially for 𝑡𝑑 internal ticks each. Next,
the model receives an interwoven sequence of 𝑁idx index embeddings (indicating which digit to
select) and 𝑁op operator embeddings (specifying either modular addition or subtraction, where each
intermediate result is taken modulo 10 to keep answers within the range 0–9), each presented for
𝑡idx and 𝑡op internal ticks, respectively. Finally, the model observes a zero tensor for 𝑡ans internal ticks,
signaling the model to produce its answer. The target, between 0 and 9, results from the composition
of all specified modular arithmetic operations. An example is shown in Figure 22.
-->
</p>
<center><img src="images/fig22.png"></center>
<p>
図22 | Q&A MNISTタスクの概要。モデルは、一連の数字とそれに続く一連のインデックスと演算子の埋め込みを観測します。各埋め込みは、複数の内部ティックで繰り返されます。その後、モデルは回答フラグを表示され、モジュラー演算の結果を予測する必要があります。
<!--
Figure 22 | Overview of the Q&A MNIST task. The model observes a series of digits followed by a series of index and
operator embeddings, each repeated for several internal ticks. The model is then shown an answer flag and must predict
the result of the modular operations.
-->
</p><p>
我々は、各入力を処理するために使用される内部ティックの数を変化させた2つの異なる構成でCTMとパラメータマッチングLSTMを学習させた。数字と埋め込みは1または10内部ティックで観測され、対応する応答時間も1または10内部ティックであった。数字の数と操作数は1から4の間で均一にサンプリングされた。入力あたり1および10内部ティックのCTMのメモリ長は、それぞれ3ステップと30ステップに設定された。これらの観測およびメモリ長の構成では、応答段階で数字の観測が常にメモリ長サイズのウィンドウの外側にあることを強調しておく。このように、CTMは後の時間ステップで数字を思い出すことができるように活性化を整理する必要がある。CTMは、セクション2.5で定義された損失で学習され、最後の𝑡ansステップでのみ計算される。もう一度、LSTMの安定学習のために、𝑡2を最後の反復回数として設定します。詳細な概要は付録Hに記載されています。
<!--
We trained CTMs and parameter-matched LSTMs with two different configurations, varying how
many internal ticks were used to process each input. Digits and embeddings were observed for either
1 or 10 internal ticks, with corresponding answering times of 1 or 10 internal ticks. The number of
digits and the number of operations were sampled uniformly between 1 and 4. Memory lengths for
the 1 and 10 internal ticks per input CTMs were set to 3 and 30 steps, respectively. We highlight that
with these observation and memory length configurations that the digit observations will always lie
outside of the memory length-sized window during the answering stage. In this way, the CTM must
organize its activations such that it can recall the digits at later time steps. The CTM is trained with
the loss defined in Section 2.5, computed only over the final 𝑡ans steps. Once more, we set 𝑡2 to be the
final iteration for the LSTM for stable training. A full overview can be found in Appendix H.
-->
</p>
<h3>9.1. 結果</h3>
<!--
<h3>9.1. Results</h3>
-->
<p>

<strong>同期によるメモリ。</strong> CTMとパラメータマッチングされたLSTMの3回のシード実行のトレーニング曲線を図23に示します。内部ティックが1つの場合、LSTMは当初CTMよりも優れたパフォーマンスを発揮します。内部ティックの数が増えるにつれて、LSTMのパフォーマンスは低下し、学習は著しく不安定になります。対照的に、CTMは思考時間を増やすことで着実にパフォーマンスを向上させます。具体的には、入力ごとに10個の内部ティックを持つCTMの3回のシード実行はすべて、最も困難な分布内タスク（4桁の数字を観測した後に4つの演算を実行する）で96%以上の精度を達成しました。対照的に、対応する10個の内部ティックのLSTMは、すべてのシード実行で21%以下の精度を達成しました。単一ティックLSTMの優れたパフォーマンスは、LSTMの複雑なゲート更新の有効性を浮き彫りにしています。しかし、このメカニズムは、内部ティックを効果的に利用して同期表現を構築するCTMとは異なり、複数の内部ステップに効果的に拡張できません。
<!--
<strong>Memory via synchronization.</strong>　Training curves for three seeded runs for CTMs and parametermatched
LSTMs are shown in Figure 23. With a single internal tick, the LSTM initially outperforms
the CTM. As the number of internal ticks increases, the LSTM’s performance degrades and learning
becomes considerably more unstable. In contrast, the CTM consistently improves its performance
with additional thinking time. Specifically, all three seeded runs for the CTM with 10 internal ticks
per input achieved over 96% accuracy on the most challenging in-distribution task (performing
four operations after observing four digits). In contrast, the corresponding 10-internal tick LSTM
performed at or below 21% accuracy across all seeded runs. The strong performance of the single-tick
LSTMs highlights the effectiveness of the LSTM’s complex gated update, however, this mechanism
does not scale effectively to multiple internal steps, unlike the CTM, which effectively utilizes internal
ticks to build up a synchronization representation.
-->
</p>
<center><img src="images/fig23.png"></center>
<p>

図23 | Q&A MNISTタスクにおけるCTMとLSTMの学習曲線。網掛け部分はシード間の1標準偏差を表す。内部ティックが1つの場合、LSTMはCTMよりも優れた性能を示す。しかし、CTMの性能は内部ティックの数が増えるにつれて向上するのに対し、LSTMはますます不安定になる。
<!--
Figure 23 | Training curves for the CTM and LSTM on the Q&A MNIST task. The shaded areas represent one standard
deviation across seeds. With a single internal tick, the LSTM outperforms the CTM. However, the performance of the CTM
increases with the number of internal ticks, while the LSTM becomes increasingly unstable.
-->
</p><p>
CTMは、観測された数字が記憶ウィンドウの外にある場合でも良好なパフォーマンスを示しました。これは、ニューロンの組織化と同期のみによって、観測した内容をある程度記憶することを学習したことを示しています。CTMの優れたパフォーマンスは、ニューロンの活動の同期を通じてタイミング情報を処理することが、記憶と想起のための強力なメカニズムである可能性を示唆しています。
<!--
The CTM performs well even when the observed digits are outside of the memory window, indicating
that it has learned to memorize what it has observed to some degree, purely via the organization and
synchronization of neurons. The strong performance of the CTM indicates that processing timing
information through the synchronization of neuron activations may be a powerful mechanism for
memorization and recall.
-->

</p><p>
<strong>CTMは一​​般化できます。</strong>　訓練中に使用されたよりも多くの桁数またはインデックス演算子の埋め込みが与えられた場合のモデルの精度を測定することで、一般化を調べます。図24は、表示される桁数と実行する演算の関数としてのCTMとLSTMの精度を示しており、訓練レジームは赤で強調表示されています。CTMとLSTMのベースラインはどちらも、演算数の増加に対して一般化できることがわかります。モデルが分布外に一般化できる仕組みを理解するために、図25にCTMの思考プロセスの例を示します。図25は、入力のサンプルシーケンスと出力ロジットのスナップショットを示しています。CTMは、最終解フラグを待って最終解を一度に決定するのではなく、埋め込みが観測されるにつれてモジュラー計算を順次実行していることがわかります。同様の動作は、1内部ティックのLSTMベースラインでも見られます。 CTMがLSTMにはできないことができると主張しているのではなく、CTMがこのタスクを解決するためのツールとして同期を使用することを学習でき、その結果が効果的であり、より長いタスク要件にも拡張可能であると主張しているのです。
<!--
<strong>The CTM can generalize.</strong>　We examine generalization by measuring the accuracy of the models
when given more digits or index-operator embeddings than used during training. Figure 24 shows
the accuracy of the CTM and LSTM as a function of the number of digits shown and operations to
perform, with the training regime highlighted in red. We find that both the CTM and LSTM baselines
can generalize to an increased number of operations. To understand how the model is capable of
generalizing out of distribution, we illustrate an example thought process of the CTM in Figure 25,
which shows a sample sequence of inputs and a snapshot of the output logits. We find that the CTM
sequentially computes the modular computation as the embeddings are observed, instead of waiting
for the final answer flag to determine the final solution at once. A similar behavior can be seen in the
1-internal tick LSTM baseline. We are not claiming that the CTM can do something that the LSTM
cannot, but instead that it can learn to use synchronization as a tool to solve this task, and that the
result is both effective and scales to longer task requirements.
-->
</p>
<center><img src="images/fig24.png"></center>
<p>
図24 | 内部ティックが1および10のCTMモデルとLSTMモデルのQ&A MNISTタスクにおける一般化可能性。X軸はモデルに入力されたMNIST桁数、Y軸はモデルが実行する必要がある演算回数を示し、色はテスト精度に対応しています。
<!--
Figure 24 | Generalizability on the Q&A MNIST task for CTM and LSTM models with 1 and 10 internal ticks. The x-axis
denotes the number of MNIST digits input to the model, the y-axis denotes the number of operations the model must
perform, and the color corresponds to the test accuracy.
-->
</p>
<center><img src="images/fig25.png"></center>
<p>

図25 | Q&A MNISTタスクにおけるCTMの思考プロセスの例。モデルへの入力（MNISTの数字、インデックス、演算子の埋め込み）と、異なるスナップショットにおける出力ロジット𝑙のargmaxが示されている。各入力は10内部ティック繰り返される。この場合、モデルは((((((1 − 9)%10) − 1)%10 + 8)%10 − 8)%10)を計算する。モデルは埋め込みが観測されるにつれてこの構成の各部分を順番に計算し、出力は2、1、9、そして最後に同期表現から投影された正解1となることがわかる。
<!--
Figure 25 | Example CTM thought process from the Q&A MNIST task. Shown are the inputs to the model (MNIST digit,
index and operator embeddings) as well as the argmax of the output logits 𝑙, at different snapshots. Each input is repeated
for 10 internal ticks. In this case, the model is to compute ( ( ( ( ( (1 − 9)%10) − 1)%10 + 8)%10 − 8)%10). We find that the
model computes each part of this composition sequentially as the embeddings are observed, with outputs of 2, 1, 9, and
finally, the correct answer of 1, projected from the synchronization representation.
-->
</p>
<h2>10. 強化学習</h2>
<!--
<h2>10. Reinforcement learning</h2>
-->
<p>
我々は以前、CTMが分離した内部再帰を用いて、非シーケンシャルなタスクをシーケンシャルに処理できることを示した。本稿では、CTMを外部環境との相互作用を伴うシーケンシャルな意思決定タスクに拡張する。具体的には、強化学習（RL）を用いてCTMを訓練する。RLでは、モデルは環境の観察と試行錯誤に基づく行動選択ポリシーを学習する。この設定では、CTMは環境を次の状態に遷移させる行動を生成する前に、1つ以上の内部ティックを処理する。これを実現するために、我々はこれらの内部ティック全体にわたるニューロンダイナミクスを、連続する環境ステップにわたって継続的に維持し、以前の環境観察がNLMを介して現在の内部状態に影響を与えることを可能にする。本節の中心的な目標は、CTMが連続環境で学習するように設定可能であるという証拠を示すことである。
<!--
We have previously shown that the CTM can process sequentially on non-sequential tasks via its
decoupled internal recurrence. Here, we extend the CTM to sequential decision-making tasks involving
interactions with external environments. Specifically, we train CTMs using reinforcement learning
(RL), where the model learns action-selection policies based on environmental observations and trialand-
error interactions. In this setting, the CTM processes one or more internal ticks before producing
an action that transitions the environment to the next state. To achieve this, we continuously maintain
the neuron dynamics across these internal ticks over successive environment steps, allowing previous
environmental observations to influence current internal states via the NLMs. A central goal of this
section is to provide evidence that the CTM can be set up to learn in a continuous environment.
-->
</p><p>

<strong>環境</strong>：我々は、Gymnasium (Barto et al., 1983; Chevalier-Boisvert et al., 2023; Sutton, 1995; Towers et al., 2024) に実装された2つの古典的な制御タスクと1つのナビゲーションタスク、すなわちCart-Pole、Acrobot、およびMiniGrid Four RoomsでCTMをテストします。これらのタスクの例を図26に示します。CTMは環境遷移にわたって活性化履歴を維持するため、状態のある再帰型ニューラルネットワークとして機能します。したがって、我々は特に、RNNが効果的な部分観測設定でCTMを評価します (Hausknecht and Stone, 2015)。部分観測性は、制御タスクでは位置と角速度の観測成分をマスクし、ナビゲーションタスクでは視野を制限することで導入されます。このマスキングにより、これらのタスクは部分観測マルコフ決定過程（POMDP）に変換され、CTMは過去の観測を想起する方策を開発する必要があります。例えば、Acrobotタスクでは、正しい行動を選択するには、過去の位置を想起し、腕の挙上速度を推測する必要があります。
<!--
<strong>Environments.</strong>　We test the CTM on two classic control tasks and one navigation task, namely, Cart-
Pole, Acrobot and MiniGrid Four Rooms, implemented in Gymnasium (Barto et al., 1983; Chevalier-
Boisvert et al., 2023; Sutton, 1995; Towers et al., 2024). Examples of these tasks are shown in
Figure 26. Because the CTM maintains an activation history across environment transitions, it functions
as a stateful recurrent neural network. Therefore, we specifically evaluate the CTM in partially
observable settings, where RNNs are effective (Hausknecht and Stone, 2015). Partial observability is
introduced by masking the positional and angular velocity observation components in the control
tasks and restricting the field of view in the navigation task. This masking converts these tasks into
partially observable Markov decision processes (POMDPs), requiring the CTMs to develop policies
that recall past observations. For instance, in the Acrobot task, selecting the correct action depends
on recalling past positions and inferring the velocity to increase arm elevation.
-->
</p>
<center><img src="images/fig26.png"></center>
<p>
図26 | 強化学習環境。CartPole (a) では、エージェントは2つの離散アクション（左または右）を使用してカート上のポールのバランスを取ります。観測値には、カートの位置とポールの角度という2つの非マスク入力が含まれます。Acrobot (b) では、エージェントは4つの非マスク入力（関節角度の正弦と余弦）を使用して、2関節アームに3つのトルク（+1、-1、または0）のいずれかを適用し、アームの先端を目標高さより上に上げます。MiniGrid Four Rooms (c) では、エージェントは7つの離散アクション（左折、右折など）を使用して移動し、7×7の限られた視野内で、オブジェクト、色、状態IDをエンコードした3×7×7の入力テンソルを観測します。
<!--
Figure 26 | Reinforcement learning environments. In CartPole (a), the agent balances a pole on a cart using two discrete
actions (left or right). Observations include two non-masked inputs: cart position and pole angle. In Acrobot (b), the agent
applies one of three torques (+1, −1, or 0) to a two-joint arm to raise its end above a target height, using four non-masked
inputs (sines and cosines of joint angles). In MiniGrid Four Rooms (c), the agent navigates using seven discrete actions
(e.g., turn left, turn right, etc.) and observes a 3 × 7 × 7 input tensor encoding object, color, and state IDs within a 7 × 7
limited field of view.
-->
</p><p>

<strong>アーキテクチャ</strong> RLタスクでは、以下のアーキテクチャが使用され、Proximal Policy Optimization (Schulman et al., 2017) を用いて学習されます。まず、入力観測値は一連の全結合層を用いて処理されます。ナビゲーションタスクでは、観測状態の埋め込みと、エージェントの視野内の位置に対応する位置埋め込みの追加も含まれます。この表現は、アテンションメカニズムを使用せずに、CTMによって一定時間内部ティック処理され、その後、同期ベクトルが出力され、アクターヘッドとクリティックヘッドによって処理されます。このアプローチを、パラメータマッチングLSTMベースラインと比較します。パラメータマッチングLSTMベースラインでは、内部ティックはLSTMセルによって処理され、LSTMセルは隠れ状態をアクターネットワークとクリティックネットワークに出力します。この比較の目的は、あるアーキテクチャの優位性を示すことではなく、CTMが連続的な活性化履歴の同期を活用して、LSTMと同等の性能を達成できることを示すことです。アーキテクチャと最適化ハイパーパラメータの詳細な説明は付録Iに記載されています。
<!--
<strong>Architecture.</strong> For the RL tasks, the following architecture is used and trained with Proximal Policy
Optimization (Schulman et al., 2017). First, the input observations are processed using a series of
fully connected layers. For the navigation task, this also includes embedding the observed states
and adding positional embeddings, corresponding to locations within the agent’s field of view. This
representation is then processed by the CTM, without the use of an attention mechanism, for a
number of internal ticks, before the synchronization vector is output and processed by the actor and
critic heads. We compare this approach with parameter-matched LSTMs baselines, where the internal
ticks are instead processed by an LSTM cell, which outputs its hidden state to the actor and critic
networks. The purpose of such comparison is not too showcase a superiority of one architecture
over another, but to show that a CTM can leverage the synchronization of a continuous history of
activations, and achieve a comparable performance to LSTMs. A full description of the architecture
and optimization hyperparameters can be found in Appendix I.
-->
</p>
<h3>10.1. 結果</h3>
<!--
<h3>10.1. Results</h3>
-->
<p>
CTMは継続的に世界と相互作用することができます。強化学習タスクの学習曲線を図27に示します。すべてのタスクにおいて、CTMはLSTMベースラインと同様のパフォーマンスを達成していることがわかります。
<!--
The CTM can continuously interact with the world. Training curves for the reinforcement learning
tasks are shown in Figure 27. In all tasks, we find that the CTM achieves a similar performance to the
LSTM baselines.
-->
</p>
<center><img src="images/fig27.png"></center>
<p>
図27 | 強化学習タスクのトレーニング曲線。各曲線は、トレーニング中のエピソード長の移動平均を表し、3回のトレーニング実行の平均値です。網掛け部分はシード間の1標準偏差を表します。Cartpoleの場合、値が高いほど優れています。AcrobotとMiniGrid 4-roomsの場合、値が低いほど優れています。
<!--
Figure 27 | Training curves for reinforcement learning tasks. Each curve depicts a moving average of the episode length
during training, averaged over three training runs. The shaded region represents one standard deviation across seeds. For
Cartpole, higher is better. For Acrobot and MiniGrid 4-rooms, lower is better.
-->
</p><p>
図28は、CartPole、Acrobot、MiniGrid Four Roomsの各タスクにおけるCTMとLSTMベースラインのニューロントレースを比較したものです。従来の制御タスクでは、CTMとLSTMの両方の活性化は、カートとアームの前後運動に対応する振動的な挙動を示しています。ナビゲーションタスクでは、CTMに豊富で複雑な活性化パターンが現れます。一方、LSTMは活性化の多様性が低い傾向にあります。このセクションで学習したLSTMは、CIFAR-10で学習した場合（図12）よりも動的なニューロン活動を示します。これは、RLタスクのシーケンシャルな性質によるものと考えられます。RLタスクでは、モデルへの入力が環境との相互作用によって時間の経過とともに変化し、フィードバックループを引き起こし、モデルの潜在表現も時間の経過とともに進化します。
<!--
Figure 28 compares the neuron traces of the CTM and the LSTM baselines for the CartPole, Acrobot
and MiniGrid Four Rooms tasks. In the classic control tasks, the activations for both the CTM and the
LSTM feature oscillatory behavior, corresponding to the back-and-forth movements of the cart and
arm. For the navigation task, a rich and complex activation pattern emerges in the CTM. The LSTM
on the other hand, features a less diverse set of activations. The LSTMs trained in this section have a
more dynamic neural activity than what can be seen when trained on CIFAR-10 (Figure 12). This
is likely due to the sequential nature of RL tasks, where the input to the model changes over time
owing to its interaction with the environment, inducing a feedback loop that results in the model’s
latent representation also evolving over time.
-->
</p>
<center><img src="images/fig28.png"></center>
<p>
図28 | CartPole、Acrobot、MiniGridの「Four Rooms」タスクにおけるCTMとLSTMの単一エピソードにおける神経活動。CTMはLSTMよりも豊富なニューロンダイナミクスを備えています。
<!--
Figure 28 | Neural activities over the course of a single episode for the CTM and LSTM on CartPole, Acrobot and MiniGrid
Four Rooms tasks. The CTM features richer neuron dynamics than the LSTM.
-->
</p>
<h2>11. 関連研究</h2>
<!--
<h2>11. Related work</h2>
-->
<p>
現代のニューラルネットワークは、様々な分野で目覚ましい成功を収めていますが、一般的には固定深度のフィードフォワード計算に依存しており、入力の複雑さに応じて処理を適応させる柔軟性は限られています。一方、生物の脳は、時間の経過とともに展開する動的な神経活動を示し、タスクの要求に合わせて計算を調整します。CTMは、この考え方に基づき、内部の神経タイミングと同期を明示的にモデル化します。本セクションでは、適応型計算、反復推論、そして生物学に着想を得たアーキテクチャに関連する主要な研究を取り上げます。これらはすべて、CTMの背後にある動機付けとなっています。
<!--
Modern neural networks have achieved remarkable success across a range of domains, yet they typically
rely on fixed-depth, feedforward computation, with limited flexibility to adapt their processing based
on input complexity. In contrast, biological brains exhibit dynamic neural activity that unfolds over
time, adjusting computation to the demands of a task. The CTM builds on this idea by explicitly
modeling internal neural timing and synchronization. In this section, we highlight key works related
to adaptive computation, iterative reasoning, and biologically inspired architectures, all of which inform
the motivation behind the CTM.
-->
</p>
<h3>11.1. 適応計算と動的停止</h3>
<!--
<h3>11.1. Adaptive computation and dynamic halting</h3>
-->
<p>
入力の難易度や信頼度に応じて推論ステップ数が変化する適応型計算は、これまで多くのアプローチで研究されてきました。早期終了ネットワーク（例：Bolukbasi et al. (2017)）では、中間層が確信度の高い予測を生成した場合、モデルは推論を早期に終了できるため、簡単な例の計算時間を節約できます。PonderNet（Banino et al., 2021）は、再帰型モデルに確率的停止メカニズムを導入し、精度と効率性のバランスをとるエンドツーエンドの微分可能損失を通じて、入力ごとに学習された「熟考時間」を可能にしました。この手法は、アルゴリズム推論タスクにおいて、より安定したトレーニングとより強力な一般化を提供することで、適応型計算時間（ACT）（Graves, 2016）を改良しました。
<!--
A number of approaches have explored adaptive computation, where the number of inference steps
varies based on input difficulty or confidence. Early-exit networks (e.g., Bolukbasi et al. (2017)) allow
models to terminate inference early if intermediate layers produce confident predictions, thereby
saving computation on easy examples. PonderNet (Banino et al., 2021) introduced a stochastic
halting mechanism for recurrent models, enabling learned per-input “ponder times” through an
end-to-end differentiable loss that balances accuracy and efficiency. This method improved upon
Adaptive Computation Time (ACT) (Graves, 2016) by offering more stable training and stronger
generalization on algorithmic reasoning tasks.
-->
</p><p>
最近では、AdaTape (Xue et al., 2023) が、入力を「テープトークン」で動的に拡張する柔軟なメモリ拡張アーキテクチャを提案しました。これにより、モデルは必要に応じてより多くの計算リソースを効率的に確保できます。同様に、Sparse Universal Transformer (SUT) (Tan et al., 2023) は、再帰的な重み共有と動的停止、およびMixture-of-Expertsルーティングを組み合わせることで、モデルが入力ごとに異なる数の再帰型Transformer層を適用できるようにしています。これらの手法は、入力依存計算の利点を示し、計算コストと問題の難易度を一致させます。これは、CTMが内部の「思考」次元を通じて追求している目標でもあります。
<!--
More recently, AdaTape (Xue et al., 2023) proposed a flexible memory-augmented architecture that
dynamically extends the input with additional “tape tokens,” effectively granting the model more
computation budget as needed. Similarly, the Sparse Universal Transformer (SUT) (Tan et al., 2023)
combines recurrent weight sharing with dynamic halting and Mixture-of-Experts routing, enabling the
model to apply varying numbers of recurrent transformer layers per input. These methods demonstrate
the benefits of input-dependent computation, aligning compute cost with problem difficulty—a goal
also pursued by the CTM via its internal “thought” dimension.
-->
</p>
<h3>11.2. 反復推論と再帰推論</h3>
<!--
<h3>11.2. Iterative and recurrent reasoning</h3>
-->
<p>
CTMは、反復推論と内部再帰向けに設計されたモデルと共通点を持っています。例えば、Quiet-STaR (Zelikman et al., 2024) は、学習中に隠れた根拠トークンを挿入することで言語モデルに「話す前に考える」ことを教え、出力生成前の内部計算を促します。このプロセスは、数学的推論や常識的な質疑応答といった複雑なタスクのパフォーマンスを向上させます。Recurrent Independent Mechanisms (RIMs) (Goyal et al., 2019) などの他のアーキテクチャは、計算をスパースに活性化されたモジュール型サブネットワークに分割し、時間の経過とともに非同期的に進化させることで、体系的な一般化と多段階推論を向上させます。これらのアプローチは、入力シーケンスに直接結び付けられていない内部の分離された計算を通じて思考をシミュレートするというCTMの目的を反映しています。
<!--
The CTM shares common ground with models designed for iterative reasoning and internal recurrence.
Quiet-STaR (Zelikman et al., 2024), for example, teaches language models to “think before speaking”
by inserting hidden rationale tokens during training, encouraging internal computation before
output generation. This process enhances performance on complex tasks like math reasoning and
commonsense QA. Other architectures like Recurrent Independent Mechanisms (RIMs) (Goyal et al.,
2019) split computation across sparsely activated,modular sub-networks, which evolve asynchronously
over time, improving systematic generalization and multi-step reasoning. These approaches echo the
CTM’s aim of simulating thought through internal, decoupled computation that is not directly tied to
the input sequence.
-->
</p>
<h3>11.3. 生物学的にインスパイアされた神経ダイナミクス</h3>
<!--
<h3>11.3. Biologically inspired neural dynamics</h3>
-->
<p>
ニューラルコンピューティングをより生物学的に妥当なものにすることを目指す研究が増えています (Schmidgall et al., 2024)。Liquid Time-Constant Networks (LTCN) (Hasani et al., 2021) は、時間変動微分方程式に支配されるニューロンを用い、各ニューロンが入力履歴に基づいて動的に応答を適応させることを可能にします。これらのネットワークは、高いサンプル効率と堅牢性を備え、時間依存タスクにおいて優れた性能を示しています。同様に、スパイキングニューラルネットワーク (SNN) は、標準的なディープネットワークに代わる生物学的根拠に基づいた代替手段として注目を集めており、離散スパイクと正確なタイミングに基づいて情報を符号化および処理します。最近の進歩 (例: Stan and Rhodes (2024)) では、SNN を状態空間モデルおよび同期メカニズムと組み合わせることで、長距離シーケンスタスクにおいて競争力のある、あるいはそれ以上の性能を実現しています。
<!--
A growing body of work aims to make neural computation more biologically plausible (Schmidgall
et al., 2024). Liquid Time-Constant Networks (LTCNs) (Hasani et al., 2021) use neurons governed by
time-varying differential equations, enabling each neuron to adapt its response dynamically based
on input history. These networks have shown strong performance on temporal tasks with high
sample efficiency and robustness. Similarly, Spiking Neural Networks (SNNs) have gained traction
as biologically grounded alternatives to standard deep networks, relying on discrete spikes and
precise timing to encode and process information. Recent advances (e.g., Stan and Rhodes (2024))
combine SNNs with state-space models and synchronization mechanisms, achieving competitive or
even superior performance on long-range sequence tasks.
-->
</p><p>
CTMは、そのような神経メカニズム、特に時間的符号化と神経同期から着想を得て、静的な活性化ではなく活動のタイミングに情報を符号化します。しかし、従来のモデルとは異なり、CTMはこれらのダイナミクスを注意と出力生成の潜在的表現として直接利用し、進化するニューロン状態の相互作用から推論が自然に生じる統一されたアーキテクチャを実現します。
<!--
The CTM draws inspiration from such neural mechanisms – particularly temporal coding and neural

synchrony – to encode information in the timing of activity rather than static activations. Unlike prior
models, however, the CTM uses these dynamics directly as a latent representation for attention and
output generation, leading to a unified architecture where reasoning emerges naturally from the
interplay of evolving neuron states.
-->
</p>
<h2>12. 考察と今後の課題</h2>
<!--
<h2>12. Discussion and future work</h2>
-->
<p>
本技術レポートでは、神経活動の時間的ダイナミクスをその知能の主要メカニズムとして展開し活用するモデルとしてCTMを紹介しました。私たちの知る限り、時間の経過に伴う神経同期をモデルの潜在的表現として用いることは、特にこの規模ではこれまで実現されていません。CTMは、自然認知において極めて重要であると考えられている時間的ダイナミクスの正確な相互作用とタイミングを用いて、多様なタスクを成功裏に実行するモデルの具体例であり、その証拠を本稿で示しました。
<!--
In this technical report we presented the CTM as a model that unfolds and leverages the temporal
dynamics of neural activity as the primary mechanism for its intelligence. To our best knowledge,
using neural synchronization over time as the latent representation for a model has never been
accomplished, particularly at this scale. The CTM is an instantiation of a model that uses the precise
interplay and timing of temporal dynamics – which is believed to be crucial in natural cognition – to
successfully perform a diverse range of tasks, for which we gave evidence herein.
-->
</p><p>
本研究の目的は、この新しいモデルと、ニューラルダイナミクスがニューラルコンピューティングの強力なツールとなり得るという視点を紹介することでした。研究コミュニティが本研究の一部を取り入れ、より生物学的に妥当で高性能なAIを構築してくれることを願っています。以下のサブセクションでは、私たちの観察に基づいた議論と展望をいくつか示します。
<!--
Our goal for this work was to introduce this new model, and the perspective that neural dynamics can
be a powerful tool for neural computation. We hope that the research community can adopt aspects
of our work to build more biologically plausible and performant AI. In the following subsections we
offer some discussion and perspectives based on our observations.
-->

</p>
<h3>12.1. 直感的な視点と生物学的妥当性</h3>
<!--
<h3>12.1. Intuitive perspective, biological plausibility</h3>
-->
<p>
CTMの出力y𝑡は、同期からの線形射影として計算されます。例えば、y𝑡がクラス予測を表すオブジェクト分類を考えてみましょう。このシナリオでは、CTMは入力データ内の抽象的な特徴を観察し、ニューロン内に特定の活性化ダイナミクスを生成する必要があります。そして、これらの活性化ダイナミクスは、正確な予測を生成するために正確に同期する必要があります。直感的に言えば、これはCTMが入力データに応答して内部の刻み目を通して持続的な神経活動パターンを発達させることを学習し、時間的なプロセスを通じて効果的に出力を構築することを意味します。この概念は、最近の推論の概念と一致しており、私たちが「思考」という用語を選択した主な理由です。さらに、このような動的かつ時間的な表現は、標準的な表現を使用する既存の方法とは大きく対照的です。本論文の実験は、この種の表現の可能性を探る初期の段階ですが、生物学的プロセスとの類似性の高さから、最終的には大きな有用性を持つ可能性があることが示唆されています。
<!--
The CTM’s outputs, y𝑡 , are computed as linear projections from synchronization. Consider, for example,
object classification, where y𝑡 represents class predictions. In this scenario, the CTM must observe
abstract features in the input data to produce specific activation dynamics within its neurons. These
activation dynamics, in turn, must synchronize in a precise manner to generate accurate predictions.
Intuitively, this implies that the CTM learns to develop persistent patterns of neural activity over
internal ticks in response to the input data, effectively building up its output through a temporal
process. This concept aligns with recent notions of reasoning and is a key motivation behind our
choice of the term ‘thought.’ Furthermore, such a dynamic and temporal representation contrasts
sharply with existing methods that use standard representations. While the experiments in this paper
represent an initial exploration of the potential of this type of representation, its closer resemblance
to biological processes suggests that its eventual utility could be substantial.
-->
</p>
<h3>12.2. 時間の経過に伴う同期の強み</h3>
<!--
<h3>12.2. The strengths of synchronization over time</h3>
-->
<p>
<strong>多重解像度</strong>：同期の測定は、時間経過に伴う活動に依存しますが、時間そのものに厳密に依存するわけではありません。これにより、同期の一部が時間の経過とともにゆっくりと変化する可能性があり、一方で、学習可能な時間依存性の減衰メカニズム（セクション2.4を参照）は、短期的な依存性の出現を可能にします。その結果、同期は、任意の数の解像度でイベントや視点を捉えることができる表現となります。多くの現実世界のシナリオでは、このような多重解像度の視点が強力になり得る特徴やアイデアが見られるため、今後の研究でこの点について検討します。
<!--
<strong>Multi-resolution.</strong>　Our measurement of synchronization depends on activity over time, but not
exactly on time itself. This potentially frees up some portion of synchronization to change slowly
over time, while our mechanism for learnable decaying time dependency (see Section 2.4) enables
the emergence of short-term dependence. The result is that synchronization is a representation that
can capture events or perspectives at any number of resolutions. Many real-world scenarios present
themselves as situations where features or ideas where such a multi-resolution perspective could be
powerful; we will explore this in future work.
-->

</p><p>
<strong>記憶</strong>　この点についてさらに言及すると、ある同期は、CTMのある期間における認知だけでなく、内部のティックの周期的な変化によって、CTMが行動をとった結果も捉えている。このような視点は、スナップショット表現よりもはるかに「経験」に近い。したがって、記憶としての同期行列は、今後の研究にとって興味深い道筋を示す。
<!--
<strong>Memory</strong>　Further to this point is that a given synchronization captures not only the CTM’s cognition
over some time period, but also the consequence of it taking action, owing to the recurrent cycle
of internal ticks. Such a perspective is far more akin to an ‘experience’ than what a snapshot
representation could yield. Hence, synchronization matrices as memories presents an interesting
avenue for future work.
-->
</p><p>
<strong>可塑性と勾配フリー学習</strong>　本技術レポートで定義したように、同期とはニューロンがどのように同時に発火するかを測定するものであり、これは非常にヘブ的な視点です（Hebb, 2005; Najarro and Risi, 2020）。この概念を活用して生涯学習（Kudithipudi et al., 2022; Wang et al., 2024）、可塑性、さらには勾配フリー最適化を探求することは、今後の研究にとって刺激的な道筋です。
<!--
<strong>Plasticity and gradient-free learning.</strong>　As we have defined it in this technical report, synchronization
measures how neurons fire together, which is a very Hebbian-like perspective (Hebb, 2005; Najarro

and Risi, 2020). Leveraging this notion to explore lifelong learning (Kudithipudi et al., 2022; Wang
et al., 2024), plasticity, or even gradient-free optimization are exciting avenues for future work.
-->
</p><p>
<strong>カーディナリティ</strong>　𝐷次元CTMにおける完全同期は(𝐷 × (𝐷 + 1))/2次元（完全同期行列の上三角）です。研究によると、大規模な表現はいくつかの理由から有利です（Allen-Zhu et al., 2019; Frankle and Carbin, 2018）。
同期により、追加コストなしで大規模で意味のある表現空間にアクセスできます。
私たちは、特にマルチモーダルモデリングの分野において、このような高カーディナリティの表現空間からどのような有用性が得られるかを探求するつもりです。
<!--
<strong>Cardinality</strong>　The full synchronization in a 𝐷 dimensional CTM is (𝐷 × (𝐷 + 1))/2 dimensional (the
upper triangle of the full synchronization matrix). Research suggests that large representations
are advantageous for a number of reasons (Allen-Zhu et al., 2019; Frankle and Carbin, 2018).
Synchronization gives us access to a large and meaningful representation space at no additional cost.
We intend to explore what utility can be gained from such a high-cardinality representation space,
particularly in the realm of multi-modal modeling.
-->
</p>
<h3>12.3. 連続世界</h3>
<!--
<h3>12.3. Continuous worlds</h3>
-->
<p>
CTMの構築には自然界からヒントを得ましたが、学習には確立されたプロトコルとデータセットを使用しました。しかし、これらのデータセットとプロトコルは必ずしも自然なものではありません。例えば、従来のニューラルネットワークの学習では、独立かつ同一に分布するデータが期待されますが、現実世界ではそうではありません。イベントは時間の経過とともに発生し、通常はそれに応じて配置されます。したがって、将来の研究では、生物学的に妥当な方法でCTMを学習させることを目指しています。特に学習中に順番にサンプリングされたシーケンシャルデータ（例：動画、テキスト）への適用は、将来の研究にとって有望な道筋です。
<!--
We took inspiration from nature to build the CTM, but used well-established protocols and datasets
when training it. These datasets and protocols, however, are not necessarily natural. For instance,
independent and identically distributed data is expected when training conventional NNs, but that
is not how the real-world operates. Events happen over time and are usually arranged accordingly.
Hence, we wish to move toward training the CTM in a biologically plausible fashion for future work.
Application to sequential data (e.g., videos, text), particularly when sampled in order during training,
is a promising avenue for future work.
-->
</p><p>

<strong>言語モデリング</strong> CTMを言語モデリングのタスクに適用した例はまだありませんが、注意を利用するという点を踏まえると、テキストの取り込みと思考に適応させることは容易です。さらに、CTMは世界モデルを構築し、それをナビゲートできるため（セクション4を参照）、位置エンコーディングを必要とせず、観察対象の文脈化された「世界モデル」を構築できる可能性があります。読者の皆様にぜひご検討いただきたい潜在的な可能性の一つは、CTMを事前学習済みの言語モデルに適用することです。今後の研究では、テキストデータを用いてカスタムCTMを構築・学習し、その分野におけるCTMの能力を理解する予定です。
<!--
<strong>Language modeling.</strong> We have yet to apply the CTM to the task of language modeling, but it is
straightforward to adapt it to ingesting and thinking about text given that it uses attention. Moreover,
since it can build a world model and navigate it (see Section 4), the CTM could potentially do
without positional encodings, instead building a contextualized ‘world model’ of what it observes.
One potential avenue we encourage readers to explore is that of applying the CTM to pretrained
language models. For future work, we will build and train custom CTMs on text data in order to
understand its capability in that domain.
-->
</p>
<h3>12.4. 何が失敗し、どのようにしてここに至ったのか?</h3>
<!--
<h3>12.4. What failed, and how did we get here?</h3>
-->
<p>
CTMの中核表現として当初何を試みたのか（同期表現ではなく）を説明することが重要だと考えています。活性化潜在空間z𝑡は明らかな候補です。しかし、Zの動的かつ複雑な性質から、何らかの平滑化操作（例えば、「ホルダー」潜在空間やロジットの蓄積など）を実行する必要があることがわかりました。さらに、この表現は𝑡と強く結合しているため、CTMは内部の自己組織化を主要な駆動力として頼るのではなく、出力を生成するタイミング（つまり、損失関数が適用されたタイミング）を正確に学習することがわかりました。
<!--
We believe it is important to explain what we initially tried as the core representation for the CTM
(as opposed to synchronization). The activated latent space, z𝑡, is an obvious candidate. We found,
however, that the dynamic and complex nature of Z meant we needed to perform some smoothing
operations (e.g., accumulating some ‘holder’ latent or logits). Further, given that this representation
is strongly coupled to 𝑡, we found that the CTM would learn when exactly to produce an output (i.e.,
when the loss function was applied) instead of relying on the internal self-organization as the primary
driving force.
-->
</p><p>
ニューロンのタイミングをシステムに組み込むことで、この課題が生じました。幸いなことに、時間に依存しない同期は、これらの課題を克服するための優れた解決策であることが証明されました。学習可能な減衰時間依存性は、CTMが短期的なニューロン行動に基づいて世界と相互作用することを学習するという、優れた解決策も提供します。
<!--
By adding neuron timing back into the system we introduced this challenge; thankfully, synchronization,
being time-independent, proved an elegant solution to overcoming these challenges. The
learnable decaying time-dependence also offers a neat solution whereby the CTM can learn to interact
with its world based on short-term neural behavior, should this be preferred.
-->
</p>
<h2>13. 結論</h2>
<!--
<h2>13. Conclusion</h2>
-->
<p>
連続思考マシン（CTM）は、人工知能における計算効率と生物学的妥当性を橋渡しする新たな一歩です。従来の点単位の活性化関数からプライベートなニューロンレベルモデルへと移行することで、CTMははるかに豊かなニューロンダイナミクスを実現します。
重要なのは、ニューラルネットワークの初期から広く用いられてきた活性化ベクトルとは異なる、強力かつ根本的に新しいタイプの表現として、ニューラル同期を活用していることです。
ニューロンダイナミクスを第一級の表現要素として直接利用することで、CTMは現代のモデルとは質的に異なる動作を示すことができます。
<!--
The Continuous Thought Machine (CTM) represents a novel step towards bridging computational
efficiency with biological plausibility in artificial intelligence. By moving beyond traditional pointwise
activation functions to private neuron-level models, the CTM cultivates far richer neuron dynamics.
Crucially, it leverages neural synchronization as a powerful and fundamentally new type of representation
– distinct from the activation vectors prevalent since the early days of neural networks.
This direct use of neuron dynamics as a first-class representational citizen allows the CTM to exhibit
behaviors qualitatively different from contemporary models.
-->
</p><p>
私たちの研究は、このアプローチの具体的な利点を実証しています。CTMは、画像分類などのタスクにおいて、時間の経過とともに動的に表現を構築し、位置埋め込みなしに特定の入力データに注意を向けるための豊富な内部マップを形成し、自然に適応的な計算を行うことができます。さらに、CTMは神経ダイナミクスを同期させることで、直近の活動履歴を超えて記憶を保存・検索することを学習します。この内部処理は、迷路やパリティタスクを系統的に解くことに見られるように、より高い解釈可能性にも役立ちます。
<!--
Our research demonstrates the tangible benefits of this approach. The CTM can dynamically build
representations over time for tasks like image classification, form rich internal maps to attend to
specific input data without positional embeddings, and naturally exhibit adaptive computation.
Furthermore, it learns to synchronize neural dynamics to store and retrieve memories beyond its
immediate activation history. This internal processing also lends itself to greater interpretability, as
seen in its methodical solving of mazes and parity tasks.
-->
</p><p>
驚くべきことに、CTMのコアアーキテクチャは、多様な難易度のタスクにおいてほぼ一貫性を保ち、入出力モジュールの調整のみを必要としました。この汎用性と学習可能性は、迷路ナビゲーションのような複雑なシナリオにおいて特に顕著でした。CTMは最小限のチューニングで成功を収めましたが、LSTMのような従来のモデルでは、大幅なチューニングを行った後でも依然として苦戦を強いられました。
<!--
Remarkably, the core CTM architecture remained largely consistent across a diverse range of challenging
tasks, requiring only input/output module adjustments. This versatility and trainability
were particularly evident in complex scenarios like maze navigation. The CTM succeeded with
minimal tuning, where a traditional model like the LSTMs still struggled even after significant tuning
efforts.
-->
</p><p>
この研究は、神経科学と機械学習の間にある、重要でありながらしばしば十分に探究されていない相乗効果を強調するものです。現代のAIは表面的には脳に着想を得ているように見えますが、この2つの分野はしばしば驚くほど孤立して機能しています。CTMは、生物学的原理からインスピレーションを得る力の証です。
このようなインスピレーションから出発し、出現する興味深い行動を反復的に追跡することで、私たちは、分類タスクにおける驚くほど強力なキャリブレーションなど、当初は想定されていなかった機能を備えたモデルを開発しました。
<!--
This work underscores a vital, yet often underexplored, synergy between neuroscience and machine
learning. While modern AI is ostensibly brain-inspired, the two fields often operate in surprising
isolation. The CTM serves as a testament to the power of drawing inspiration from biological principles.
By starting with such inspiration and iteratively following the emergent, interesting behaviors,
we developed a model with unexpected capabilities, such as its surprisingly strong calibration in
classification tasks, a feature that was not explicitly designed for.
-->
</p><p>
我々のアプローチは、厳密で文字通りの妥当性を追求するのではなく、生物学の概念を借用することを推奨していることに留意することが重要です。現実のニューロンはCTMでモデル化されたように活動履歴にアクセスできないかもしれませんが、それでも進行波のような創発現象は現れます。実用性と生物学的インスピレーションの間のこの微妙なバランスは、新たな研究方向への展望を開き、それが現在AIに欠けている能力を解き放つ鍵となる可能性があり、より人間に近い知性を示し、現在のAIの限界に対処するシステムにつながる可能性があります。
<!--
It is crucial to note that our approach advocates for borrowing concepts from biology rather than
insisting on strict, literal plausibility; real neurons may not access their activation history as modeled
in the CTM, yet emergent phenomena like traveling waves still manifest. This nuanced balance
between practicality and biological inspiration opens a landscape of new research directions, which
may hold the key to unlocking capabilities currently missing in AI, potentially leading to systems that
exhibit more human-like intelligence and address its current limitations.
-->
</p><p>
当初「なぜこの研究をするのか？」と自問したとき、CTMの旅が説得力のある答えを提供してくれることを期待していました。軽い生物学的インスピレーションを受け入れ、観察された新しい行動を追求することで、当初の設計を超える創発能力を備えたモデルに到達しました。私たちはこの探求を継続し、さらなる概念を借りて、どのような新しくエキサイティングな行動が生まれるかを発見し、AIの限界を押し広げていくことに尽力しています。
<!--
When we initially asked, “why do this research?”, we hoped the journey of the CTM would provide
compelling answers. By embracing light biological inspiration and pursuing the novel behaviors
observed, we have arrived at a model with emergent capabilities that exceeded our initial designs.
We are committed to continuing this exploration, borrowing further concepts to discover what new
and exciting behaviors will emerge, pushing the boundaries of what AI can achieve.
-->
</p><p>
<string>制限事項</strong><br>
CTMの主な制限事項は、並列化できない逐次処理を必要とすることです。つまり、特に現代のAIモデルの現状は、並列開発されたハードウェアとソフトウェアに適していることを考慮すると、標準的なフィードフォワードモデルよりもトレーニング時間が長くなります（Hooker, 2021）。
<!--
<string>Limitations</strong><br>
The main limitation of the CTM is that it requires sequential processing that cannot be parallelized,
meaning that training times are longer than a standard feed-forward model, particularly when
considering that the current state of modern AI models are well suited to the hardware and software
that has developed in parallel (Hooker, 2021).
-->
</p><p>
ニューロンレベルモデルに関連する追加のパラメータコストも制約となる可能性があります。
メリットがコストを上回るかどうかはまだ証明されていませんが、その有用性は高いと考えています。
<!--
The additional parameter cost associated with neuron-level models can also be considered a limitation.
Whether the benefits outweigh the costs remains to be proven, but we believe their utility can be
high.
-->
</p>
<h2>参考文献</h2>
<!--
<h2>References</h2>
-->
<p>
<div class="styleRef">
<ul><li>
Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via overparameterization.
In International conference on machine learning, pages 242–252. PMLR, 2019.
</li><br><li>Cristina M Atance and Daniela K O’Neill. Episodic future thinking. Trends in cognitive sciences, 5(12):
533–539, 2001.
</li><br><li>Andrea Banino, Jan Balaguer, and Charles Blundell. Pondernet: Learning to ponder. arXiv preprint
arXiv:2107.05407, 2021.
</li><br><li>Arpit Bansal, Avi Schwarzschild, Eitan Borgnia, Zeyad Emam, Furong Huang, Micah Goldblum, and
Tom Goldstein. End-to-end algorithm synthesis with recurrent networks: Extrapolation without
overthinking. Advances in Neural Information Processing Systems, 35:20232–20242, 2022.
</li><br><li>Andrew G. Barto, Richard S. Sutton, and Charles W. Anderson. Neuronlike adaptive elements that
can solve difficult learning control problems. IEEE Transactions on Systems, Man, and Cybernetics,
SMC-13(5):834–846, 1983. doi: 10.1109/TSMC.1983.6313077.
</li><br><li>Tolga Bolukbasi, Joseph Wang, Ofer Dekel, and Venkatesh Saligrama. Adaptive neural networks for
efficient inference. In International Conference on Machine Learning, pages 527–536. PMLR, 2017.
</li><br><li>Natalia Caporale and Yang Dan. Spike timing–dependent plasticity: a hebbian learning rule. Annu.
Rev. Neurosci., 31(1):25–46, 2008.
</li><br><li>Peter Cariani and Janet M Baker. Time is of the essence: neural codes, synchronies, oscillations,
architectures. Frontiers in Computational Neuroscience, 16:898829, 2022.
</li><br><li>Makram Chahine, Ramin Hasani, Patrick Kao, Aaron Ray, Ryan Shubert, Mathias Lechner, Alexander
Amini, and Daniela Rus. Robust flight navigation out of distribution with liquid neural networks.
Science Robotics, 8(77):eadc8892, 2023.
</li><br><li>Maxime Chevalier-Boisvert, Bolun Dai, Mark Towers, Rodrigo de Lazcano, Lucas Willems, Salem
Lahlou, Suman Pal, Pablo Samuel Castro, and Jordan Terry. Minigrid & miniworld: Modular &
customizable reinforcement learning environments for goal-oriented tasks. CoRR, abs/2306.13831,
2023.
</li><br><li>François Chollet. On the measure of intelligence. arXiv preprint arXiv:1911.01547, 2019.
</li><br><li>Francois Chollet, Mike Knoop, Gregory Kamradt, and Bryan Landers. Arc prize 2024: Technical
report. arXiv preprint arXiv:2412.04604, 2024.
</li><br><li>Yann N Dauphin, Angela Fan, Michael Auli, and David Grangier. Language modeling with gated
convolutional networks. In International conference on machine learning, pages 933–941. PMLR,
2017.
</li><br><li>Rahul Dey and Fathi M Salem. Gate-variants of gated recurrent unit (gru) neural networks. In 2017
IEEE 60th international midwest symposium on circuits and systems (MWSCAS), pages 1597–1600.
IEEE, 2017.
</li><br><li>Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural
networks. arXiv preprint arXiv:1803.03635, 2018.
</li><br><li>Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian R Bartoldson,
Bhavya Kailkhura, Abhinav Bhatele, and Tom Goldstein. Scaling up test-time compute with latent
reasoning: A recurrent depth approach. arXiv preprint arXiv:2502.05171, 2025.
</li><br><li>Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning. MIT press
Cambridge, 2016.
</li><br><li>James Gornet and Matt Thomson. Automated construction of cognitive maps with visual predictive
coding. Nature Machine Intelligence, 6(7):820–833, 2024.
</li><br><li>Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani, Sergey Levine, Yoshua Bengio, and
Bernhard Schölkopf. Recurrent independent mechanisms. arXiv preprint arXiv:1909.10893, 2019.
</li><br><li>Alex Graves. Adaptive computation time for recurrent neural networks. arXiv preprint
arXiv:1603.08983, 2016.
Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber. Connectionist temporal
classification: labelling unsegmented sequence data with recurrent neural networks. In Proceedings
</li><br><li>of the 23rd international conference on Machine learning, pages 369–376, 2006.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks.
In International conference on machine learning, pages 1321–1330. PMLR, 2017.
</li><br><li>David Ha and Jürgen Schmidhuber. World models. arXiv preprint arXiv:1803.10122, 2018.
</li><br><li>Ramin Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, and Radu Grosu. Liquid timeconstant
networks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages
7657–7666, 2021.
</li><br><li>Matthew J Hausknecht and Peter Stone. Deep recurrent q-learning for partially observable mdps. In
AAAI fall symposia, volume 45, page 141, 2015.
</li><br><li>Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition.
In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778,
2016.
</li><br><li>Donald Olding Hebb. The organization of behavior: A neuropsychological theory. Psychology press,
2005.
</li><br><li>Tien Ho-Phuoc. Cifar10 to compare visual recognition performance between deep neural networks
and humans. arXiv preprint arXiv:1811.07270, 2018.
</li><br><li>Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):
1735–1780, 1997.
</li><br><li>Patrick Hohenecker and Thomas Lukasiewicz. Ontology reasoning with deep neural networks. Journal
of Artificial Intelligence Research, 68:503–540, 2020.
</li><br><li>Sara Hooker. The hardware lottery. Communications of the ACM, 64(12):58–65, 2021.
</li><br><li>Michael Igorevich Ivanitskiy, Rusheb Shah, Alex F. Spies, Tilman Räuker, Dan Valentine, Can Rager,
Lucia Quirke, Chris Mathwin, Guillaume Corlouer, Cecilia Diniz Behn, and Samy Wu Fung. A
configurable library for generating and manipulating maze datasets, 2023. URL http://arxiv.
org/abs/2309.10498.
</li><br><li>Mozes Jacobs, Roberto C Budzinski, Lyle Muller, Demba Ba, and T Anderson Keller. Traveling waves
integrate spatial information into spectral representations. arXiv preprint arXiv:2502.06034, 2025.
</li><br><li>Herbert Jaeger. Echo state network. scholarpedia, 2(9):2330, 2007.
</li><br><li>Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, and Joao Carreira.
Perceiver: General perception with iterative attention. In International conference on machine
learning, pages 4651–4664. PMLR, 2021.
</li><br><li>Louis Kirsch and Jürgen Schmidhuber. Meta learning backpropagation and improving it. Advances in
Neural Information Processing Systems, 34:14122–14134, 2021.
</li><br><li>Louis Kirsch, Sebastian Flennerhag, Hado Van Hasselt, Abram Friesen, Junhyuk Oh, and Yutian Chen.
Introducing symmetries to black box meta reinforcement learning. In Proceedings of the AAAI
Conference on Artificial Intelligence, volume 36, pages 7202–7210, 2022.
</li><br><li>Dhireesha Kudithipudi, Mario Aguilar-Simon, Jonathan Babb, Maxim Bazhenov, Douglas Blackiston,
Josh Bongard, Andrew P Brna, Suraj Chakravarthi Raja, Nick Cheney, Jeff Clune, et al. Biological
underpinnings for lifelong learning machines. Nature Machine Intelligence, 4(3):196–210, 2022.
</li><br><li>Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building machines
that learn and think like people. Behavioral and brain sciences, 40:e253, 2017.
</li><br><li>Yann LeCun. A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27. Open
Review, 62(1):1–62, 2022.
</li><br><li>Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.
</li><br><li>Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436–444, 2015.
</li><br><li>Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint
arXiv:1711.05101, 2017.
</li><br><li>Wolfgang Maass. On the relevance of time in neural computation and learning. Theoretical Computer
Science, 261(1):157–178, 2001.
</li><br><li>Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt.
Deepproblog: Neural probabilistic logic programming. Advances in neural information processing
systems, 31, 2018.
</li><br><li>Gary Marcus. Deep learning: A critical appraisal. arXiv preprint arXiv:1801.00631, 2018.
</li><br><li>Leland McInnes, John Healy, and James Melville. Umap: Uniform manifold approximation and
projection for dimension reduction. arXiv preprint arXiv:1802.03426, 2018.
</li><br><li>Larry Medsker and Lakhmi C Jain. Recurrent neural networks: design and applications. CRC press,
1999.
</li><br><li>Takeru Miyato, Sindy Löwe, Andreas Geiger, and Max Welling. Artificial kuramoto oscillatory neurons.
arXiv preprint arXiv:2410.13821, 2024.
</li><br><li>Lyle Muller, Frédéric Chavane, John Reynolds, and Terrence J Sejnowski. Cortical travelling waves:
mechanisms and computational principles. Nature Reviews Neuroscience, 19(5):255–268, 2018.
</li><br><li>Elias Najarro and Sebastian Risi. Meta-learning through hebbian plasticity in random networks.
Advances in Neural Information Processing Systems, 33:20719–20731, 2020.
</li><br><li>Joachim Pedersen, Erwan Plantec, Eleni Nisioti, Milton Montero, and Sebastian Risi. Structurally
flexible neural networks: Evolving the building blocks for general agents. In Proceedings of the
Genetic and Evolutionary Computation Conference, pages 1119–1127, 2024.
</li><br><li>Joshua C Peterson, Ruairidh M Battleday, Thomas L Griffiths, and Olga Russakovsky. Human uncertainty
makes classification more robust. In Proceedings of the IEEE/CVF international conference on
computer vision, pages 9617–9626, 2019.
</li><br><li>Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang,
Mohamed Shaaban, et al. Humanity’s last exam, 2025. URL https://arxiv.org/abs/2501.1
4249.
</li><br><li>Jing Ren and Feng Xia. Brain-inspired artificial intelligence: A comprehensive review. arXiv preprint
arXiv:2408.14811, 2024.
</li><br><li>Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical
image segmentation. In Medical image computing and computer-assisted intervention–MICCAI 2015:
18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18, pages
234–241. Springer, 2015.
</li><br><li>Imanol Schlag and Jürgen Schmidhuber. Augmenting classic algorithms with neural components
for strong generalisation on ambiguous and high-dimensional data. In Advances in Programming
Languages and Neurosymbolic Systems Workshop, 2021.
</li><br><li>Samuel Schmidgall, Rojin Ziaei, Jascha Achterberg, Louis Kirsch, S Hajiseyedrazi, and Jason
Eshraghian. Brain-inspired learning in artificial neural networks: a review. APL Machine Learning,
2(2), 2024.
</li><br><li>John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy
optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.
</li><br><li>Avi Schwarzschild, Eitan Borgnia, Arjun Gupta, Furong Huang, Uzi Vishkin, Micah Goldblum, and
Tom Goldstein. Can you learn an algorithm? generalizing from easy to hard problems with recurrent
networks. Advances in Neural Information Processing Systems, 34:6695–6706, 2021.
</li><br><li>Matei-Ioan Stan and Oliver Rhodes. Learning long sequences in spiking neural networks. Scientific
Reports, 14(1):21957, 2024.
</li><br><li>Richard S Sutton. Generalization in reinforcement learning: Successful examples using sparse coarse
coding. Advances in neural information processing systems, 8, 1995.
</li><br><li>Shawn Tan, Yikang Shen, Zhenfang Chen, Aaron Courville, and Chuang Gan. Sparse universal
transformer. arXiv preprint arXiv:2310.07096, 2023.
</li><br><li>Neil C Thompson, Kristjan Greenewald, Keeheon Lee, Gabriel F Manso, et al. The computational
limits of deep learning. arXiv preprint arXiv:2007.05558, 10, 2020.
</li><br><li>Mark Towers, Ariel Kwiatkowski, Jordan Terry, John U. Balis, Gianluca De Cola, Tristan Deleu, Manuel
Goulão, Andreas Kallinteris, Markus Krimmel, Arjun KG, Rodrigo Perez-Vicente, Andrea Pierré,
Sander Schulhoff, Jun Jet Tai, Hannah Tan, and Omar G. Younis. Gymnasium: A standard interface
for reinforcement learning environments, 2024. URL https://arxiv.org/abs/2407.17032.
</li><br><li>Peter Uhlhaas, Gordon Pipa, Bruss Lima, Lucia Melloni, Sergio Neuenschwander, Danko Nikolić, and
Wolf Singer. Neural synchrony in cortical networks: history, concept and current status. Frontiers
in integrative neuroscience, 3:543, 2009.
</li><br><li>Paul E Utgoff. Machine learning of inductive bias, volume 15. Springer Science & Business Media,
2012.
</li><br><li>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing
systems, 30, 2017.
</li><br><li>Vasilis Vryniotis and Matthieu Cord. How to Train State-Of-The-Art Models Using TorchVision’s Latest
Primitives. PyTorch Blog, dec 2021. URL https://pytorch.org/blog/how-to-train-s
tate-of-the-art-models-using-torchvision-latest-primitives/. Last edited on
2021-12-22.
</li><br><li>Liyuan Wang, Xingxing Zhang, Hang Su, and Jun Zhu. A comprehensive survey of continual learning:
Theory, method and application. IEEE Transactions on Pattern Analysis and Machine Intelligence,
2024.
</li><br><li>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,
Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models.
arXiv preprint arXiv:2206.07682, 2022.
</li><br><li>Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel,
and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention.
In International conference on machine learning, pages 2048–2057. PMLR, 2015.
</li><br><li>Fuzhao Xue, Valerii Likhosherstov, Anurag Arnab, Neil Houlsby, Mostafa Dehghani, and Yang You.
Adaptive computation with elastic input sequence. In International Conference on Machine Learning,
pages 38971–38988. PMLR, 2023.
</li><br><li>Liu Yang, Kangwook Lee, Robert Nowak, and Dimitris Papailiopoulos. Looped transformers are better
at learning learning algorithms. arXiv preprint arXiv:2311.12424, 2023.
</li><br><li>Eric Zelikman, Georges Harik, Yijia Shao, Varuna Jayasiri, Nick Haber, and Noah D Goodman.
Quiet-star: Language models can teach themselves to think before speaking. arXiv preprint
arXiv:2403.09629, 2024.
</li><br><li>Tao Zhang, Jia-Shu Pan, Ruiqi Feng, and Tailin Wu. T-scend: Test-time scalable mcts-enhanced
diffusion model. arXiv preprint arXiv:2502.01989, 2025.
</li></ul></div>
</p>
<h2>A. 用語集</h2>
<!--
<h2>A. Glossary</h2>
-->
<p>
            <table border="1">
<tr><th>用語 </th><th>説明</th></tr>
<tr><td>内部ティック</td><td>内部計算の1ステップ。</td></tr>
<tr><td>メモリ長</td><td>ローリングFIFO方式で更新される、前活性化のローリング履歴の長さ。</td></tr>
<tr><td>シナプスモデル</td><td>\(\mathbf z^𝑡\)と\(\mathbf o^𝑡\)を入力として受け取り、前活性化を予測する回帰モデル。\(\mathbf a^𝑡\)。</td></tr>
<tr><td>前活性化</td><td>回帰シナプスモデルの出力。NLMへの入力。</td></tr>
<tr><td>事後活性化</td><td>NLMの出力、時刻 \(𝑡\) におけるニューロンの状態。</td></tr>
<tr><td>(事前/事後)活性化履歴</td><td>時間経過に伴う活性化の順序付けられた履歴。</td></tr>
<tr><td>ニューロンレベルモデル (NLM)</td><td>事後活性化履歴に対するニューロンごとのMLP。</td></tr>
<tr><td>同期</td><td>事後活性化履歴のドット積。</td></tr>
<tr><td>自己ペア</td><td>対角同期行列のエントリ \((𝑖,𝑖)\)。</td></tr>
<tr><td>アクション同期</td><td>アテンションクエリの同期表現。</td></tr>
<tr><td>出力同期</td><td>予測のための同期表現。</td></tr>
<tr><td>減衰 \(𝑟_{𝑖𝑗}\)</td><td>同期（アクションまたは出力）のための学習可能な時間減衰。</td></tr>
<tr><td>特徴抽出器</td><td>タスク固有の入力エンコーダ（例：ResNet）。</td></tr>
<tr><td>アテンション出力</td><td>アクション同期から計算されたクエリ、q𝑡、およびデータのキー/値を使用したクロスアテンション後の出力。</td></tr>
<!--
                <tr><th>Term </th><th>Description</th></tr>
                <tr><td>Internal tick</td><td>One step of internal computation.</td></tr>
                <tr><td>Memory length</td><td>Length of rolling history of pre-activations, updated in a
rolling FIFO fashion</td></tr>
                <tr><td>Synapse model</td><td>Recurrent model that takes \(\mathbf z^𝑡\) and \(\mathbf o^𝑡\) as input to preduct preactivations,
\(\mathbf a^𝑡\) .</td></tr>
                <tr><td>Pre-activations</td><td>Output of recurrent synapse model, input to NLMs.</td></tr>
                <tr><td>Post-activations</td><td>Output of NLMs, neuron states at time \(𝑡\).</td></tr>
                <tr><td>(Pre/Post) activation history</td><td>Sequentially ordered history of activations over time.</td></tr>
                <tr><td>Neuron-Level Model (NLM)</td><td>Per-neuron MLP over pre-activation history.</td></tr>
                <tr><td>Synchronization</td><td>Dot product of post-activation histories.</td></tr>
                <tr><td>Self-pair</td><td>Diagonal synchronization matrix entries \((𝑖, 𝑖)\).</td></tr>
                <tr><td>Action synchronization</td><td>Synchronization representation for attention queries.</td></tr>
                <tr><td>Output synchronization</td><td>Synchronization representation for predictions.</td></tr>
                <tr><td>Decay \(𝑟_{𝑖𝑗}\)</td><td>Learnable time decay for synchronization (action or output).</td></tr>
                <tr><td>Feature extractor</td><td>Task-specific input encoder (e.g., ResNet).</td></tr>
                <tr><td>Attention output</td><td>Output after cross-attention using queries, q𝑡 , computed from
action synchronization, and keys/values from data.</td></tr>
-->
            </table>
</p><p>
表 1 | 用語集
<!--
Table 1 | Glossary of terms.
-->
            <table border="1">
<tr><th>シンボル</th><th>意味</th></tr>
<tr><td>\(𝑇\) </td><td>内部ティック数</td></tr>
<tr><td>\(𝑀\) </td><td>メモリ長</td></tr>
<tr><td>\(𝑑_{model}\) </td><td>CTMにおける潜在状態の次元数</td></tr>
<tr><td>\(𝑑_{input}\) </td><td>アテンション出力の次元数</td></tr>
<tr><td>\(𝑑_{hidden}\) </td><td>各ニューロンのプライベートMLP（NLM）における隠れニューロンのサイズ</td></tr>
<tr><td>\(𝑘\) </td><td>シナプスMLPまたはU-Netの深さ</td></tr>
<tr><td>\(𝑝_{dropout}\) </td><td>シナプスモデルにおけるドロップアウト確率</td></tr>
<tr><td>\(𝑛_{heads}\) </td><td>マルチヘッドアテンションにおけるヘッド数</td></tr>
<tr><td>\(𝐽_{action}\) </td><td>動作同期に使用されるニューロン数</td></tr>
<tr><td>\(𝐽_{out}\) </td><td>出力同期に使用されるニューロン数</td></tr>
<tr><td>\(𝐷_{action}\) </td><td>動作同期の次元ベクトル</td></tr>
<tr><td>\(𝐷_{out}\) </td><td>出力同期ベクトルの次元数</td></tr>
<tr><td>\(𝑛_{self}\) </td><td>同期サンプリングで使用される自己ペアの数 \((𝑖, 𝑖)\)</td></tr>
<tr><td>\(𝑟_{𝑖𝑗}\) </td><td>ニューロン𝑖と𝑗間の同期のための学習可能な減衰パラメータ</td></tr>
<tr><td>\(\mathbf S^𝑡\) </td><td>内部ティックにおける完全な同期行列 \(𝑡\)</td></tr>
<tr><td>\(\mathbf q^𝑡\) </td><td>アクション同期から射影されたクエリベクトル</td></tr>
<tr><td>\(\mathbf y^𝑡\) </td><td>出力同期から射影された出力ベクトル（例：ロジット）</td></tr>
<!--
                <tr><th>Symbol</th><th>Meaning</th></tr>
<tr><td>\(𝑇\) </td><td>Number of internal ticks</td></tr>
<tr><td>\(𝑀\) </td><td>Memory length</td></tr>
<tr><td>\(𝑑_{model}\) </td><td>Dimensionality of latent state in the CTM</td></tr>
<tr><td>\(𝑑_{input}\) </td><td>Dimensionality of attention output</td></tr>
<tr><td>\(𝑑_{hidden}\) </td><td>Hidden size in each neuron’s private MLP (NLM)</td></tr>
<tr><td>\(𝑘\) </td><td>Depth of the synapse MLP or U-Net</td></tr>
<tr><td>\(𝑝_{dropout}\) </td><td>Dropout probability in the synapse model</td></tr>
<tr><td>\(𝑛_{heads}\) </td><td>Number of heads in multi-head attention</td></tr>
<tr><td>\(𝐽_{action}\) </td><td>Number of neurons used for action synchronization</td></tr>
<tr><td>\(𝐽_{out}\) </td><td>Number of neurons used for output synchronization</td></tr>
<tr><td>\(𝐷_{action}\) </td><td>Dimensionality of action synchronization vector</td></tr>
<tr><td>\(𝐷_{out}\) </td><td>Dimensionality of output synchronization vector</td></tr>
<tr><td>\(𝑛_{self}\) </td><td>Number of self-pairs \((𝑖, 𝑖)\) used in synchronization sampling</td></tr>
<tr><td>\(𝑟_{𝑖𝑗}\) </td><td>Learnable decay parameter for synchronization between neuron 𝑖 and 𝑗</td></tr>
<tr><td>\(\mathbf S^𝑡\) </td><td>Full synchronization matrix at internal tick \(𝑡\)</td></tr>
<tr><td>\(\mathbf q^𝑡\) </td><td>Query vector projected from action synchronization</td></tr>
<tr><td>\(\mathbf y^𝑡\) </td><td>Output vector (e.g., logits) projected from output synchronization</td></tr>
-->
            </table>
</p><p>
表 2 | 記号の用語集。
<!--
Table 2 | Glossary of symbols.
-->
</p>
<h2>B. 手法の詳細</h2>
<h3>B.1. シナプスモデル</h3>
<!--
<h2>B. Method details</h2>
<h3>B.1. Synapse models</h3>
-->
<p>
図29は、CTM内のニューロン間で情報を共有する再帰構造であるシナプスモデルを示しています。このモデルは、深さを𝑘（常に偶数）に設定することで実装されます。各層の幅は、幅16に達するまで次元を線形に削減し、その後はスキップ接続を用いて情報を保持しながら増加させます。シナプスモデルは、o𝑡（アテンションの出力）も入力として受け取ります。
<!--
Figure 29 show the synapse model which is the recurrent structure that shares information across
neurons in the CTM. It is implemented by choosing a depth of 𝑘 (always even), where each subsequent
layer width is chosen to linearly reduce the dimensionality until a width of 16 is reached, and then
increase thereafter, using skip connections to retain information. The synapse model also takes o𝑡
(the output of attention) as input.
-->
</p>
<center><img src="images/fig29.png"></center>
<p>
図29 | UNETスタイルの「シナプス」リカレントモデルの概要。z𝑡は前のステップからの事後活性化、o𝑡は観測データからのアテンション出力であり、シナプスモデルはNLMが処理するためのa𝑡の事前活性化を生成します。
UNET構造は、最内層のボトルネック層が16ユニット幅になるように設定され、その間の各層は線形スケーリングされます。層ノルムを持つスキップ接続は、情報を維持するために古典的なUNET構造を実装します。低次元を生成する層は青で示され、高次元を生成する層はオレンジで示されます。
<!--
Figure 29 | Overview of UNET style ‘synapse’ recurrent models. z𝑡 are the post-activations from the previous step, o𝑡
are the attention outputs from observing data, and the synapse model yields a𝑡 pre-activations for the NLMs to process.
The UNET structure is set up so that the innermost bottleneck layer is 16 units wide, with linear scaling for each layer in
between. Skip connections with layer-norm implement the classic UNET structure to maintain information. Layers that
produce lower dimensionality are shown in blue, while layers that produce higher dimensionality are shown in orange.
-->
</p>
<h3>B.2. サンプリング同期ニューロン</h3>
<!--
<h3>B.2. Sampling synchronization neurons</h3>
-->
<p>

218 / 5,000
CTMは、𝐷次元の潜在表現zに対して再帰性を用いて動作します。zは時間の経過とともに展開し、選択されたニューロン間の同期によって、CTMが実現する新しい種類の表現が形成されます。
<!--
The CTM operates using recurrence on a latent representation, z, that is 𝐷-dimensional. z unfolds
over time and the synchronization between some chosen neurons form the new kind of representation
that the CTM enables.
-->
</p><p>
ニューロンのペアは\(\frac{𝐷×(𝐷+1)}{2}\)個存在し、ニューロン同期ペアの集合はニューロン数よりもはるかに大きくなります。これが選択プロセスの必要性を生みます。
CTMの開発を通して、私たちはニューロンを選択するための3つのアプローチを考案しました。
<!--
There are \(\frac{𝐷×(𝐷+1)}{2}\) unique pairs of neurons, making for a substantially larger set of neuron synchronization
pairs than there are neurons themselves. This motivates the need for a selection process.
Over the development of the CTM we came up with three approaches to selecting neurons:
-->
<div class="styleBullet">
<ul><li>
1. 稠密ペアリング：この設定では、\(𝐽\) ニューロンを選択し、\(𝐽\) ニューロンのあらゆる可能な \((𝑖,𝑗)\) ペアについて同期を計算します。\(\mathbf S_{out}^𝑡\) には𝐽out ニューロンを選択し、\(\mathbf S_{action}^𝑡\) には重複しない𝐽action ニューロンを選択します。稠密ペアリングに𝐽out ニューロンを選択すると、出力同期表現は \(𝐷_{out} = \frac{𝐽_{out}×(𝐽_{out}+1)}{2}\) となり、アクション表現についても同様です。このアプローチは本質的に、すべての勾配が選択されたニューロンを通過しなければならないという強いボトルネックを作り出します。これは一部のタスクでは有利になる可能性があります。
</li><br><li>2. 半稠密ペアリング：この設定では、2つの異なるサブセット \(𝐽_1\) と \(𝐽_2\) を選択することで、前述のボトルネックを2倍に広げます。同期ドット積の左側のニューロン \(𝑖\) は \(𝐽_1\) から、右側のニューロン \(𝑗\) は \(𝐽_2\) から取得されます。その後、以前と同じ稠密計算が適用されます。
この場合のボトルネックの幅は以前の2倍です。出力とアクションの選択は、ここでも重複しません。
</li><br><li>3.ランダムペアリング：この設定では、𝐷out または𝐷action のニューロンペアをランダムに選択し、各ペア間の同期を計算します。これは、選択されたすべてのニューロン間で密に同期を計算するのとは対照的です。また、ATMが必要に応じてスナップショット表現を復元できるように、各ケースにおいて𝑛selfニューロン間の \((𝑖,𝑖)\) ドット積を意図的に計算します。

これにより、ボトルネックが以前よりもはるかに大きくなります。この場合、重複した選択を許容します。
<!--
1. Dense pairing: in this setup we select \(𝐽\) neurons and compute synchronization for every
possible \((𝑖, 𝑗)\) pair of the \(𝐽\) neurons. For \(\mathbf S_{out}^𝑡\) we choose 𝐽out neurons and for \(\mathbf S_{action}^𝑡\) we choose
non-overlapping 𝐽action neurons. Selecting 𝐽out neurons for dense pairing results in an output
synchronization representation of \(𝐷_{out} = \frac{𝐽_{out}×( 𝐽_{out}+1)}{2}\) , and similarly for the action representation.
This approach essentially creates a strong bottleneck where all gradients must flow through the
selected neurons, which can be advantageous for some tasks.
</li><br><li>2. Semi-dense pairing: in this setup we open up the aforementioned bottleneck twofold by
selecting two different subsets,  \(𝐽_1\) and \(𝐽_2\), such that the left neurons of the synchronization
dot product, \(𝑖\), are taken from \(𝐽_1\) and the right neurons, \(𝑗\), are taken from \(𝐽_2\). The same dense
computation as before is then applied.
The bottleneck width in this case is 2× as wide as before. Output and action selections are, once
more, not overlapping.
</li><br><li>3. Random pairing: in this setup we randomly select 𝐷out or 𝐷action pairs of neurons and compute
the synchronization between each pair as opposed to doing so densely between all selected
neurons. We also intentionally compute the \((𝑖, 𝑖)\) dot products between 𝑛self neurons in each
case in order to ensure that the ATM could recover a snapshot representation if it wanted to.

This opens up the bottleneck much more than before. We allow overlapping selections in this
case.
-->
</li></ul></div>
</p>
<h2>C. ImageNet-1K</h2>
<p>
このセクションでは、ImageNet-1K 実験の追加の詳細と結果について説明します。
<!--
This section provides additional details and results for the ImageNet-1K experiments.
-->
</p>
<h3>C.1. アーキテクチャの詳細</h3>
<!--
<h3>C.1. Architecture details</h3>
-->
<p>
このタスクでは、https://github.com/huyvnphan/PyTorch_CIFAR10 から改変した、古典的な ResNet アーキテクチャ (He et al., 2016) の制約版を使用しました。これは、ImageNet の標準実装とは異なり、最初の畳み込みでカーネルサイズが 7 × 7 ではなく 3 × 3 に制限されています。ResNet-152 構造を使用し、最終的な平均プーリングとクラスロジットへの射影を行う前の出力を取得しました。入力画像のサイズは 224 × 224 で、クロスアテンションで使用されるキーと値として 14 × 14 の特徴が生成されました。
<!--
We used a constrained version of the classic ResNet architecture (He et al., 2016) for this task, which
we adapted from https://github.com/huyvnphan/PyTorch_CIFAR10. It differs from the
standard implementation for ImageNet in that the first convolution is constrained to use a kernel size
of 3 × 3 as opposed to 7 × 7. We used a ResNet-152 structure and took the output prior to the final
average pooling and projection to class logits. We used input images of size 224 × 224 which yielded
14 × 14 features for the keys and values used in cross attention.
-->
</p><p>
次のハイパーパラメータを使用しました。
<!--
We used the following hyperparameters:
-->
<div class="styleBullet">
<ul><li>
• 𝐷 = 4096 (the width of z𝑡 and a𝑡)
</li><li>• 𝑘 = 16 (synapse depth, 8 layers down and 8 layers up)
</li><li>• 𝑑input = 1024 (the width of attention output, o𝑡)
</li><li>• 𝑛heads = 16
</li><li>• Random pairing for neuron selection (see Appendix B.2)
</li><li>• 𝐷out = 8196 (width of S𝑡
out synchronization representation)
</li><li>• 𝐷action = 2048 (width of S𝑡
action synchronization representation)
</li><li>• 𝑛self = 32 (for recovering a snapshot representation)
</li><li>• 𝑇 = 50 (internal ticks)
</li><li>• 𝑀 = 25 (FIFO rolling memory input to NLMs)
</li><li>• 𝑑hidden = 64 (width of MLPs inside NLMs)
</li><li>• 𝑝dropout = 0.2 (dropout probability for synapse model)
</li><li>• No positional embedding
</li></ul></div>
</p><p>
最適化には次の設定を使用しました。
<!--
We used the following settings for optimization:
-->
<div class="styleBullet">
<ul><li>
• Trained using a batch size of 64 across 8 H100 Nvidia GPUs
</li><li>• 500000 iterations for training, using a custom sampling such that each minibatch was sampled
with possible replacement
</li><li>• AdamW (Loshchilov and Hutter, 2017)
</li><li>• A learning rate of 5e-4 with a linear warmup of 10000 iterations and decaying to zero using a
cosine annealing learning rate scheduler
</li><li>• Gradient norm clipping set to a norm of 20
</li><li>• No weight decay
</li></ul></div>
</p>
<h3>C.2. 損失関数</h3>
<!--
<h3>C.2. Loss function</h3>
-->
<p>
リスト5は、ImageNet-1K上でCTMを学習するために使用した画像分類損失関数のPythonコードを示しています。これは、セクション2.5で定義された損失を伴います。
<!--
Listing 5 shows the python code for the image classification loss function used to train the CTM on
ImageNet-1K. This accompanies the loss defined in Section 2.5.
-->
<br>
<br>
<code>
def image_classification_loss ( predictions , certainties , targets , use_most_certain = True ):<br>
"""<br>
Computes the maze loss with auto - extending cirriculum .<br>
Predictions are of shape : (B, class , internal_ticks ),<br>
Certainties are of shape : (B, 2, internal_ticks ),<br>
where the inside dimension (2) is [ normalised_entropy , 1- normalised_entropy ]<br>
Targets are of shape : [B]<br>
use_most_certain will select either the most certain point or the final point .<br>
"""
targets_expanded = torch . repeat_interleave ( targets . unsqueeze ( -1) , predictions . size ( -1), -1)<br>
# Losses are of shape [B, internal_ticks ]<br>
losses = nn. CrossEntropyLoss ( reduction ='none ')( predictions , targets_expanded )<br>loss_index_1 = losses . argmin ( dim =1)<br>
loss_index_2 = certainties [: ,1]. argmax ( -1)<br>
if not use_most_certain : # Revert to final loss if set<br>
loss_index_2 [:] = -1<br>
batch_indexer = torch . arange ( predictions . size (0) , device = predictions . device )<br>
loss_minimum_ce = losses [ batch_indexer , loss_index_1 ]. mean ()<br>
loss_selected = losses [ batch_indexer , loss_index_2 ]. mean ()<br>
loss = ( loss_minimum_ce + loss_selected )/2<br>
return loss<br>
</code>
<br>
リスト 5 | ImageNet-1K で使用される、標準分類タスクのセクション 2.5 の損失関数の実装。
<!--
Listing 5 | Loss function implementation of Section 2.5 for standard classification tasks, used for ImageNet-1K.
-->

</p>
<h3>C.3. 追加のデモンストレーション</h3>
<!--
<h3>C.3. Additional demonstrations</h3>
-->
</p>
<center><img src="images/fig30.png"></center>
<p>
図 30 | 検証画像インデックス 1235。不正確で不確実な予測を示しています。
<!--
Figure 30 | Validation image index 1235, showing incorrect and uncertain prediction.
-->
</p>
<center><img src="images/fig31.png"></center>
<p>
図 31 | 検証画像インデックス 15971。正しい予測と、妥当と思われる 2 番目に可能性の高いクラスを示しています。
<!--
Figure 31 | Validation image index 15971, showing correct prediction and plausible 2nd most probable class.
-->
</p>
<center><img src="images/fig32.png"></center>
<p>
図 32 | 検証画像インデックス 21202、正しい予測を通り過ぎた後に誤った予測を示し、「考えすぎ」を示しています。
<!--
Figure 32 | Validation image index 21202, incorrect prediction after passing by correct prediction, showing ‘over-thinking’.
-->
</p>
<center><img src="images/fig33.png"></center>
<p>
図 33 | 検証画像インデックス 39275、正しいが不確実な予測。
<!--
Figure 33 | Validation image index 39275, correct but uncertain prediction.
-->
</p>
<h2>D. 2D迷路</h2>
<h3>D.1. データセット</h3>
<!--
<h2>D. 2D Mazes</h2>
<h3>D.1. Dataset</h3>
-->
<p>
本研究では、maze-datasetリポジトリ（https://github.com/understanding-search/maze-dataset）を使用して迷路を作成しました。19×19、39×39、99×99のサイズの迷路を生成しました。
<!--
We used the maze-dataset repository to generate mazes for this work: https://github.com/und
erstanding-search/maze-dataset. We generated mazes of size 19 × 19, 39 × 39, and 99 × 99.
-->
</p><p>
それぞれのケースで50,000個の迷路を生成し、45,000個の訓練セットと5,000個のテストセットに分割しました。本技術レポートでは、訓練には39×39のデータセットを使用し、一般化のテストには99×99のデータセットを使用しました。3つの迷路データセットはすべてCTMコードリポジトリで提供されています。<sup>8</sup>
<!--
In each case we generated 50000 mazes and split them into train sets of size 45000 and test sets of
size 5000. We used the 39 × 39 for training in this technical report and tested generalization on the
99 × 99. We provide all three maze datasets <sup>8</sup> in the CTM code repository.
-->
</p>
<p class="margin-large">
<sup>8</sup> 
19 × 19 はデバッグに有益であることがわかったため、これも提供しています。
<!--
We found the 19 × 19 beneficial for debugging, hence we provide it too.
-->
</p>
<h3>D.2. アーキテクチャの詳細</h3>
<!--
<h3>D.2. Architecture details</h3>
-->
<p>
次のハイパーパラメータを使用しました。
<!--
We used the following hyperparameters:
-->
<div class="styleBullet">
<ul><li>
• 39 × 39 mazes and a ResNet-34 backbone, where the keys and values were taken as features
after the second hyper-block, resulting in a down-sample to 10 × 10
</li><li>• 𝐷 = 2048 (the width of z𝑡 and a𝑡)
</li><li>• 𝑘 = 16 (synapse depth, 8 layers down and 8 layers up)
</li><li>• 𝑑input = 512 (the width of attention output, o𝑡)
</li><li>• 𝑛heads = 16
</li><li>• Dense pairing for neuron selection (see Appendix B.2)
</li><li>• 𝐽out = 32 (width of S𝑡
out synchronization representation)
</li><li>• 𝐽action = 32 (width of S𝑡
action synchronization representation)
</li><li>• 𝑇 = 75 (internal ticks)
</li><li>• 𝑀 = 25 (FIFO rolling memory input to NLMs)
</li><li>• 𝑑hidden = 32 (width of MLPs inside NLMs)
</li><li>• 𝑝dropout = 0.1 (dropout probability for synapse model)
</li><li>• No positional embedding
</li></ul></div>
</p><p>
最適化には次の設定を使用しました。
<!--
We used the following settings for optimization:
-->
<div class="styleBullet">
<ul><li>
• Trained using a batch size of 64 on 1 H100 Nvidia GPU
</li><li>• 1000000 iterations for training using AdamW (Loshchilov and Hutter, 2017)
</li><li>• A learning rate of 1e-4 with a linear warmup of 10000 iterations and decaying to zero using a
cosine annealing learning rate scheduler
</li><li>• No weight decay
</li></ul></div>
</p><p>
その結果、31,998,330 個のパラメータを持つモデルが作成されました。
<!--
This resulted in a model with 31,998,330 parameters.
-->
</p>
<h3>D.3. 迷路カリキュラム</h3>
<!--
<h3>D.3. Maze curriculum</h3>
-->
<p>
迷路を解くための損失関数にカリキュラム要素を組み込むように適応させました。式(12)の損失の𝑡1と𝑡2を計算する前に、まず各内部ティックにおける損失を変更し、迷路内の正しく予測されたステップと、経路に沿った追加の5ステップのみを考慮するようにしました。これにより、モデル（CTMまたはLSTMベースライン）は、迷路を最初から最後までゆっくりと解くことを効果的に学習できます。リスト6は、損失を計算する際にこれがどのように実装されているかを示しており、CTMとLSTMの両方のトレーニングに使用されます。
<!--
We adapted the loss function for solving mazes to include a curriculum element. Before computing 𝑡1
and 𝑡2 for the loss in Equation (12) we first altered the loss at each internal tick to only account
for those steps in the maze that were correctly predicted with plus 5 additional steps along the path.
This effectively lets the model (CTM or LSTM baselines) slowly learn to solve the maze from start to
finish. Listing 6 shows how this is implemented when computing the loss and is used for both CTM
and LSTM training.
-->
</p>
<h3>D.4. ベースラインの詳細</h3>
<!--
<h3>D.4. Baselines details</h3>
-->
<p>
この課題を解決するために、いくつかのLSTMベースラインをテストしましたが、学習中の安定性に問題がありました（図7参照）。特に、LSTM層が1層を超える場合や、内部ティック数が多い場合が顕著でした。そこで、深度1、2、3の3つのLSTM構成をテストしました。各モデルについて、CTMと一致するように内部ティック数を75に設定し、安定性を確保するために内部ティック数を50に設定しました。また、平均プーリング前の特徴空間をCTMと同じ幅の隠れ層に投影するフィードフォワードモデルもテストしました。これにより、パラメータ数がわずかに増加しました。すべてのハイパーパラメータは一定に保ち、以下の設定を行いました。
<!--
We tested a number of LSTM baselines for solving this task, but struggled with stability during training
(see Figure 7), particularly beyond a single LSTM layer or with a higher number of internal ticks.
Hence we tested three LSTM configurations of depths 1,2, and 3. For each model we tested with 75
internal ticks to match the CTM, and 50 internal ticks for stability. We also tested a feed-forward
model, projecting the feature space (before average pooling) into a hidden layer of the same width as
the CTM, yielding a slightly higher parameter count. We kept all hyperparameters constant, yielding
the following setups:
-->
<div class="styleBullet">
<ul><li>
• LSTM, 1 layer, 𝑇 = 50 and 𝑇 = 75: 42,298,688
</li><li>• LSTM, 2 layers, 𝑇 = 50 and 𝑇 = 75: 75,869,504 parameters
</li><li>• LSTM, 3 layers, 𝑇 = 50 and 𝑇 = 75: 109,440,320 parameters
</li><li>• Feed-forward, with a hidden layer width of 2048 (and GLU activation thereon): 54,797,632
parameters
</li></ul></div>
</p><p>

<br><br>
<code>
def image_classification_loss ( predictions , certainties , targets , use_most_certain = True ):<br>
"""<br>
Computes the maze loss with auto - extending cirriculum .<br>
Predictions are of shape : (B, class , internal_ticks ),<br>
Certainties are of shape : (B, 2, internal_ticks ),<br>
where the inside dimension (2) is [ normalised_entropy , 1- normalised_entropy ]<br>
Targets are of shape : [B]<br>
use_most_certain will select either the most certain point or the final point .<br>
"""<br>
targets_expanded = torch . repeat_interleave ( targets . unsqueeze ( -1) , predictions . size ( -1), -1)<br>
# Losses are of shape [B, internal_ticks ]<br>
losses = nn. CrossEntropyLoss ( reduction ='none ')( predictions , targets_expanded )<br>
loss_index_1 = losses . argmin ( dim =1)<br>
loss_index_2 = certainties [: ,1]. argmax ( -1)<br>
if not use_most_certain : # Revert to final loss if set<br>
loss_index_2 [:] = -1<br>
batch_indexer = torch . arange ( predictions . size (0) , device = predictions . device )<br>
loss_minimum_ce = losses [ batch_indexer , loss_index_1 ]. mean ()<br>
loss_selected = losses [ batch_indexer , loss_index_2 ]. mean ()<br>
loss = ( loss_minimum_ce + loss_selected )/2<br>
return loss<br>
</code>
<br>
リスト6 | 迷路経路予測のためのセクション2.5の損失関数の実装。CTMとLSTMの両方に対する自動カリキュラムアプローチを含む。
<!--
Listing 6 | Loss function implementation of Section 2.5 for maze route prediction, including an auto curriculum approach
for both CTM and LSTM.
-->
</p>
<h3>D.5. 迷路損失曲線</h3>
<!--
<h3>D.5. Maze loss curves</h3>
-->
<p>
図34は、第4.1節の迷路解決モデルの損失曲線を示しており、このタスクで訓練した場合、CTMがより安定して高性能になることを示しています。
<!--
Figure 34 gives the loss curves for the maze solving models in Section 4.1, showing how the CTM is
more stable and performant when trained on this task.
-->

</p>
<center><img src="images/fig34.png"></center>
<p>
図 34 | CTM とベースラインをトレーニングするときの損失曲線。
<!--
Figure 34 | Loss curves when training the CTM and baselines.
-->
</p>
<h2>E. CIFAR-10と人間</h2>
<!--
<h2>E. CIFAR-10 versus humans</h2>
-->
<p>
制約付きResNet-18バックボーンの最初のハイパーブロック（付録C.1参照）を使用しました。畳み込み層は合計5層、ダウンサンプル係数は2倍です。CTMには以下のハイパーパラメータを使用しました。
<!--
We used a the first hyper-block of a constrained ResNet-18 backbone (see Appendix C.1): 5 convolutional
layers in total and a downsample factor of 2×. We used the following hyperparameters for the
CTM:
-->
<div class="styleBullet">
<ul><li>

• 𝐷 = 256 (the width of z𝑡 and a𝑡)
</li><li>• 𝑘 = 10 (synapse depth, 5 layers down and 5 layers up)
</li><li>• 𝑑input = 64 (the width of attention output, o𝑡)
</li><li>• 𝑛heads = 16
</li><li>• Random pairing for neuron selection (see Appendix B.2)
</li><li>• 𝐷out = 256 (width of S𝑡
out synchronization representation)
</li><li>• 𝐷action = 512 (width of S𝑡
action synchronization representation)
</li><li>• 𝑛self = 0
</li><li>• 𝑇 = 50
</li><li>• 𝑀 = 15 (FIFO rolling memory input to NLMs)
</li><li>• 𝑑hidden = 64 (width of MLPs inside NLMs)
</li><li>• 𝑝dropout = 0.0
</li><li>• Weight decay of 0.0001
</li><li>• No positional embedding
</li></ul></div>
</p><p>
最適化には次の設定を使用しました。
<!--
We used the following settings for optimization:
-->
<div class="styleBullet">
<ul><li>
• 1基のH100 Nvidia GPUでバッチサイズ512で学習
</li><li>• AdamW (Loshchilov and Hutter, 2017) を用いた学習で600000回の反復
</li><li>• 学習率は1e-4、2000回の反復で線形ウォームアップし、コサインアニーリング学習率スケジューラを用いて0に減衰
<!--
• Trained using a batch size of 512 on 1 H100 Nvidia GPU
</li><li>• 600000 iterations for training using AdamW (Loshchilov and Hutter, 2017)
</li><li>• A learning rate of 1e-4 with a linear warmup of 2000 iterations and decaying to zero using a
cosine annealing learning rate scheduler
-->
</li></ul></div>
</p><p>
LSTMベースラインでは、単層LSTMよりも優れたパフォーマンスを示し、学習において比較的安定していた2層LSTMを使用しました（迷路タスクと比較して）。CTMのシナプス深度、メモリ長、NLM隠れ層の幅は、モデル幅が一定（256）になるように選択し、CTMとLSTMのパラメータ数はほぼ一致するようにしました。フィードフォワードモデルでは、モデル幅を一定に保ちました。
<!--
For the LSTM baseline a 2-layer LSTM was used as this performed better than a single layer LSTM
setup and was relatively stable in training (compared to the maze task). The CTM synapse depth,
memory length, and NLM hidden width were chosen such that the model width was kept constant
(256) while parameter counts were closely matched between the CTM and LSTM. For the feed-forward
model we kept the model width constant.
-->
</p>
<h2>F. CIFAR-100</h2>
<p>
このセクションでは、CIFAR-100 実験の詳細について説明します。
<!--
This section discusses the details of the CIFAR-100 experiments.
-->
</p>
<h3>F.1. アーキテクチャの詳細</h3>
<!--
<h3>F.1. Architecture details</h3>
-->
<p>
セクション6.1では、制約付きResNet-34バックボーンの最初の2つのハイパーブロック（付録C.1参照）を使用しました。ダウンサンプル係数は4倍です。この実験では、𝐷を変化させましたが、その他のハイパーパラメータは以下のように設定しました。
<!--
For Section 6.1 we used a the first two hyper-blocks of a constrained ResNet-34 backbone (see
Appendix C.1): a downsample factor of 4×. For this experiment we varied 𝐷 but kept all other
hyperparameters as:
-->
<div class="styleBullet">
<ul><li>
• 𝑘 = 8 (synapse depth, 4 layers down and 4 layers up)
</li><li>• 𝑑input = 512 (the width of attention output, o𝑡)
</li><li>• 𝑛heads = 8
</li><li>• Random pairing for neuron selection (see Appendix B.2)
</li><li>• 𝐷out = 2048 (width of S𝑡
out synchronization representation)
</li><li>• 𝐷action = 1024 (width of S𝑡
action synchronization representation)
</li><li>• 𝑛self = 32
</li><li>• 𝑇 = 50
</li><li>• 𝑀 = 25 (FIFO rolling memory input to NLMs)
</li><li>• 𝑑hidden = 32 (width of MLPs inside NLMs)
</li><li>• 𝑝dropout = 0.2
</li><li>• No weight decay
</li><li>• No positional embedding
</li></ul></div>
</p><p>
セクション6.2では、制約付きResNet-19バックボーンの最初の2つのハイパーブロック（付録C.1参照）を使用しました。ダウンサンプル係数は4倍です。この実験では、𝑇を変化させましたが、その他のハイパーパラメータは以下のように変更しませんでした。
<!--
For Section 6.2 we used the first two hyper-blocks of a constrained ResNet-19 backbone (see Appendix
C.1): a downsample factor of 4×. For this experiment we varied 𝑇 but kept all other hyperparameters
as:
-->
<div class="styleBullet">
<ul><li>
• 𝐷 = 512
</li><li>• 𝑘 = 4 (synapse depth, 2 layers down and 2 layers up)
</li><li>• 𝑑input = 256 (the width of attention output, o𝑡)
</li><li>• 𝑛heads = 4
</li><li>• Random pairing for neuron selection (see Appendix B.2)
</li><li>• 𝐷out = 256 (width of S𝑡
out synchronization representation)
</li><li>• 𝐷action = 256 (width of S𝑡
action synchronization representation)
</li><li>• 𝑛self = 0
</li><li>• 𝑀 = 25 (FIFO rolling memory input to NLMs)
</li><li>• 𝑑hidden = 16 (width of MLPs inside NLMs)
</li><li>• 𝑝dropout = 0.0
</li><li>• Weight decay of 0.001
</li><li>• No positional embedding
</li></ul></div>
</p><p>
このモデルは、より多くのティックを使用することで生じるオーバーヘッドのため、他のCIFAR-100アブレーションと比較してより制約が厳しく設定されています。セクション6.2で説明したように、より長いティックで学習された変異体は、より多くの学習から利益を得る可能性があり、この実験でより大きなモデルを使用する場合、この差異はさらに大きくなります。
<!--
This model was set up to be more constrained compared to the other CIFAR-100 ablation because
of the overhead induced by using more ticks. We explained in Section 6.2 that the variants trained
with longer ticks could benefit from more training, and this disparity would be greater should we use
bigger models for this experiment.
-->
</p>
<h2>G. パリティ</h2>
<h3>G.1. データセットの詳細</h3>
<!--
<h2>G. Parity</h2>
<h3>G.1. Dataset details</h3>
-->
<p>
パリティタスクの入力データは長さ64のベクトルで、各位置は-1または1です。
各サンプルのターゲットは同じサイズのベクトルで、各位置はその位置までのシーケンスのパリティ（累積パリティ）です。このデータは、新しいバッチがフェッチされるたびにオンザフライで生成されます。
<!--
The input data for the parity task is a vector of length 64, where at each position is either a −1 or 1.
The target for each sample is a vector of the same size, where at each position is the parity of the
sequence up to that position, which we refer to as the cumulative parity. This data is generated on
the fly, each time a new batch is fetched.
-->
</p>
<h3>G.2. アーキテクチャの詳細</h3>
<!--
<h3>G.2. Architecture details</h3>
-->
<p>
パリティタスクの実験では、以下のアーキテクチャが用いられる。モデルへの入力は(𝐵, 64)の形状であり、ミニバッチのサイズとシーケンスの長さはそれぞれ𝐵と64である。長さ64のシーケンスの各値は、ランダムに-1または1となる。まず、-1と1の値は𝑑embed = 𝑑inputの埋め込みに変換され、位置埋め込みが加算される。得られた埋め込みは、層正規化を伴う線形層に渡され、（同一の）アテンションキーとアテンション値が形成される。第2節で説明したように、𝐽actionニューロン間の同期が計算され、この表現からアテンションクエリが形成される。このクエリは、アテンション値の計算に使用され、アテンション値は活性化状態に連結され、シナプスとニューロンレベルモデルによって処理される。シナプスには、浅いフィードフォワードネットワークを使用します。このプロセスは𝑇内部ティックごとに繰り返され、各内部ティック𝑡において、𝐽outニューロン間の同期が計算され、ロジット空間に投影されます。
<!--
The following architecture is used for the experiments in the parity task. Inputs to the model are
of shape (𝐵, 64), where the size of the minibatch and sequence length are 𝐵 and 64, respectively.
Each of the values in the 64-length sequence are either -1 or 1, at random. First, the values of -1
and 1 are converted into embeddings in 𝑑embed = 𝑑input and positional embeddings are added. The
resulting embeddings are passed through a linear layer with layer normalization to form (identical)
attention keys and values. As described in section 2, the synchronization between 𝐽action neurons
is computed and from this representation an attention query is formed. This query is then used to
compute the attention values, which are concatenated to the activated state to be processed by the
synapses and the neuron-level models. For the synapses we use a shallow feedforward network. This
process repeats for 𝑇 internal ticks, where at each internal tick 𝑡, the synchronization can be computed
between 𝐽out neurons and projected to the logit space.
-->
</p><p>
パリティタスクでは、内部ティック数とメモリ長を変化させた場合のモデルのパフォーマンスを実験しました。ベースラインとして、CTMと同じ内部ティック数を使用し、パラメータマッチングされた単層LSTMを使用しました。すべてのCTMモデルは、以下に示す共通のアーキテクチャハイパーパラメータセットを共有しています。表3は、実験構成によって異なるハイパーパラメータのサブセットを示しています。
<!--
In the parity task, we experimented with how the model performs with a varying number of internal
ticks and memory length. As a baseline, we use single-layer LSTMs which are both parameter matched
and use the same number of internal ticks as the CTM.
All CTM models share a common set of architectural hyperparameters, listed below. The Table 3
shows the subset of hyperparameters that vary across experimental configurations.
-->
<div class="styleBullet">
<ul><li>
• \(𝑑_{model}\) = 1024
</li><li>• \(𝑑_{input}\) = 512
</li><li>• \(𝑑_{hidden}\) = 4
</li><li>• 𝑘 = 1
</li><li>• \(𝑝_{dropout}\) = 0
</li><li>• \(𝑛_{heads}\) = 8
</li><li>• \(𝐽_{action}\) = 32
</li><li>• \(𝐽_{out}\) = 32
</li><li>• Semi-dense pairing was used for selecting neurons for synchronization
</li><li>• Absolute positional encoding was added to the input features
</li></ul></div>
</p><p>

            <table border="1">
                <tr><th>Model</th><th>𝑇</th><th>𝑀</th><th> \(𝑑_{model}\)</th><th>Total Parameters</th></tr>
                <tr><td>CTM </td>  <td>1</td><td>1</td>  <td>1024</td>  <td>4908706</td>  </tr>
                <tr><td>LSTM </td>  <td>1</td><td>-</td>  <td>669</td>  <td>4912710</td>  </tr>
                <tr><td>CTM </td>  <td>10</td><td>5</td>  <td>1024</td>  <td>5043874</td>  </tr>
                <tr><td>LSTM</td>  <td>10</td><td>-</td>  <td>686</td>  <td>5050716</td>  </tr>
                <tr><td>CTM </td>  <td>25</td><td>10</td>  <td>1024</td>  <td>5212834</td>  </tr>
                <tr><td>LSTM </td>  <td>25</td><td>-</td>  <td>706</td>  <td>5224386</td>  </tr>
                <tr><td>CTM </td>  <td>50</td><td>25</td>  <td>1024</td>  <td>5719714</td>  </tr>
                <tr><td>LSTM </td>  <td>50</td><td>-</td>  <td>765</td>  <td>5722374</td>  </tr>
                <tr><td>CTM </td>  <td>75</td><td>25</td>  <td>1024</td>  <td>5719714</td>  </tr>
                <tr><td>LSTM </td>  <td>75</td><td>-</td>  <td>765</td>  <td>5722374</td>  </tr>
                <tr><td>CTM </td>  <td>100</td><td>50</td>  <td>1024</td>  <td>6564514</td>  </tr>
                <tr><td>LSTM </td>  <td>100</td><td>-</td>  <td>857</td>  <td>6567486</td>  </tr>
            </table>
 </p><p>  
表 3 | パリティ タスクのモデル ハイパーパラメータ (構成によって異なります)。
<!--
Table 3 | Model hyperparameters for the parity task (that vary across configurations).
-->
</p>
<h3>G.3. 最適化の詳細</h3>
<!--
<h3>G.3. Optimization details</h3>
-->
<p>
CTMはセクション2.5で説明した確実性ベースの損失関数を用いて学習されましたが、LSTMベースラインは最終内部ティックで計算されたクロスエントロピー損失を利用しました。この選択は、確実性ベースの損失関数を用いてLSTMを効果的に学習させることが当初困難であったために行われました。図35は、最終損失または確実性ベースの損失を用いて学習した、10回および25回の反復回数におけるLSTMベースラインの学習精度曲線を比較しています。一般的に、複数の内部ティックを持つLSTMの場合、どちらの損失関数も学習が不安定になります。
<!--
The CTM was trained using the certainty-based loss function described in section 2.5, whereas the
LSTM baselines utilized the cross-entropy loss computed at the final internal tick. This choice was
made due to initial difficulties in training the LSTM effectively with the certainty-based loss. In
Figure 35, we compare training accuracy curves for the LSTM baselines with 10 and 25 iterations,
trained with either the final or certainty-based loss. Generally, both loss functions lead to unstable
training for LSTMs with multiple internal ticks.
-->
</p><p>
最適化には次の設定を使用しました。
<!--
We used the following settings for optimization:
-->
<div class="styleBullet">
<ul><li>
• 1基のH100 Nvidia GPUでバッチサイズ64で学習しました。
</li><li>• AdamW (Loshchilov and Hutter, 2017) を用いた200,000回の反復学習。
</li><li>• 学習率は1e-4で、500回の反復で線形ウォームアップし、コサインアニーリング学習率スケジューラを用いて0に減衰させました。
<!--
• Trained using a batch size of 64 on 1 H100 Nvidia GPU.
</li><li>• 200000 iterations for training using AdamW (Loshchilov and Hutter, 2017).
</li><li>• A learning rate of 1e-4 with a linear warmup of 500 iterations and decaying to zero using a
cosine annealing learning rate scheduler.
-->
</li></ul></div>
</p>
<h3>G.4. 結果</h3>
<!--
<h3>G.4. Results</h3>
-->
<p>
モデルのパフォーマンスはシード間で大きく異なります。図19は、様々なCTMおよびLSTM構成におけるトレーニング中の精度を示しています。各構成は3回の独立した実行の平均値です。これらのトレーニング曲線は、実行間でパフォーマンスが大きく異なるため、かなりのばらつきを示しています。これは、初期のランダムシードに強く影響されます。例えば、図36は、75の内部ティックと25のメモリ長でトレーニングされたCTMの個々のトレーニング曲線を示しています。実行1と3は完璧な精度に達していますが、実行2は準最適な解に収束しています。
<!--
Model performance varies significantly between seeds Figure 19 shows the accuracy over training
for various CTM and LSTM configurations, with each configuration averaged over three independent
runs. These training curves exhibit considerable variance due to significant differences in performance
between runs, strongly influenced by the initial random seed. For example, Figure 36 shows individual
training curves for the CTM trained with 75 internal ticks and a memory length of 25. Runs 1 and 3
reach perfect accuracy, while run 2 converges to a suboptimal solution.
-->
</p><p>
さらに、これら3つのモデルはすべて著しく異なる挙動を示し、各CTMは75の内部ティックにわたって入力シーケンスの非常に異なる部分に注意を払います。内部ティックにおけるこれらの注意パターンは図37に示されています。実行3では、シーケンス全体の最初から最後まで注意を払うモデルが生成されますが、実行1では逆の順序で注意を払います。
<!--
Furthermore, all three of these models display significantly different behaviors, with each CTM
attending to very different parts of the input sequence over the 75 internal ticks. These attention
patterns over the internal ticks are shown in Figure 37. Run 3 results in a model that attends from
the beginning to the end of the entire sequence, while run 1 attends in reverse order.
-->
</p>
<center><img src="images/fig35.png"></center>
<p>

図35 | 最終内部ティックにおける確実性ベースの損失またはクロスエントロピー損失のいずれかで学習したLSTMベースラインのテスト精度。どちらの損失関数も学習が不安定になる。
<!--
Figure 35 | Test accuracies for LSTM baselines, trained with either the certainty-based loss or the cross-entropy loss at the
final internal tick. Both loss functions lead to unstable learning.
-->
</p>
<center><img src="images/fig36.png"></center>
<p>
図36 | 3つのランダムシードを用いて学習した3つのCTMの学習曲線。実行1と3は損失がゼロに収束しますが、もう1つの実行は損失がゼロ以外になります。
<!--
Figure 36 | Training curves for three CTMs trained with three random seeds. Run 1 and 3 converge to a loss of zero, while
the other run converges to a non-zero loss.
-->
</p>
<center><img src="images/fig37.png"></center>
<p>
図 37 | トレーニング後の 3 回の実行ごとの注意パターン。
<!--
Figure 37 | Attention patterns for each of the three runs after training.
-->
</p>
<h2>H. Q&A MNIST</h2>
<h3>H.1. アーキテクチャの詳細</h3>
<!--
<h3>H.1. Architecture details</h3>
-->
<p>
他のタスクとは異なり、Q&A MNISTタスクは、MNIST数字画像、演算子とインデックスマーカーの埋め込み、そして回答フラグとしてのゼロテンソルなど、複数の入力タイプを処理します。MNIST画像は、2つの畳み込みブロック（各ブロックは畳み込み層、バッチ正規化、ReLU活性化、および最大プーリング層を含む）で構成される畳み込みバックボーンによる前処理を受けます。このバックボーンからの出力はアテンションキーとアテンション値を形成し、CTMは同期表現からの射影を用いてこれらを照会します。結果として得られるアテンション出力は、シナプス処理の前にCTMのアクティブ状態と連結されます。対照的に、演算子とインデックスの埋め込み、そして回答フラグは、畳み込みバックボーンとアテンションメカニズムをバイパスし、CTMのアクティブ状態に直接連結されます。演算子は学習された埋め込みを使用し、インデックスは正弦波埋め込み（Vaswani et al., 2017）を利用し、回答フラグは埋め込み次元に一致するゼロベクトルです。
<!--
Unlike other tasks, the Q&A MNIST task processes multiple input types: MNIST digit images, embeddings
for operator and index markers, and zero tensors as answer flags. MNIST images undergo preprocessing through a convolutional backbone consisting of two convolutional blocks, each containing
a convolutional layer, batch normalization, a ReLU activation, and a max pooling layer. Outputs
from this backbone form attention keys and values, which the CTM queries using projections from
the synchronization representation. The resulting attention outputs are concatenated with the CTM’s
activated state before synaptic processing. In contrast, operator and index embeddings, as well as
answer flags, bypass the convolutional backbone and attention mechanism, being directly concatenated
to the CTM’s activated state. Operators use learned embeddings, indices utilize sinusoidal
embeddings (Vaswani et al., 2017), and answer flags are zero vectors matching the embedding
dimension.
-->
</p><p>
比較のために、パラメータと内部ティックが一致した単層LSTMベースラインを使用しました。実験で使用した共通パラメータは以下のとおりです。
<!--
For comparison, parameter and internal tick matched single-layer LSTM baselines were used. The
common parameters used in the experiment are as follows:
-->
<div class="styleBullet">
<ul><li>
• \(𝑑_{model}\) = 1024
</li><li>• \(𝑑_{input}\) = 64
</li><li>• \(𝑑_{hidden}\) = 16
</li><li>• 𝑘 = 1
</li><li>• \(𝑝_{dropout}\) = 0
</li><li>• \(𝑛_{heads}\) = 4
</li><li>• \(𝐽_{action}\) = 32
</li><li>• \(𝐽_{out}\) = 32
</li><li>• 同期ニューロンの選択には、半稠密ペアリングが用いられました。
</li><li>• 位置エンコーディングは用いられませんでした。
CTMの詳細なハイパーパラメータは表4に示されています。
<!--
</li><li>• Semi-dense pairing was used for selecting neurons for synchronization.
</li><li>• Positional encoding was not used.
Detailed hyperparameters of the CTM are provided in Table 4.
-->
</li></ul></div>
</p><p>
<table border="1">
<tr><th>Model  </th>  <th>𝑇  </th><th>𝑀  </th>  <th>Repeats/Input  </th>  <th>Answering Steps  </th>  <th>Total Parameters  </th>  </tr>
<tr><td>CTM  </td>  <td>1  </td>  <td>3  </td>  <td>1  </td>  <td>1  </td>  <td>2,501,388  </td>  </tr>
<tr><td> LSTM </td>  <td>1 </td><td>-  </td>  <td>1  </td>  <td>1  </td>  <td>2,507,218  </td>  </tr>
<tr><td> CTM </td>  <td>10  </td><td>30  </td>  <td>10  </td>  <td>10  </td>  <td>3,413,772  </td>  </tr>
<tr><td> LSTM </td>  <td>10  </td><td>-  </td>  <td>10  </td>  <td>10  </td>  <td>3,418,954  </td>  </tr>
</table>
</p><p>
表4 | Q&A MNIST実験における異なるモデルのハイパーパラメータと合計パラメータ。Repeats/Input列は、モデルが一意の入力を処理するために使用した内部ティック数を示します。例えば、Repeats/Input = 10は、MNISTの各数字と各インデックスまたは演算子の埋め込みを処理するために10内部ティックが使用されることを意味します。Answering Stepsは、回答フラグが観測される内部ティック数を示します。
<!--
Table 4 | Differing model hyperparameters and total parameters for the Q&A MNIST experiments. The column Repeats/
Input refers to the number of internal ticks the model used to process a unique input. For example, Repeats/Input = 10
implies that 10 internal ticks are used to process each MNIST digit and each index or operator embedding. The Answering
Steps refers to the number of internal ticks the answering flag is observed for.
-->
</p>
<h3>H.2. 最適化の詳細</h3>
<!--
<h3>H.2. Optimization details</h3>
-->
<p>
CTMはセクション2.5で説明した確実性ベースの損失関数を用いて学習され、LSTMベースラインは最終内部ティックにおけるクロスエントロピー損失を用いて学習されました。最適化には以下の設定を使用しました。
<!--
The CTM was trained using the certainty-based loss function described in section 2.5, while the LSTM
baselines were trained using the cross-entropy loss at the final internal tick. We used the following
settings for optimization:
-->
<div class="styleBullet">
<ul><li>
• 1基のH100 Nvidia GPUでバッチサイズ64で学習しました。
</li><li>• AdamW (Loshchilov and Hutter, 2017) を用いた学習には300,000回の反復処理を行いました。
</li><li>• 学習率は1e-4で、500回の反復処理で線形ウォームアップを行い、コサインアニーリング学習率スケジューラを用いて0に減衰させました。
<!--
• Trained using a batch size 64 on 1 H100 Nvidia GPU.
</li><li>• 300000 iterations for training using AdamW (Loshchilov and Hutter, 2017).
</li><li>• A learning rate of 1e-4 with a linear warmup of 500 iterations and decaying to zero using a
cosine annealing learning rate scheduler.
-->
</li></ul></div>
</p>
<h2>I. 強化学習</h2>
<h3>I.1. 環境の詳細</h3>
<!--
<h2>I. Reinforcement learning</h2>
<h3>I.1. Environment details</h3>
-->
<p>
<strong>CartPole</strong> CartPoleタスク（CartPole-v1）は、強化学習における古典的なタスクです。摩擦のない軌道上を移動するカートにヒンジで接続されたポールのバランスをとるタスクです。システムは、ポールを垂直に保つことを目的として、カートに水平方向の力（左または右）を加えることで制御されます。1歩ごとに+1の報酬が与えられ、ポールの角度が±12◦を超えるか、カートの位置が±2.4を超えるか、エピソードの長さが最大歩数（200歩に設定）を超えるとエピソードは終了します。さらに、報酬の正規化を使用して、即時報酬の指数移動平均がほぼ一定の分散を持つようにします。
<!--
<strong>CartPole.</strong>　The CartPole task (CartPole-v1) is a classic task in reinforcement learning. It involves
balancing a pole, which is hinged to a cart moving along a frictionless track. The system is controlled by applying horizontal forces (left or right) to the cart, with the objective of keeping the pole
upright. A reward of +1 is given for every step taken, with the episode terminating when either
the pole angle is greater than ±12◦, the cart position is greater than ±2.4, or the episode length is
greater than the maximum number of steps, which we set to 200 steps. Furthermore, we use reward
normalization, such that the exponential moving average of immediate rewards has an approximately
fixed variance.
-->
</p><p>

行動空間は、カートに作用する力の方向に対応する2つの離散的な行動から構成されます。典型的なカートポール課題では、観測空間は(4, )の形状を持ち、値はカートの位置、カートの速度、ポールの角度、ポールの角速度に対応します。しかし、CTMを用いた本実験では、環境を部分的に観測可能にするために、カートの速度とポールの角速度はマスクされています。
<!--
The action space is composed of 2 discrete actions, corresponding to the direction of force applied to
the cart. In the typical cartpole task, the observation space is of shape (4, ) with values corresponding
to the cart position, cart velocity, pole angle and pole angular velocity. For our experiments with the
CTM, however, the cart velocity and the pole angular velocity are masked to make the environment
partially observable.
-->
</p><p>
<strong>Acrobot</strong> Acrobotタスク（Acrobot-v1）では、2つのリンクが直線的に接続されたチェーンで構成されるシステムが用いられ、チェーンの一端は固定されています。2つのリンク間のジョイントは駆動され、固定端のジョイントは自由に回転します。目標は、駆動ジョイントにトルクを加えて、チェーンの自由端をできるだけ少ないステップ数で特定の高さ以上に振り上げることです。チェーンは最初はランダムな角度と速度で垂れ下がっています。エピソードは、チェーンが必要な高さを超えるか、最大ステップ数（500ステップに設定）に達した時点で終了します。目標到達までのすべてのステップに対して-1の報酬が発生し、上限は-100です。
<!--
<strong>Acrobot.</strong>　In the Acrobot task (Acrobot-v1), a system composed of two links connected linearly to
form a chain, with one end of the chain fixed. The joint between the two links is actuated, while
the joint at the fixed end is free to rotate. The goal is to apply torques to the actuated joint to swing
the free end of the chain above a certain height in as few steps as possible, with the chain initially
hanging down with some initial random angle and velocity. An episode ends when the chain reaches
above the required height, or a maximum number of steps are taken, which we set to 500 steps. A
reward of −1 is incurred for all steps taken to reach the goal, with a limit of −100.
-->
</p><p>
動作空間は3つの離散動作から構成され、駆動関節に-1、0、1𝑁𝑚のトルクをかける。観測空間は(6)の形状で、第1関節のなす角度の正弦と余弦（角度0は第1リンクが真下を向いていることを示す）、第2リンクの正弦と余弦（角度0は2つのリンク間の角度が同じであることを示す）、そして2つの角度の角速度から構成される。CartPoleタスクと同様に、これら2つの角速度成分はマスクされているため、環境は部分的にしか観測できない。
<!--
The action space consists of three discrete actions, which are to apply −1, 0 and 1 𝑁𝑚 of torque to the
actuated joint. The observation space is of shape (6,) composed of the sine and cosine of the angle
made by the first joint (such that an angle of 0 indicated the first link is pointing directly downwards),
the sine and cosine of the second link (such that an angle of 0 corresponds to having the same angle
between the two links), and the angular velocity of two angles. As in the CartPole task, these two
angular velocity components are masked such that the environment is only partially observable.
-->
</p><p>

<strong>ミニグリッド 4 つの部屋</strong> ミニグリッド 4 つの部屋タスク (MiniGrid-FourRooms-v0) は、エージェントが壁の 4 つの隙間で相互接続された 4 つの部屋で構成されたグリッドワールド内を移動する必要がある強化学習環境です。エージェントは、緑色の四角にあるゴールに到達した場合は 1 − 0.9 (歩数×最大歩数) の報酬を、それ以外の場合は 0 を受け取ります。ここでも、報酬正規化を使用して、過去の報酬の移動平均を正規化します。エージェントの位置、ゴールの位置、および壁の 4 つの隙間は、各エピソードの開始時にランダムに配置されます。環境は、エージェントがゴールに到達するか、最大歩数 (300 歩に設定) に達したときに終了します。
<!--
<strong>MiniGrid Four Rooms.</strong> The MiniGrid Four Rooms task (MiniGrid-FourRooms-v0) is a reinforcement
learning environment in which an agent must navigate in a grid world composed of four rooms
interconnected by four gaps in the walls. The agent receives a reward of 1−0.9(step count×max steps)
if it reaches the goal located at the green square, or 0 otherwise. Again, reward normalization is used
to normalize the moving average of past rewards. The agent’s position, the goal position, and each
of the four gaps in the walls are positioned randomly at the start of each episode. The environment
terminates when the agent reaches the goal or when the maximum number of steps has been reached,
which we set to 300 steps.
-->
</p><p>

アクション空間は、左折、右折、前進、拾う、落とす、切り替え、完了に対応する7つの個別のアクションで構成されています。これらのアクションのうち、最初の3つだけがタスクに関連し、残りの4つのアクションは待機または何もしないアクションとして動作します。このタスクでは、エージェントの視野は限られており、エージェントの前方にある7×7のグリッドで構成されています。この環境の観測空間は7×7×3の形状で、7×7のタイルのそれぞれは、その位置にあるオブジェクト、色、状態IDに対応する3次元タプルとしてエンコードされています。具体的には、11種類のオブジェクト（壁、床など）、6種類の色、3種類の状態（開いている、閉じているなど）があります。
<!--
The action space is composed of 7 discrete actions, corresponding to turn left, turn right, go forward,
pickup, drop, toggle, and done. Of these actions, only the first three are relevant to the task, with the
other four actions behaving as a wait or no-op action. In this task, the agent has a limited field of view,
consisting of the 7 × 7 grid located in front of the agent. The observation space of this environment is
of shape 7 × 7 × 3, where each of the 7 × 7 tiles is encoded as a three-dimensional tuple corresponding
to the object, color and state IDs at that position. Specifically, there are 11 different objects (such as
wall, floor, etc.), 6 different colors and 3 different states (open, closed, etc.).
-->
</p>
<h2>I.2. アーキテクチャの詳細</h2>
<!--
<h2>I.2. Architecture details</h2>
-->
<p>
PPOを用いた学習のためのCTMの構成は以下のとおりです。まず、観測データはフィードフォワードネットワークなどのバックボーンによって処理され、アテンション機構を介さずにCTMの現在のアクティブ状態に連結され、一定数の内部ティックにわたって処理されます。この一定数の内部ティックの後、出力ニューロン間の同期が計算され、アクターヘッドとクリティックヘッドに渡され、次のアクションの選択と状態値の推定が行われます。
<!--
The configuration of the CTM for training with PPO is as follows. First, observations are processed by
a backbone, such as a feedforward network, and are concatenated to the current activated state of
the CTM, without an attention mechanism, for processing over a fixed number of internal ticks. After
this fixed number of internal ticks, the synchronization between the output neurons is calculated and
passed to the actor and critic heads for selecting the next action and estimating the state value.
-->
</p><p>
活性化履歴全体にわたって同期を計算する他のタスクとは異なり、RL 設定ではメモリ長 𝑀 のスライディングウィンドウを使用します。このアプローチにより、これらのタスクでは数千にまで達する可能性のある非常に長い活性化履歴の蓄積を防止できます。さらに、これにより、エピソードの展開の全段階で同じ形状のテンソルを維持できます。これを実現するために、CTM は学習済み初期状態トレースと学習済み初期活性化状態トレースの両方で初期化され、各エピソードの初期化時にモデルに提供されます。モデルの 1 回のフォワードパス（1 つの環境ステップに対応）の後、これらの状態トレースは維持され、次の環境ステップでモデルに提供されます。これにより、CTM は継続的な活動履歴を処理できるため、過去の多くの環境状態からの活性化が現在に影響を与えることができます。
<!--
Unlike the other tasks, which calculate synchronization across the entire activation history, in the RL
setting we use a sliding window of size memory length 𝑀. This approach prevents the buildup of
very long activation histories, which may grow into the thousands for these tasks. Additionally, this
allows for maintaining tensors of the same shape across all stages of the episode rollouts. To facilitate
this, the CTM is initialized with both a learned initial state trace and a learned initial activated
state trace, which are supplied to the model on the initialization of each episode. After a single
forward pass of the model (corresponding to a single environment step), these state traces will be
maintained and provided to the model on the next environment step. This allows the CTM to process
a continuous history of activity, enabling activations from many environment states in the past to
impact the present.
-->
</p><p>
従来の制御タスクでは、観測バックボーンは線形層、ゲート線形ユニット（GLU）（Dauphin et al., 2017）、および層の正規化を含む2つのブロックで構成されています。ナビゲーションタスクでも同様の入力処理が行われますが、オブジェクト、色、状態IDのそれぞれが最初に𝑑𝑒𝑚𝑏𝑒𝑑 = 8に埋め込まれます。CTMの場合、バックボーンの出力は現在のアクティブ状態に連結されますが、LSTMベースラインの場合、出力はCTMと同じ数の内部ティックで処理されます。アクターヘッドとクリティックヘッドは、それぞれReLU活性化を持つ64個のニューロンからなる2層の多層パーセプトロン（MLP）として実装されています。 CTMの場合、これらのヘッドは出力ニューロンの同期を入力として受け取りますが、LSTMベースラインの場合、これらのヘッドはLSTMの隠れ状態を𝑇内部ティック後に受け取ります。同期させるニューロンを選択するために、密なペアリングが使用されました。
<!--
For the classic control tasks, the observation backbone is composed of two blocks containing a linear
layer, a gated linear unit (GLU) (Dauphin et al., 2017) and layer normalization. A similar input
processing is carried out for the navigation task, however, each of the object, color and state IDs
are first embed in 𝑑𝑒𝑚𝑏𝑒𝑑 = 8. While for the CTM the output of the backbone is concatenated to the
current activated state, for the LSTM baseline, the output is instead processed for the same number
of internal ticks as the CTM. The actor and critic heads are implemented as two-layer multilayer
perceptrons (MLPs), each comprising two hidden layers of 64 neurons with ReLU activations. For the
CTM, these heads receive the synchronization of the output neurons as inputs, while for the LSTM
baselines, they receive the hidden state of the LSTM after 𝑇 internal tick. Dense pairing was used to
select neurons for synchronization.
-->
</p><p>
画像分類（セクション3）などのUNetスタイルのシナプスモデルを使用する他のタスクとは異なり、RLタスクでは2層のフィードフォワードシナプスを採用しています。各層は線形変換、GLU、LayerNormで構成されています。経験的に、これらの2層は単層シナプスよりも大幅に優れた性能を発揮することがわかりました。特にナビゲーションタスクでは、単層シナプスではLSTMの平均エピソード長に一貫して一致しませんでした。
<!--
Unlike other tasks such as image classification (Section 3), which use a UNet-style synapse model, the
RL tasks employ a two-layer feedforward synapse, where each layer consists of a linear transformation,
a GLU and LayerNorm. Empirically, we found that two of these layers significantly outperformed a
single layer, particularly in the navigation task, where a single-layer synapse consistently failed to
match the LSTM’s average episode length.
-->
</p><p>
CartPole、Acrobot、MiniGrid Four Roomsの実験に使用されたモデルのハイパーパラメータは、表5～7に記載されています。
<!--
The model hyperparameters used for the experiments for CartPole, Acrobot and MiniGrid Four Rooms
can be found in Tables 5 to 7.
-->

<table border="1">
<tr><th>Model</th><th> 𝑇</th><th> 𝑀</th><th>\(𝑑_{model}\)</th><th>\(𝑑_{input}\)</th><th>\(𝑑_{hidden}\)</th><th>\(𝑱_{out}\) </th><th>Total Parameters</th></tr>
<tr><td>CTM</td><td> 1 </td><td>10</td><td> 128</td><td> 128</td><td> 4</td><td> 16</td><td> 175437</td></tr>
<tr><td>LSTM</td><td> 1</td><td> –</td><td> 118</td><td> 128</td><td> –</td><td> –</td><td> 175855</td></tr>
<tr><td>CTM</td><td> 2</td><td> 20</td><td> 128</td><td> 128</td><td> 4</td><td> 16</td><td> 188237</td></tr>
<tr><td>LSTM</td><td> 2</td><td> – </td><td>126</td><td> 128</td><td> –</td><td> –</td><td> 188863</td></tr>
<tr><td>CTM</td><td> 5</td><td> 50</td><td> 128</td><td> 128</td><td> 4</td><td> 16</td><td> 226637</td></tr>
<tr><td>LSTM</td><td> 5</td><td> –</td><td> 148</td><td> 128</td><td> –</td><td> –</td><td> 227275</td></tr>
</table>
</p><p>
表 5 | CartPole 実験のモデルハイパーパラメータ。
<!--
Table 5 | Model hyperparameters for the CartPole experiments.
-->
<table border="1">
<tr><th> Model</th><th> 𝑇</th><th> 𝑀</th><th>\(𝑑_{model}\)</th><th>\(𝑑_{input}\)</th><th>\(𝑑_{hidden}\) </th><th>\(𝑱_{out}\)</th><th> Total Parameters</th></tr>
<tr><td>CTM </td><td>1</td><td> 5</td><td> 256</td><td> 64</td><td> 4</td><td> 16</td><td> 350094</td></tr>
<tr><td>LSTM </td><td>1</td><td> –</td><td> 243</td><td> 64</td><td> –</td><td> –</td><td> 350118</td></tr>
<tr><td>CTM</td><td> 2</td><td> 10</td><td> 256</td><td> 64</td><td> 4</td><td> 16</td><td> 362894</td></tr>
<tr><td>LSTM</td><td> 2</td><td> –</td><td> 249</td><td> 64</td><td> –</td><td> –</td><td> 364290</td></tr>
<tr><td>CTM</td><td> 5</td><td> 25</td><td> 256</td><td> 64</td><td> 4</td><td> 16</td><td> 401294</td></tr>
<tr><td>LSTM</td><td> 5</td><td> –</td><td> 265</td><td> 64</td><td> – </td><td>–</td><td> 403490</td></tr>
</table>
</p><p>
表 6 | Acrobot 実験のモデルハイパーパラメータ。
<!--
Table 6 | Model hyperparameters for the Acrobot experiments.
-->
<table border="1">
<tr><th>Model</th><th> 𝑇</th><th> 𝑀</th><th> \(𝑑_{model}\) </th><th>\(𝑑_{input}\) </th><th>\(𝑑_{hidden}\)</th><th> \(𝑱_{out}\)</th><th> Total Parameters</th></tr>
<tr><td>CTM</td><td> 1</td><td> 10</td><td> 512</td><td> 128</td><td> 16</td><td> 32</td><td> 7802690</td></tr>
<tr><td>LSTM</td><td> 1</td><td> –</td><td> 294</td><td> 128</td><td> –</td><td> –</td><td> 7813692</td></tr>
<tr><td>CTM</td><td> 2</td><td> 20</td><td> 512</td><td> 128</td><td> 16</td><td> 32</td><td> 7976770</td></tr>
<tr><td>LSTM</td><td> 2</td><td> –</td><td> 300</td><td> 128</td><td> –</td><td> –</td><td> 7979304</td></tr>
</table>
</p><p>
表 7 | MiniGrid Four Rooms 実験のモデルハイパーパラメータ。
<!--
Table 7 | Model hyperparameters for the MiniGrid Four Rooms experiments.
-->
</p>
<h3>I.3. 最適化の詳細</h3>
<!--
<h3>I.3. Optimization details</h3>
-->
<p>
モデルは、単一のH100 Nvidia GPU上でProximal Policy Optimization (Schulman et al., 2017)を用いて学習されました。CTMとLSTMベースラインの両方に同じPPOハイパーパラメータセットが使用されており、表8に示されています。
<!--
The models were trained with Proximal Policy Optimization (Schulman et al., 2017) on single H100
Nvidia GPU. The same set of PPO hyperparameters were used for both the CTM and the LSTM
baseline, and are shown in Table 8.
-->
<table border="1">
<tr><th>Hyperparameter</th><th> CartPole</th><th> Acrobot</th><th> MiniGrid Four Rooms</th></tr>
<tr><td>Learning Rate (LR)</td><td> \(1×10^{−3}\)</td><td> \(5 × 10^{−4}\)</td><td> \(1 × 10^{−4}\)</td></tr>
<tr><td>Total Environment Steps</td><td> 10M</td><td> 2M</td><td> 300M</td></tr>
<tr><td>Rollout Length</td><td> 50</td><td> 100</td><td> 50</td></tr>
<tr><td>Number of Environments</td><td> 256</td><td> 12</td><td> 256</td></tr>
<tr><td>Max Environment Steps per Episode</td><td> 200</td><td> 500</td><td> 300</td></tr>
<tr><td>Update Epochs</td><td> 4</td><td> 1</td><td> 1</td></tr>
<tr><td>Minibatches</td><td> 4</td><td> 4</td><td> 4</td></tr>
<tr><td>Discount Factor (𝛾) </td><td>0.99</td><td> 0.99 </td><td>0.99</td></tr>
<tr><td>GAE Lambda (𝜆) </td><td>0.95 </td><td>0.95 </td><td>0.95</td></tr>
<tr><td>Clip Coefficient </td><td>0.1</td><td> 0.1</td><td> 0.1</td></tr>
<tr><td>Entropy Coefficient </td><td>0.1</td><td> 0.1 </td><td>0.1</td></tr>
<tr><td>Value Function Coefficient </td><td>0.25 </td><td>0.25 </td><td>0.25</td></tr>
<tr><td>Value Function Clipping</td><td> No </td><td>No </td><td>No</td></tr>
<tr><td>Max Gradient Norm </td><td>0.5</td><td> 0.5 </td><td>0.5</td></tr>
</table>
</p><p>
表 8 | 各タスクの PPO ハイパーパラメータ。
<!--
Table 8 | PPO hyperparameters for each task.
-->
</p>

<h2>J. UMAP</h2>
<p>
図6の構築にはUMAP (McInnes et al., 2018) を使用しました。この場合のUMAPの目的は、ImageNet CTM内の各ニューロンに2次元的な位置を与え、ニューロンの活動の経時変化を視覚化する際に、意味のあるパターンが存在する場合にそれを観察できるようにすることです。この目的のために、200枚の異なる画像における活動後の履歴をUMAPへの高次元入力（200 × 𝑇 = 200 × 5 = 1000次元）として考慮しました。そして、UMAPを用いてこれを2次元空間に投影し、視覚化しました。
<!--
We used UMAP (McInnes et al., 2018) to build Figure 6. The purpose of UMAP in this case was
to give each neuron in the ImageNet CTM a 2D location such that when their activities over time
were visualized a meaningful pattern could be observed, should it exist. To this end, we considered
the histories of post-activations for 200 different images as the high-dimensional inputs to UMAP
(200 × 𝑇 = 200 × 5 = 1000 dimensions). UMAP was then used to project this to a 2D space for
visualization.
-->
</p>
<h2>K. 同期行列の再帰計算</h2>
<!--
<h2>K. Recursive computation of the synchronization matrix</h2>
-->
<p>
In Section 2.4 we defined the synchronization matrix at internal tick 𝑡 as
\[
\mathbf S^𝑡 = \mathbf Z^𝑡 (\mathbf Z^𝑡)^⊺,　　 \mathbf Z^𝑡 ∈\mathbb  ℝ^{𝐷×𝑡}  \tag{13}
\]

ここで、\(\mathbf Z^𝑡\) の n 番目の行には、ニューロン 𝑑 のティック \(𝑡\) までの活性化後のトレースが格納されます (式 (4) を参照)。式 (13) はティックごとにすべての 𝐷2 内積を最初から再計算するため、その時間計算量は長さ 𝑡 のロールアウト全体で O(𝐷2𝑡) です。以下では、式 (10) を指数関数的に減少させる再スケーリングにより、ティックごとに O(𝐷sub) の作業しか必要としない 1 階の再帰のペアから同じ量を取得できることを示します。ここで、𝐷sub ≪ 𝐷 は、出力とアクションの投影に実際に使用されるサブサンプリングされたニューロンインデックスの数です。
<!--
where the 𝑑–th row of \(\mathbf Z^𝑡\) stores the post–activation trace of neuron 𝑑 up to tick \(𝑡\) (cf. Eq. (4)). Because
Eq. (13) recomputes all 𝐷2 inner products from scratch at every tick, its time complexity is O(𝐷2𝑡)
over a roll-out of length 𝑡. Below we show that, with the exponentially–decaying rescaling of Eq. (10),
the same quantity can be obtained from a pair of first–order recursions that require only O(𝐷sub)
work per tick, where 𝐷sub ≪ 𝐷 is the number of subsampled neuron indices actually used for the
output and action projections.
-->
</p><p>
表記を明瞭にするため、まず単一の（𝑖,𝑗）ニューロンペアを考え、サブサンプリングは省略する。ペアのバッチへの拡張は即座に可能である。再スケールされた同期エントリは次のように定義されることを思い出してほしい。
<!--
For notational clarity we first consider a single (𝑖, 𝑗) neuron pair and omit the subsampling; the
extension to a batch of pairs is immediate. Recall that the rescaled synchronization entry is defined
as
-->
\[
𝑆_{ij}^𝑡 =\frac{\sum\limits_{𝜏=1}^t e^{−𝑟_{𝑖𝑗} (𝑡−𝜏)} 𝑧_i^𝜏 𝑧_j^𝜏}{\sqrt{\sum\limits_{\tau=1}^t e^{−𝑟_{𝑖𝑗} (𝑡−𝜏)}}} \tag{14}
\]
ここで、\(𝑟_{𝑖𝑗} ≥ 0\) はペア (𝑖, 𝑗) の学習可能な減衰率である。以下の補助シーケンスを定義する。
<!--
where \(𝑟_{𝑖𝑗} ≥ 0\) is the learnable decay rate for the pair (𝑖, 𝑗). Define the following auxiliary sequences
-->
\[
\begin{align}
\alpha_{ij}^t &:= \sum_{\tau=1}^t e^{-r_{ij}(t^tau)}z_i^\tau z_j^\tau　　\alpha_{ij}^1=z_i^1z_j^1 \tag{15} \\
\\
\beta_{ij}^t &:= \sum_{𝜏=1}^t e^{−𝑟_{𝑖𝑗} (𝑡−𝜏)}　　\beta_{ij}^1=1 \tag{16}
\end{align}
\]

すると、\(𝑆_{ij}^𝑡 = 𝛼_{ij}^𝑡/\sqrt{𝛽_{ij}^𝑡}\) となり、\(𝛼_{ij}^𝑡\) と \(𝛽_{ij}^𝑡\) は両方とも単純な1階差分方程式に従います。
<!--
Then \(𝑆_{ij}^𝑡 = 𝛼_{ij}^𝑡/\sqrt{𝛽_{ij}^𝑡}\) and both \(𝛼_{ij}^𝑡\) and \(𝛽_{ij}^𝑡\) obey simple first–order difference equations:
-->

\[
\begin{align}
𝛼_{ij}^{𝑡+1} &= e^{−𝑟_{𝑖𝑗}}𝛼_{ij}^𝑡 + 𝑧_i^{𝑡+1}𝑧_j^{𝑡+1} \tag{17} \\
\\
𝛽_{ij}^{𝑡+1} &= e^{−𝑟_{𝑖𝑗}} 𝛽_{ij}^𝑡 + 1  \tag{18}
\end{align}
\]

式(17)のランク1更新により、完全な活性化履歴を保存したり、大きな外積を繰り返し形成したりする必要がなくなる。順方向シミュレーション中、選択された各ペアについて \(𝛼_{ij}^𝑡\) と \(𝛽_{ij}^𝑡\) を維持し、\(\mathcal O(1)\) 時間で更新する。
<!--
The rank–1 update in Eq. (17) makes it unnecessary to store the full activation history or to repeatedly
form large outer products. During forward simulation we maintain \(𝛼_{ij}^𝑡\) and \(𝛽_{ij}^𝑡\) for each selected pair and update them in \(\mathcal O(1)\) time.
-->
</p><p>

実際には、\(\{𝛼_{ij}^𝑡, 𝛽_{ij}^𝑡\}\) は、\(\mathbf S_{out}^𝑡\) と \(\mathbf S_{action}^𝑡\) を形成する2つの互いに素な部分サンプルに対してのみ保存されます (セクション 2.4)。したがって、メモリ使用量と計算オーバーヘッドはどちらも保持されるペアの数に比例して増加します。つまり、ティックあたり \(\mathcal O(𝐷_{sub}) = \mathcal O(𝐷_{out} + 𝐷_{action})\) となります。
<!--
In practice we store \(\{𝛼_{ij}^𝑡, 𝛽_{ij}^𝑡\}\) only for the two disjoint subsamples that form \(\mathbf S_{out}^𝑡\) and \(\mathbf S_{action}^𝑡\) (Section 2.4). Both memory footprint and compute overhead therefore scale linearly with the number of
retained pairs, i.e. \(\mathcal O(𝐷_{sub}) = \mathcal O(𝐷_{out} + 𝐷_{action})\) per tick.
-->
</p>
    </body>
</html>
